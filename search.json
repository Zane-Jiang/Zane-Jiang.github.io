[{"title":"CUDAç®—å­ä¼˜åŒ–-Reduce","path":"/2025/09/06/CUDA ç®—å­ä¼˜åŒ–ç³»åˆ—/CUDAç®—å­ä¼˜åŒ–-Reduce/","content":"æœ¬æ–‡æ˜¯å¯¹å®˜æ–¹reduceä¼˜åŒ–çš„ç²¾ç®€ï¼Œæ–¹ä¾¿ä¸ªäººå¤ä¹ ,è¯¦ç»†å›é¡¾å‚è€ƒçŸ¥ä¹æ·±å…¥æµ…å‡ºç³»åˆ— leetGPU é—®é¢˜è§£å†³ å±•ç¤º reduceçš„7ç§ä¼˜åŒ– V0_0 naiveè·¨æ­¥ç›¸åŠ ï¼Œéå…¨å±€å†…å­˜è®¿é—®ï¼Œ __global__ void reduce_naive(float *g_idata, float *g_odata, unsigned int n) unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx = n) return; // ç›´æ¥åœ¨å…¨å±€å†…å­˜ä¸Šè¿›è¡Œè·¨æ­¥å½’çº¦ for (unsigned int stride = 1; stride blockDim.x; stride *= 2) // ç¡®ä¿æ‰€æœ‰å‰ä¸€è½®çš„å†™å…¥å¯¹ä¸‹ä¸€è½®å¯è§ if (threadIdx.x % (2 * stride) == 0) g_idata[idx] += g_idata[idx + stride]; __syncthreads(); // ä¸€ä¸ªçº¿ç¨‹å—çš„ç»“æœå†™å›å…¨å±€å†…å­˜ if (threadIdx.x == 0) g_odata[blockIdx.x] = g_idata[blockIdx.x * blockDim.x]; æ•´ä¸ªè¿‡ç¨‹éƒ½åœ¨è¯»å†™ç¼“æ…¢çš„å…¨å±€å†…å­˜ï¼Œå»¶è¿Ÿå¾ˆé«˜ï¼ŒO(N)æ¬¡æ“ä½œéœ€è¦è®¿é—®å…¨å±€å†…å­˜O(NlogN)æ¬¡å…¨å±€å†…å­˜ï¼Œæ•ˆç‡ä½ V0 shared_memory.unacawfvhnxu{zoom:50%;} __global__ void reduce0(int *g_idata, int *g_odata) extern __shared__ int sdata[]; // each thread loads one element from global to shared mem\tunsigned int tid = threadIdx.x;\tunsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\tsdata[tid] = g_idata[i]; __syncthreads();\t// do reduction in shared mem\tfor(unsigned int s=1; s blockDim.x; s *= 2) if (tid % (2*s) == 0) sdata[tid] += sdata[tid + s]; __syncthreads(); // write result for this block to global mem\tif (tid == 0) g_odata[blockIdx.x] = sdata[0]; é—®é¢˜ï¼š ä¼šé€ æˆçº¿ç¨‹æŸåˆ†åŒ–ï¼ŒåŒä¸€ä¸ªwarpså†…æ‰§è¡Œçš„æ“ä½œä¸ä¸€è‡´ V1 çº¿ç¨‹æŸåˆ†åŒ–__global__ void reduce1(float *d_in,float *d_out) __shared__ float sdata[THREAD_PER_BLOCK]; //each thread loads one element from global memory to shared mem unsigned int i=blockIdx.x*blockDim.x+threadIdx.x; unsigned int tid=threadIdx.x; sdata[tid]=d_in[i]; __syncthreads(); // do reduction in shared mem for(unsigned int s=1; sblockDim.x; s*=2) int index = 2*s*tid; if(index blockDim.x)//ä¸åŒçº¿ç¨‹æŸæ‰§è¡Œä¸åŒ sdata[index]+=sdata[index+s]; __syncthreads(); // write result for this block to global mem if(tid==0)d_out[blockIdx.x]=sdata[tid]; æœ¬è´¨ï¼Œå°†åŒºåˆ«é€šè¿‡indexè½¬æ¢è¿ç§»åˆ°çº¿ç¨‹æŸä¹‹é—´è€Œä¸æ˜¯çº¿ç¨‹æŸå†…éƒ¨ï¼Œä»¥å‰æ˜¯æ¯ä¸ªçº¿ç¨‹æŸä¸­éƒ½ä¼šå‡ºç°if elseï¼Œé™åˆ¶æ˜¯ä¸€ä¸ªçº¿ç¨‹æŸä¸­çš„ç¨‹åºéƒ½ä¸€èµ·æ‰§è¡Œæˆ–è€…ä¸€èµ·ä¸æ‰§è¡Œï¼ˆæœ€åå‡ è½®é™¤å¤–ï¼‰ ç»§ç»­å‡å®šblockä¸­å­˜åœ¨256ä¸ªthreadï¼Œå³æ‹¥æœ‰256328ä¸ªwarpã€‚å½“è¿›è¡Œç¬¬1æ¬¡è¿­ä»£æ—¶ï¼Œ0-3å·warpçš„indexblockDim.xï¼Œ 4-7å·warpçš„indexblockDim.xã€‚å¯¹äºæ¯ä¸ªwarpè€Œè¨€ï¼Œéƒ½åªæ˜¯è¿›å…¥åˆ°ä¸€ä¸ªåˆ†æ”¯å†…ï¼Œæ‰€ä»¥å¹¶ä¸ä¼šå­˜åœ¨warp divergenceçš„æƒ…å†µã€‚å½“è¿›è¡Œç¬¬2æ¬¡è¿­ä»£æ—¶ï¼Œ0ã€1å·ä¸¤ä¸ªwarpè¿›å…¥è®¡ç®—åˆ†æ”¯ã€‚å½“è¿›è¡Œç¬¬3æ¬¡è¿­ä»£æ—¶ï¼Œåªæœ‰0å·warpè¿›å…¥è®¡ç®—åˆ†æ”¯ã€‚å½“è¿›è¡Œç¬¬4æ¬¡è¿­ä»£æ—¶ï¼Œåªæœ‰0å·warpçš„å‰16ä¸ªçº¿ç¨‹è¿›å…¥åˆ†æ”¯ã€‚æ­¤æ—¶å¼€å§‹äº§ç”Ÿwarp divergenceã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æ¶ˆé™¤äº†å‰3æ¬¡è¿­ä»£çš„warp divergenceã€‚ æ¥è‡ªçŸ¥ä¹ã€Šæ·±å…¥æµ…å‡ºGPUä¼˜åŒ–ç³»åˆ—ã€‹ V2 bankå†²çª0å·å’Œ32å·å…ƒç´ å†²çª __global__ void reduce2(float *d_in,float *d_out) __shared__ float sdata[THREAD_PER_BLOCK]; //each thread loads one element from global memory to shared mem unsigned int i=blockIdx.x*blockDim.x+threadIdx.x; unsigned int tid=threadIdx.x; sdata[tid]=d_in[i]; __syncthreads(); // do reduction in shared mem for(unsigned int s=blockDim.x/2; s0; s=1) if(tid s) sdata[tid]+=sdata[tid+s]; __syncthreads(); // write result for this block to global mem if(tid==0)d_out[blockIdx.x]=sdata[tid]; è®©ä¸€å¼€å§‹çš„è®¿å­˜è·¨åº¦æœ€å¤§ï¼Œæ°å¥½åœ¨å…ƒç´ å¤šçš„æ—¶å€™é”™å¼€ï¼Œä¸€ä¸ªwarpä¸­ä¸ä¼šåŒæ—¶è®¿é—®åŒä¸€ä¸ªbank é—®é¢˜ï¼š ä¸€åŠçš„çº¿ç¨‹æ˜¯ç©ºé—²çš„ V3 ç©ºé—²çº¿ç¨‹ä¼˜åŒ–__global__ void reduce3(float *d_in,float *d_out) __shared__ float sdata[THREAD_PER_BLOCK]; //each thread loads one element from global memory to shared mem unsigned int i=blockIdx.x*(blockDim.x*2)+threadIdx.x; //æ ¸å¿ƒï¼Œæ¯ä¸ªblockå¤„ç†ä¸¤ä¸ªblock unsigned int tid=threadIdx.x; sdata[tid]=d_in[i] + d_in[i+blockDim.x]; __syncthreads(); // do reduction in shared mem for(unsigned int s=blockDim.x/2; s0; s=1) if(tid s) sdata[tid]+=sdata[tid+s]; __syncthreads(); // write result for this block to global mem if(tid==0)d_out[blockIdx.x]=sdata[tid]; V4 å±•å¼€æœ€åä¸€æ¬¡è®¡ç®—å‡å°‘åŒæ­¥__device__ void warpReduce(volatile float* cache,int tid) //volatile çš„ä½œç”¨ï¼šç¦æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–ï¼Œæ¯æ¬¡è®¿é—®éƒ½å¿…é¡»çœŸæ­£ä»å…±äº«å†…å­˜é‡Œå–å€¼/å†™å€¼,é˜²æ­¢ç¼“å­˜åˆ°å¯„å­˜å™¨é‡Œï¼Œç„¶åé‡å¤ä½¿ç”¨å¯„å­˜å™¨çš„å€¼ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½ä»å…±äº«å†…å­˜è¯»å– //32åˆ°1æ˜¯è·¨åº¦s cache[tid]+=cache[tid+32]; cache[tid]+=cache[tid+16]; cache[tid]+=cache[tid+8]; cache[tid]+=cache[tid+4]; cache[tid]+=cache[tid+2]; cache[tid]+=cache[tid+1];__global__ void reduce4(float *d_in,float *d_out) __shared__ float sdata[THREAD_PER_BLOCK]; //each thread loads one element from global memory to shared mem unsigned int i=blockIdx.x*(blockDim.x*2)+threadIdx.x; unsigned int tid=threadIdx.x; sdata[tid]=d_in[i] + d_in[i+blockDim.x]; __syncthreads(); // do reduction in shared mem for(unsigned int s=blockDim.x/2; s32; s=1) if(tid s) sdata[tid]+=sdata[tid+s]; __syncthreads(); // write result for this block to global mem if(tid32)warpReduce(sdata,tid); if(tid==0)d_out[blockIdx.x]=sdata[tid]; ä¸€ä¸ªSIMDå•å…ƒå·¥ä½œæ—¶ï¼Œé¿å…__syncthreadsåŒæ­¥ V5 æš´åŠ›forå¾ªç¯å±•å¼€å…¶å®ä¸ªäººæ— æ³•ç†è§£ï¼Œç°ä»£ç‰ˆæœ¬ä¸­æ„Ÿè§‰ä¸éœ€è¦äº† template unsigned int blockSize__device__ void warpReduce(volatile float* cache,int tid) if(blockSize = 64)cache[tid]+=cache[tid+32]; if(blockSize = 32)cache[tid]+=cache[tid+16]; if(blockSize = 16)cache[tid]+=cache[tid+8]; if(blockSize = 8)cache[tid]+=cache[tid+4]; if(blockSize = 4)cache[tid]+=cache[tid+2]; if(blockSize = 2)cache[tid]+=cache[tid+1];template unsigned int blockSize__global__ void reduce5(float *d_in,float *d_out) __shared__ float sdata[THREAD_PER_BLOCK]; //each thread loads one element from global memory to shared mem unsigned int i=blockIdx.x*(blockDim.x*2)+threadIdx.x; unsigned int tid=threadIdx.x; sdata[tid]=d_in[i] + d_in[i+blockDim.x]; __syncthreads(); // do reduction in shared mem if(blockSize=512) if(tid256) sdata[tid]+=sdata[tid+256]; __syncthreads(); if(blockSize=256) if(tid128) sdata[tid]+=sdata[tid+128]; __syncthreads(); if(blockSize=128) if(tid64) sdata[tid]+=sdata[tid+64]; __syncthreads(); // write result for this block to global mem if(tid32)warpReduceblockSize(sdata,tid); if(tid==0)d_out[blockIdx.x]=sdata[tid]; V6ç‰ˆæœ¬å’Œæ–‡ç« ä¸­è®²çš„æœ‰äº›å·®è·ï¼Œæœ¬è´¨ä¸€ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªæ•°ã€‚ template unsigned int blockSize, int NUM_PER_THREAD__global__ void reduce6(float *d_in,float *d_out, unsigned int n) __shared__ float sdata[blockSize]; // each thread loads NUM_PER_THREAD element from global to shared mem unsigned int tid = threadIdx.x; unsigned int i = blockIdx.x * (blockSize * NUM_PER_THREAD) + threadIdx.x; sdata[tid] = 0; #pragma unroll for(int iter=0; iterNUM_PER_THREAD; iter++) sdata[tid] += d_in[i+iter*blockSize]; __syncthreads(); // do reduction in shared mem if (blockSize = 512) if (tid 256) sdata[tid] += sdata[tid + 256]; __syncthreads(); if (blockSize = 256) if (tid 128) sdata[tid] += sdata[tid + 128]; __syncthreads(); if (blockSize = 128) if (tid 64) sdata[tid] += sdata[tid + 64]; __syncthreads(); if (tid 32) warpReduceblockSize(sdata, tid); // write result for this block to global mem if (tid == 0) d_out[blockIdx.x] = sdata[0]; reduce6THREAD_PER_BLOCK, NUM_PER_THREADGrid,Block(d_a, d_out, N); V7 shuffleä¼˜åŒ–todo How_to_optimize_in_GPUreducereduce_v7_shuffle.cu at master Â· Liu-xiandongHow_to_optimize_in_GPU é‡‡ç”¨äº†shuffleæŒ‡ä»¤ä¹‹åï¼Œwarpå†…çš„çº¿ç¨‹å¯ä»¥ç›´æ¥å¯¹å…¶ä»–çº¿ç¨‹çš„å¯„å­˜å™¨è¿›è¡Œè®¿å­˜ã€‚é€šè¿‡è¿™ç§æ–¹å¼å¯ä»¥å‡å°‘è®¿å­˜çš„å»¶æ—¶ã€‚ #define THREAD_PER_BLOCK 256#define WARP_SIZE 32template unsigned int blockSize__device__ __forceinline__ float warpReduceSum(float sum) if (blockSize = 32)sum += __shfl_down_sync(0xffffffff, sum, 16); // 0-16, 1-17, 2-18, etc. if (blockSize = 16)sum += __shfl_down_sync(0xffffffff, sum, 8);// 0-8, 1-9, 2-10, etc. if (blockSize = 8)sum += __shfl_down_sync(0xffffffff, sum, 4);// 0-4, 1-5, 2-6, etc. if (blockSize = 4)sum += __shfl_down_sync(0xffffffff, sum, 2);// 0-2, 1-3, 4-6, 5-7, etc. if (blockSize = 2)sum += __shfl_down_sync(0xffffffff, sum, 1);// 0-1, 2-3, 4-5, etc. return sum;template unsigned int blockSize, int NUM_PER_THREAD__global__ void reduce7(float *d_in,float *d_out, unsigned int n) float sum = 0; // each thread loads one element from global to shared mem unsigned int tid = threadIdx.x; #pragma unroll //çº¿ç¨‹çº§å±€éƒ¨è§„çº¦ for(int iter=0; iterNUM_PER_THREAD; iter++) sum += d_in[i+iter*blockSize]; // Shared mem for partial sums (one per warp in the block) static __shared__ float warpLevelSums[WARP_SIZE]; const int laneId = threadIdx.x % WARP_SIZE; const int warpId = threadIdx.x / WARP_SIZE; sum = warpReduceSumblockSize(sum); if(laneId == 0 )warpLevelSums[warpId] = sum; __syncthreads(); // read from shared memory only if that warp existed sum = (threadIdx.x blockDim.x / WARP_SIZE) ? warpLevelSums[laneId] : 0; // Final reduce using first warp if (warpId == 0) sum = warpReduceSumblockSize/WARP_SIZE(sum); // write result for this block to global mem if (tid == 0) d_out[blockIdx.x] = sum;reduce7THREAD_PER_BLOCK, NUM_PER_THREADGrid,Block(d_a, d_out, N); ä¼˜åŒ–æ€»ç»“ ä½¿ç”¨å…±äº«å†…å­˜ å‡å°‘çº¿ç¨‹æŸåˆ†åŒ–ï¼ˆå·®å¼‚ä¿ç•™åœ¨çº¿ç¨‹æŸä¹‹é—´ï¼‰ å‡å°‘bankå†²çªï¼›å˜æ¢è§’æ ‡ï¼Œé”™ä½ï¼ˆ+1ä¸è·¨åº¦é”™ä½ï¼‰ å‡å°‘ç©ºé—²çº¿ç¨‹ï¼Œä¸€ä¸ªçº¿ç¨‹å–ä¸¤ä¸ªå…ƒç´  å‡å°‘__syncthreadsåŒæ­¥ï¼Œä¸€ä¸ªSIMDå†…å¯ä»¥ä¸ä½¿ç”¨ åˆç†è®¾ç½®blockæ•°é‡ ä½¿ç”¨shuffleæŒ‡ä»¤","tags":["CUDA.C++"],"categories":["CUDA"]},{"title":"CUDAç®—å­ä¼˜åŒ–-SoftMax","path":"/2025/09/06/CUDA ç®—å­ä¼˜åŒ–ç³»åˆ—/CUDAç®—å­ä¼˜åŒ–-SoftMax/","content":"TongkaioCUDA_Kernel_Samples: CUDA ç®—å­æ‰‹æ’•ä¸é¢è¯•æŒ‡å—","tags":["CUDA.C++"],"categories":["CUDA"]},{"title":"GGMLæºç æµ…æ(1) åŸºç¡€æ•°æ®ç»“æ„ã€å†…å­˜ç®¡ç†ã€åç«¯ç®¡ç†","path":"/2025/08/01/GGMLæºç æµ…æ/","content":"GGML æºç æµ…æï¼ˆ1ï¼‰å‰è¨€1.é˜…è¯»è·¯çº¿ â€‹\t1.å†…å­˜ç®¡ç†ï¼šä¸ä½¿ç”¨åç«¯æ—¶ï¼ˆå‚è§examplesimple-ctxï¼‰ä»‹ç»ggmlä¸­çš„é‡è¦æ•°æ®ç»“æ„ä»¥åŠå†…å­˜ç®¡ç† â€‹\t2.åç«¯çš„è®¾è®¡é€»è¾‘ 3.åŸºäºgpt-2å­¦ä¹ æ¨¡å‹æ„å»ºè¿‡ç¨‹ä¸­æƒé‡ä¸kv-cacheç®¡ç† 2.é‡ç‚¹ â€‹\t1.å…³äºggml-contextçš„ç›¸å…³æ•°æ®ç»“æ„ï¼Œéœ€è¦ç†è§£ggml-contxtä¸­å†…å­˜åˆ†é…ç»“æ„ï¼Œå¯ä»¥å‚çœ‹å…¶ä¸­ç»™çš„å‡ å¼ å›¾ â€‹\t2.é€šè¿‡è¾“å‡ºç»“æœåæ¨æ„å»ºè®¡ç®—å›¾ â€‹\t3.åç«¯è®¾è®¡ä¸­ï¼Œä¸€å®šç”¨é¢å‘å¯¹è±¡çš„æ–¹å¼æ¥æ€è€ƒç›¸å…³åç«¯å®ç°ï¼Œå…¶å®å°±æ˜¯ç”¨cå®ç°äº†C++çš„é¢å‘å¯¹è±¡ï¼Œè‡ªå·±å®ç°äº†è™šå‡½æ•°è¡¨ï¼Œç§æœ‰æˆå‘˜å˜é‡ï¼ˆvoid*) â€‹\t4.ä¸€æ¬¡æ“ä½œçš„é€»è¾‘ å¤§ä½¬æ•™ç¨‹ æ·±å…¥ç†è§£GGMLï¼ˆä¸€ï¼‰æ¨¡å‹å’Œè®¡ç®—å›¾ - çŸ¥ä¹ 1.æ ¸å¿ƒæ•°æ®ç»“æ„1.1ggml_contextstruct ggml_context size_t mem_size; void* mem_buffer; //cpué‡‡ç”¨ç”±poxsi_alignåˆ†é…çš„å†…å­˜å¯¹é½å†…å­˜ï¼Œå¯¹äºä¸åŒçš„åç«¯ï¼Œåˆ†é…ä¸åŒçš„å†…å­˜ bool mem_buffer_owned;//å¤–éƒ¨åˆ†é…è¿˜æ˜¯å±äºæœ¬å¤„ï¼Œå†³å®šå†…å­˜åˆ†é…æƒï¼Ÿ bool no_alloc; bool no_alloc_save; // this is used to save the no_alloc state when using scratch buffers int n_objects; struct ggml_object * objects_begin;//ggml_objectç»´æŠ¤çš„æ˜¯ä¸€ä¸ªé“¾è¡¨ struct ggml_object * objects_end; struct ggml_scratch scratch; struct ggml_scratch scratch_save;; struct ggml_object size_t offs; size_t size; struct ggml_object * next; enum ggml_object_type type; char padding[4]; ; ggml_contextæ˜¯æœ€æ ¸å¿ƒçš„æ•°æ®ç»“æ„ï¼Œæ‰€æœ‰çš„å¼ é‡ã€è®¡ç®—å›¾éƒ½ä¾èµ–äºè¿™ä¸ªæ•°æ®ç»“æ„: mem_sizeè¡¨ç¤ºggml_initæ—¶åˆ†é…ä¸€å—å¤šå¤§çš„å†…å­˜ï¼Œåç»­çš„å¼ é‡éƒ½ä»è¿™å—å†…å­˜ä¸­åˆ†é…ç©ºé—´ï¼Œé¿å…åå¤çš„malloc mem_buffer_ownedè¡¨ç¤ºè¿™ä¸ªmem_bufferæ˜¯å¤–éƒ¨ä¼ è¿›æ¥çš„è¿˜æ˜¯è‡ªå·±åˆ†é…çš„ï¼Œå†³å®šåˆ†é…æƒï¼Œé¿å…è¯¯é‡Šæ”¾ ã€‚ no_mallocæ˜¯è¡¨ç¤ºå¼ é‡åˆ†é…å†…å­˜çš„æ—¶å€™æ˜¯çœŸçš„åˆ†é…å†…å­˜è¿˜æ˜¯ä»…ä»…ç”¨äºå ä½ no_alloc_saveä½¿ç”¨äº†scratchä¼šå¼ºåˆ¶å¼€å¯å†…å­˜ï¼Œæ‰€ä»¥éœ€è¦æš‚å­˜ä¸€ä¸‹no_malloc scratchæ˜¯ä¸€å—ä¸´æ—¶å†…å­˜ï¼Œç”¨äºå­˜æ”¾ä¸­é—´çš„ä¸´æ—¶ç»“æœã€ç¼“å­˜ scratch_saveæš‚å­˜scatchçš„çŠ¶æ€ n_objectsä»¥åŠä¸¤ä¸ªæŒ‡é’ˆç»´æŠ¤äº†ä¸€ä¸ªå¯¹è±¡åŒå‘é“¾è¡¨ï¼Œè®°å½•æ‰€æœ‰å·²åˆ›å»ºçš„å¯¹è±¡ï¼Œå¯ä»¥çœ‹åˆ°è¿™ä¸ªggml_objectä¸»è¦ç»´æŠ¤äº†åç§»offså’Œsize,å®¹æ˜“ç†è§£å®é™…æ•°æ®å°±æ˜¯åˆ†é…åœ¨ggml_contextçš„bufferä¸­ï¼Œè€Œè¦æ‰¾åˆ°è¿™äº›æ•°æ®å°±é€šè¿‡objecté“¾è¡¨æ¥è¿›è¡ŒæŸ¥æ‰¾ä¸åˆ†é…ã€‚ ggml_objectè¿™ä¸ªç»“æ„ä½“æœ¬æœ¬èº«ä¹Ÿæ˜¯åˆ†é…åœ¨ggml_context.mem_bufferä¸Šçš„ï¼Œä¹‹åè·Ÿç€å¯¹åº”çš„æ•°æ®ã€‚ ggml-object-ggml_tensor-tensor_data è¿™ä¸€éƒ¨åˆ†çš„å®ç°å…·ä½“æŸ¥çœ‹ggml_new_object static struct ggml_object * ggml_new_object(struct ggml_context * ctx, enum ggml_object_type type, size_t size) // always insert objects at the end of the contexts memory pool struct ggml_object * obj_cur = ctx-objects_end; const size_t cur_offs = obj_cur == NULL ? 0 : obj_cur-offs; const size_t cur_size = obj_cur == NULL ? 0 : obj_cur-size; const size_t cur_end = cur_offs + cur_size; // align to GGML_MEM_ALIGN size_t size_needed = GGML_PAD(size, GGML_MEM_ALIGN); char * const mem_buffer = ctx-mem_buffer; struct ggml_object * const obj_new = (struct ggml_object *)(mem_buffer + cur_end); if (cur_end + size_needed + GGML_OBJECT_SIZE ctx-mem_size) GGML_PRINT(%s: not enough space in the contexts memory pool (needed %zu, available %zu) , __func__, cur_end + size_needed, ctx-mem_size); assert(false); return NULL; *obj_new = (struct ggml_object) .offs = cur_end + GGML_OBJECT_SIZE, .size = size_needed, .next = NULL, .type = type, ; GGML_ASSERT_ALIGNED(mem_buffer + obj_new-offs); if (obj_cur != NULL) obj_cur-next = obj_new; else // this is the first object in this context ctx-objects_begin = obj_new; ctx-objects_end = obj_new; //printf(%s: inserted new object at %zu, size = %zu , __func__, cur_end, obj_new-size); return obj_new; å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„æ“ä½œéƒ½æŒ‚é åˆ°ggml_contextä¸Š å†…å­˜åˆ†é…ï¼š struct ggml_init_params params = .mem_size = 64 * 1024 * 1024, .mem_buffer = malloc(mem_size), .no_alloc = false;struct ggml_context * ctx = ggml_init(params); å¼ é‡åˆ†é…ï¼š struct ggml_tensor * a = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 10); â€‹\tå¯ä»¥æŸ¥çœ‹ggml.c/ggml_new_tensor_impl()å…·ä½“å®ç°ï¼Œæœ€ç»ˆåˆ†é…çš„tensorçš„data,æŒ‡é’ˆæŒ‡å‘çš„æ•°æ®è¿˜æ˜¯ggml_contxt.mem_bufä¸­çš„å¯¹åº”åç§»é‡ã€‚ è®¡ç®—æ“ä½œï¼š struct ggml_tensor * c = ggml_add(ctx, a, b); æ‰§è¡Œè®¡ç®—å›¾ï¼š struct ggml_cgraph graph = ggml_build_forward(c);ggml_graph_compute_with_ctx(ctx, graph, n_threads); ä¸‹è¾¹å°çº¢ä¹¦åšä¸»**TransormerX**ç»˜åˆ¶çš„è¿™å‡ å¼ å›¾ æ¸…æ™° ç¾è§‚çš„å±•ç¤ºäº†å†…å­˜åˆ†é…æƒ…å†µï¼š .fqfbycwpbnru{zoom:80%;} .dqvigblpekab{zoom:67%;} .bwqcknrglpxo{zoom:50%;} é™¤äº†å›¾ä¸­ç»˜åˆ¶çš„tensoræ˜¯æŒ‰ç…§è¿™æ ·çš„å†…å­˜åˆ†å¸ƒä»¥å¤–ï¼Œå…¶ä»–ç±»å‹graphã€workbufferç­‰ç±»å‹çš„objectéƒ½æ˜¯é‡‡ç”¨è¿™æ ·çš„å†…å­˜æ’å¸ƒï¼Œå³ï¼šobjectç»“æ„ä½“-å¯¹åº”ç±»å‹ç»“æ„ä½“ï¼ˆtensor\\graph)-ç›¸åº”data æ¯”å¦‚å›¾çš„å­˜å‚¨å°±æ˜¯object-ggml_cgraph(ç»“æ„ä½“æœ¬èº«)-èŠ‚ç‚¹å¶å­ç­‰æŒ‡é’ˆæ•°ç»„ WORK_BUFFERå°±æ˜¯objectâ€“work_data ï¼ˆç›´æ¥è¢«cplanä¸­çš„æŒ‡é’ˆæ‰€æŒ‡ï¼‰ 1.2ggml_stateæ•´ä¸ªggmlç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­æœ‰ä¸€ä¸ªå…¨å±€çš„g_state. static struct ggml_state g_state;#define GGML_MAX_CONTEXTS 64struct ggml_state struct ggml_context_container contexts[GGML_MAX_CONTEXTS]; struct ggml_numa_nodes numa;;struct ggml_context_container bool used; struct ggml_context context;;struct ggml_numa_nodes enum ggml_numa_strategy numa_strategy; struct ggml_numa_node nodes[GGML_NUMA_MAX_NODES]; uint32_t n_nodes; uint32_t total_cpus; // hardware threads on system uint32_t current_node; // node on which main process is execting#if defined(__gnu_linux__) cpu_set_t cpuset; // cpuset from numactl#else uint32_t cpuset; // no NUMA support outside of Linux at this time. Use a portable datatype#endif; ggml_stateä¸­åŒ…å«äº†ä¸€ä¸ªggml_contextï¼ˆé¢å¤–åŠ ä¸€ä¸ªusedæ ‡è¯†è€Œå·²ï¼‰æ•°ç»„ã€‚ åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨ggml_initæ—¶ï¼Œä¼šå¯¹g_stateè¿›è¡Œåˆå§‹åŒ–ã€‚ //ä½äºggml.c/ggml_initif (is_first_call) //.....åˆå§‹åŒ–æ¿€æ´»å‡½æ•°è¡¨ //åˆå§‹åŒ–g_state g_state = (struct ggml_state) /*.contexts =*/ 0 , /*.numa =*/ .n_nodes = 0, .total_cpus = 0, , ; for (int i = 0; i GGML_MAX_CONTEXTS; ++i) g_state.contexts[i].used = false; äºæ˜¯å¯ä»¥ç†è§£åˆ°ï¼Œç¨‹åºè¿è¡Œæ—¶ï¼Œä¼šåœ¨å…¨å±€é™æ€å†…å­˜åŒºåˆ†é…ä¸€ä¸ªg_state,åŒ…å«äº†ä¸€ä¸ªg_contextæ•°ç»„ï¼Œæ¯æ¬¡ggml_initçš„æ—¶å€™å°±å»g_stateä¸­æ‰¾ä¸€ä¸ªæ²¡æœ‰ä½¿ç”¨çš„g_context,è·å¾—å…¶æŒ‡é’ˆåè¿›è¡Œæ¯ä¸ªå­—æ®µçš„åˆå§‹åŒ–ä»¥åŠå¡«å……ï¼Œä¹‹åå°±ä¾é è¿™ä¸ªggml_contextè¿›è¡Œä¸€æ¬¡ä¸€æ¬¡ã€‚ ç›®å‰ä¸ªäººçœ‹ä»£ç è§‰å¾—æ¯æ¬¡æ¨¡å‹æ‰§è¡Œåªéœ€è¦ä¸€ä¸ªggml_conterxtï¼Œä½†æ˜¯ç»™äº†ä¸€ä¸ª64ä¸ªggml_contextç»„æˆçš„æ•°ç»„ï¼Œæ˜¯å› ä¸ºå¯èƒ½éœ€è¦æ”¯æŒæ¨¡å‹çš„å¹¶è¡Œï¼ˆè¿™ä¸ªè§‚ç‚¹å‚è€ƒGPTï¼‰ 1.3ggml_tensor// n-dimensional tensor struct ggml_tensor enum ggml_type type; //æ•°æ®ç±»å‹ GGML_DEPRECATED(enum ggml_backend_type backend, use the buffer type to find the storage location of the tensor); struct ggml_backend_buffer * buffer;//ä¸€ä¸ªè¡¨ç¤ºæ•°æ®å®é™…å­˜å‚¨çš„å†…å­˜åç«¯ï¼Œå¤šæ€å®ç°ï¼Œä¸€ä¸ªé‡è¦çš„ç»“æ„ä½“ int64_t ne[GGML_MAX_DIMS]; // number of elements//æ¯ä¸€ç»´çš„å…ƒç´ ä¸ªæ•° size_t nb[GGML_MAX_DIMS]; // stride in bytes: //æ¯ä¸€ä½èµ°åˆ°ä¸‹ä¸€ä¸ªå…ƒç´ çš„å­—èŠ‚æ•° // nb[0] = ggml_type_size(type) // nb[1] = nb[0] * (ne[0] / ggml_blck_size(type)) + padding // nb[i] = nb[i-1] * ne[i-1] // compute data enum ggml_op op;//è¿™ä¸ªtensoræ˜¯é€šè¿‡ä»€ä¹ˆæ“ä½œè®¡ç®—å¾—åˆ°çš„ // op params - allocated as int32_t for alignment int32_t op_params[GGML_MAX_OP_PARAMS / sizeof(int32_t)]; //å­˜å‚¨å½“å‰opçš„å‚æ•°op = CONV2D æ—¶ï¼Œå¯èƒ½å­˜å‚¨ kernel sizeã€stride int32_t flags; struct ggml_tensor * grad; //å¦‚æœå½“å‰å¼ é‡æ”¯æŒåå‘ä¼ æ’­ï¼Œåˆ™å­˜å‚¨æ¢¯åº¦å¼ é‡ struct ggml_tensor * src[GGML_MAX_SRC]; //å½“å‰å¼ é‡æ˜¯æŸä¸ªå¼ é‡çš„è¿ç®—ç»“æœï¼Œåˆ™è®°å½•è¾“å…¥å¼ é‡ // source tensor and offset for views struct ggml_tensor * view_src; size_t view_offs; void * data;//å®é™…å¼ é‡çš„æ•°æ®æŒ‡é’ˆï¼Œé€šå¸¸æŒ‡å‘ggml_context char name[GGML_MAX_NAME]; void * extra; // extra things e.g. for ggml-cuda.cu // char padding[4]; ; è¿™é‡Œæœ‰ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„æ¦‚å¿µæ˜¯view,viewä¸ä¼šä¿¡åˆ†é…å†…å­˜ã€‚ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼šå¦‚æœä¸€ä¸ªçŸ­å‘é‡æ˜¯ä¸€ä¸ªé•¿å‘é‡çš„å­å‘é‡ï¼Œå¯ä»¥ç†è§£ä¸ºçŸ­å‘é‡æ˜¯é•¿å‘é‡çš„å­å‘é‡ï¼Œä¹Ÿå°±æ˜¯é•¿å‘é‡çš„è§†å›¾ï¼Œåˆ†é…çŸ­å‘é‡æ—¶ï¼Œå¯ä»¥åˆ©ç”¨é•¿å‘é‡å·²ç»åˆ†é…çš„å†…å­˜ï¼Œä»è€Œé¿å…äº†å†…å­˜çš„åˆ†é…ã€‚ 1.4 ggml_cgraphstruct ggml_cgraph int size; int n_nodes;//èŠ‚ç‚¹ int n_leafs;//å¶å­èŠ‚ç‚¹æ•° struct ggml_tensor ** nodes;//ä¸­é—´èŠ‚ç‚¹æ•° struct ggml_tensor ** grads; struct ggml_tensor ** leafs;//å¶å­èŠ‚ç‚¹ struct ggml_hash_set visited_hash_set;//åå‘æ„å»ºä¸­ hashå»é‡ enum ggml_cgraph_eval_order order; ; 2.æ ¸å¿ƒæ“ä½œ2.1æ¨¡å‹åŠ è½½ggufç»“æ„ä¸è§£æggufå®šä¹‰äº†æ¨¡å‹çš„æƒé‡ä¿å­˜æ–¹å¼ï¼Œä»¥ä¸‹ä¸ºggufçš„ç»“æ„ ä¸»è¦å¯ä»¥åˆ†ä¸ºä»¥ä¸‹4éƒ¨åˆ†ï¼š 1.header åŒ…å«æ¨¡å¼ï¼Œtensoræ•°é‡ã€kvå…ƒæ•°æ®æ•°ã€ç‰ˆæœ¬ç­‰ 2.æ¨¡å‹å…ƒæ•°æ®ï¼ˆKVè¡¨ç¤ºï¼‰ 3.æ¯ä¸ªtensorçš„ä¿¡æ¯ï¼ˆoffsetç­‰ï¼Œä¸åŒ…å«tensorçš„å€¼ï¼‰ 4.tensorçš„å€¼ æ–‡ä»¶ggml.cä¸­ï¼Œå®šä¹‰äº†ggufç›¸å…³çš„ç»“æ„ä½“ï¼Œå…¶ä¸­gguf_contextå¯¹åº”äºä¸€ä¸ªæ–‡ä»¶ï¼ŒåŒ…å«headerã€kvã€tensor_infoç­‰ union gguf_value uint8_t uint8; int8_t int8; uint16_t uint16; int16_t int16; uint32_t uint32; int32_t int32; float float32; uint64_t uint64; int64_t int64; double float64; bool bool_; struct gguf_str str; struct enum gguf_type type; uint64_t n; // GGUFv2 void * data; arr;;struct gguf_kv struct gguf_str key; enum gguf_type type; union gguf_value value;;struct gguf_header char magic[4]; uint32_t version; uint64_t n_tensors; // GGUFv2 uint64_t n_kv; // GGUFv2;struct gguf_tensor_info struct gguf_str name; uint32_t n_dims; uint64_t ne[GGML_MAX_DIMS]; enum ggml_type type; uint64_t offset; // offset from start of `data`, must be a multiple of `ALIGNMENT` // for writing API const void * data; size_t size;;struct gguf_context struct gguf_header header; struct gguf_kv * kv; struct gguf_tensor_info * infos; size_t alignment; size_t offset; // offset of `data` from beginning of file size_t size; // size of `data` in bytes //uint8_t * padding; void * data;; ggml.c/gguf_init_from_fileå®ç°äº†ä»æ–‡ä»¶åŠ è½½æ¨¡å‹åˆ°ç»“æ„ä½“ä¸­ 2.2è®¡ç®—å›¾ï¼ˆå‰å‘å›¾ï¼‰æ„å»ºä»¥simple-ctxä¸ºä¾‹è¯´æ˜è®¡ç®—å›¾æ„å»ºæµç¨‹ struct ggml_cgraph * build_graph(const simple_model model) struct ggml_cgraph * gf = ggml_new_graph(model.ctx); // result = a*b^T struct ggml_tensor * result = ggml_mul_mat(model.ctx, model.a, model.b); ggml_build_forward_expand(gf, result); return gf;struct ggml_tensor * ggml_mul_mat( struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b) GGML_ASSERT(ggml_can_mul_mat(a, b)); GGML_ASSERT(!ggml_is_transposed(a)); bool is_node = false; if (a-grad || b-grad) is_node = true; const int64_t ne[4] = a-ne[1], b-ne[1], b-ne[2], b-ne[3] ; struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, 4, ne); result-op = GGML_OP_MUL_MAT; result-grad = is_node ? ggml_dup_tensor(ctx, result) : NULL; result-src[0] = a; result-src[1] = b; return result; ggml_new_graphä¼šåœ¨ggml-contxtä¸­ç›¸å…³çš„å†…å­˜åŒºåŸŸåˆ†é…ggml_cgraphçš„å†…å­˜ï¼Œè¿›è¡Œåˆå§‹åŒ–ï¼› è€Œåè¿›è¡Œå®é™…çš„ç®—å­æ„å»ºï¼Œè¿™ä¸ªè¿‡ç¨‹æ¯ä¸€æ­¥å¾—åˆ°çš„è¾“å‡ºå¼ é‡ä¼šè®°å½•å¯¹åº”çš„è¾“å…¥ã€ä»¥åŠæ“ä½œç±»å‹ï¼Œå‚ç…§ä¸Šè¾¹çš„ggml_tensorçš„æ•°æ®ç»“æ„ æœ€åæ ¸å¿ƒçš„å‡½æ•°æ˜¯ggml_build_forward_expandï¼Œè¿™ä¸ªè¿‡ç¨‹æ ¹æ®è¾“å‡ºçš„tensorï¼Œåå‘æ·»åŠ graphä¸­çš„è®¡ç®—èŠ‚ç‚¹ã€‚ å³æµç¨‹ä¸ºæ‰‹åŠ¨è®¾ç½®æœ€ç»ˆè¾“å‡ºtensorçš„è¿‡ç¨‹ï¼Œåˆ©ç”¨tensorä¸­çš„å˜é‡åå‘æ„å»ºé™æ€è¾“å‡ºå›¾ï¼ŒæˆåŠŸåœ¨graphä¸­æ·»åŠ ä¸åŒçš„èŠ‚ç‚¹ï¼Œå®Œæˆgraphçš„ç»´æŠ¤ å…·ä½“æ„å»ºè¿‡ç¨‹è§ï¼šggml.c/ggml_visit_parentsç®€è¨€ä¹‹å°±æ˜¯ååºéå†+hashå»é‡ï¼Œå¡«å……cgraphä¸­çš„ç›¸å…³æŒ‡é’ˆ static void ggml_visit_parents(struct ggml_cgraph * cgraph, struct ggml_tensor * node) if (node-grad == NULL) // this usually happens when we generate intermediate nodes from constants in the backward pass // it can also happen during forward pass, if the user performs computations with constants if (node-op != GGML_OP_NONE) //GGML_PRINT_DEBUG(%s: warning: node %p has no grad, but op %d , __func__, (void *) node, node-op); // check if already visited if (ggml_hash_insert(cgraph-visited_hash_set, node) == GGML_HASHSET_ALREADY_EXISTS) return; for (int i = 0; i GGML_MAX_SRC; ++i) const int k = (cgraph-order == GGML_CGRAPH_EVAL_ORDER_LEFT_TO_RIGHT) ? i : (cgraph-order == GGML_CGRAPH_EVAL_ORDER_RIGHT_TO_LEFT) ? (GGML_MAX_SRC-1-i) : /* unknown order, just fall back to using i*/ i; if (node-src[k]) ggml_visit_parents(cgraph, node-src[k]); if (node-op == GGML_OP_NONE node-grad == NULL) // reached a leaf node, not part of the gradient graph (e.g. a constant) GGML_ASSERT(cgraph-n_leafs cgraph-size); if (strlen(node-name) == 0) ggml_format_name(node, leaf_%d, cgraph-n_leafs); cgraph-leafs[cgraph-n_leafs] = node; cgraph-n_leafs++; else GGML_ASSERT(cgraph-n_nodes cgraph-size); if (strlen(node-name) == 0) ggml_format_name(node, node_%d, cgraph-n_nodes); cgraph-nodes[cgraph-n_nodes] = node; if (cgraph-grads) cgraph-grads[cgraph-n_nodes] = node-grad; cgraph-n_nodes++; åå‘å›¾çš„æ„å»ºè¿‡ç¨‹æ›´åŠ å¤æ‚ä¸€äº›ï¼Œä¼šåŒæ—¶ä¿å­˜ç›¸å…³çš„æ¢¯åº¦ä¿¡æ¯ã€‚ åå‘å›¾çš„æ„å»ºä¾èµ–å‰å‘å›¾ï¼Œåå‘å›¾é æ‹·è´äº†å‰å‘è®¡ç®—å›¾ï¼Œ 2.3è®¡ç®—æ ¸å¿ƒå‡½æ•° enum ggml_status ggml_graph_compute_with_ctx(struct ggml_context * ctx, struct ggml_cgraph * cgraph, int n_threads) struct ggml_cplan cplan = ggml_graph_plan(cgraph, n_threads, NULL); struct ggml_object * obj = ggml_new_object(ctx, GGML_OBJECT_TYPE_WORK_BUFFER, cplan.work_size); cplan.work_data = (uint8_t *)ctx-mem_buffer + obj-offs; return ggml_graph_compute(cgraph, cplan); ä¸»è¦æ­¥éª¤ä¸ºï¼Œ 1.æ„å»ºæ‰§è¡Œè®¡åˆ’ggml_graph_plan,ç”Ÿæˆæ‰§è¡Œé¡ºåºå’Œä»»åŠ¡è®¡åˆ’ã€æ‰€æœ‰ç®—å­ä¸­çš„é¢„è®¡åˆ†é…å†…å­˜å¤§å°ã€çº¿ç¨‹æ•°é‡ã€‚çº¿ç¨‹åˆ†é…æ•°é‡ç”±ggml_get_n_tasksä¸­çš„ä¸€ä¸ªswitch caseå†³å®šã€‚å…¶ä¸­æœ‰ä¸€æ®µwork_size += CACHE_LINE_SIZE * n_threads;çš„ä»£ç æ˜¯é¿å…å¤šä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ä¸ªç¼“å­˜å’Œï¼Œé€ æˆä¼ªå…±äº«ã€‚ä¸€äº›å¯ä»¥è¢«å¤šçº¿ç¨‹æ‰§è¡Œçš„ç®—å­è®¡ç®—é¢„è®¡å†…å­˜åˆ†é…çš„æ—¶å€™è¿˜ä¼šä¹˜ä»¥çº¿ç¨‹æ•°ï¼Œä¿è¯ä¸ä¼šå¯¼è‡´é¢å¤–çš„å†…å­˜åŒæ­¥å¼€é”€ã€‚ 2.ggml_new_objectç”Ÿæˆä»»åŠ¡ç¼“å†²åŒº,ggml_contextä¸­ ã€‚ 3.æ‰§è¡Œè®¡ç®—å›¾ggml_graph_compute ggml_graph_compute æ‰§è¡Œggml_graph_computeæ—¶ï¼Œé¦–å…ˆåˆå§‹åŒ–æˆ–è€…è®¾ç½®ggml_threadpoolä¸­çš„ç›¸å…³å‚æ•°ï¼ŒåŒ…æ‹¬cplanç­‰ åªæœ‰è°ƒç”¨ggml_graph_compute_threadè¿›è¡Œå¤šçº¿ç¨‹å¤„ç†ï¼Œå¯ç”¨ompè¿›è¡Œå¤šçº¿ç¨‹å¤„ç†ï¼Œå¦åˆ™å•çº¿ç¨‹ å…¶ä¸­éå†cgraphä¸­çš„æ¯ä¸ªç®—å­èŠ‚ç‚¹ï¼Œé€šè¿‡ggml_compute_forwardè½¬å‘åˆ°ä¸åŒçš„ç®—å­è¿›è¡Œè®¡ç®—ï¼Œæ¯ä¸ªç®—å­å†…éƒ¨åŒºåˆ†ä¸åŒçš„ç²¾è¯»ï¼Œè½¬å‘åˆ°ä¸åŒçš„ç²¾åº¦å¤„ç†å‡½æ•°ï¼Œæœ€åä¸åŒçš„ç²¾åº¦è®¡ç®—ç®—å­å‡½æ•° é€šè¿‡ith thè€ƒè™‘çº¿ç¨‹åˆ†é…ï¼Œå†…å­˜å­˜å– å°†çº¿ç¨‹åˆ’åˆ†è®¡ç®—çš„æƒåˆ©äº¤ç»™äº†ç®—å­è‡ªèº«æ¥æ‰§è¡Œã€‚ ä¾‹å¦‚ä»¥f16_addä¸ºä¾‹,é€šè¿‡ithåˆ’åˆ†ä¸¾è¯çš„è¡Œå’Œåˆ—ï¼Œæ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸åŒçš„å°çŸ©é˜µï¼Œå®ç°å¹¶è¡ŒåŒ–ã€‚ static void ggml_compute_forward_add_f16_f16( const struct ggml_compute_params * params, struct ggml_tensor * dst) const struct ggml_tensor * src0 = dst-src[0]; const struct ggml_tensor * src1 = dst-src[1]; GGML_ASSERT(ggml_are_same_shape(src0, src1) ggml_are_same_shape(src0, dst)); const int ith = params-ith; const int nth = params-nth; const int nr = ggml_nrows(src0); GGML_TENSOR_BINARY_OP_LOCALS GGML_ASSERT(src0-type == GGML_TYPE_F16); GGML_ASSERT(src1-type == GGML_TYPE_F16); GGML_ASSERT(dst-type == GGML_TYPE_F16); GGML_ASSERT( nb0 == sizeof(ggml_fp16_t)); GGML_ASSERT(nb00 == sizeof(ggml_fp16_t)); // rows per thread const int dr = (nr + nth - 1)/nth; // row range for this thread const int ir0 = dr*ith; const int ir1 = MIN(ir0 + dr, nr); if (nb10 == sizeof(ggml_fp16_t)) for (int ir = ir0; ir ir1; ++ir) // src0, src1 and dst are same shape = same indices const int i3 = ir/(ne2*ne1); const int i2 = (ir - i3*ne2*ne1)/ne1; const int i1 = (ir - i3*ne2*ne1 - i2*ne1); ggml_fp16_t * dst_ptr = (ggml_fp16_t *) ((char *) dst-data + i3*nb3 + i2*nb2 + i1*nb1); ggml_fp16_t * src0_ptr = (ggml_fp16_t *) ((char *) src0-data + i3*nb03 + i2*nb02 + i1*nb01); ggml_fp16_t * src1_ptr = (ggml_fp16_t *) ((char *) src1-data + i3*nb13 + i2*nb12 + i1*nb11); for (int i = 0; i ne0; i++) dst_ptr[i] = GGML_FP32_TO_FP16(GGML_FP16_TO_FP32(src0_ptr[i]) + GGML_FP16_TO_FP32(src1_ptr[i])); else // src1 is not contiguous GGML_ABORT(fatal error); 3.åç«¯å®ç°å¿«é€Ÿå…¥é—¨æŠ€å·§ï¼š ç”¨é¢å‘å¯¹è±¡æ€æƒ³æ¥é˜…è¯»ï¼ 3.1ç›¸å…³æ•°æ®ç»“æ„ggml_backendæŸ¥çœ‹examplesimpleä»£ç æ—¶ï¼Œåç«¯çš„æ¨¡å‹ä¸­å¢åŠ äº†ä¸€ä¸ªggml_backendç»“æ„ã€‚ ggml_backendå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªè®¾å¤‡ç®¡ç†å™¨ struct ggml_backend ggml_guid_t guid;//ç”¨äºå”¯ä¸€æ ‡è¯† backend å®ä¾‹ï¼Œä¾¿äºæ³¨å†Œã€æŸ¥æ‰¾æˆ–è°ƒè¯•ã€‚ struct ggml_backend_i iface;//å®šä¹‰åç«¯è¡Œä¸ºçš„å‡½æ•°è™šè¡¨ï¼ŒåŒ…å«åç«¯è¡Œä¸ºçš„å‡½æ•°æŒ‡é’ˆ ggml_backend_context_t context;//void *ï¼Œå…·ä½“å†…å®¹ä¾èµ–åç«¯å®ç°; ggml_backend_bufferstruct ggml_backend_buffer struct ggml_backend_buffer_i iface; ggml_backend_buffer_type_t buft; ggml_backend_buffer_context_t context; size_t size; enum ggml_backend_buffer_usage usage; ; åˆåŒ…å«äº†ggml_backend_buffer_type struct ggml_backend_buffer_type struct ggml_backend_buffer_type_i iface; ggml_backend_buffer_type_context_t context; ; è¿™é‡Œç»“æ„ä½“æ¯”è¾ƒå¤šï¼Œçœ‹èµ·æ¥æ¯”è¾ƒå¤æ‚ï¼Œç”¨è¿™ç¯‡åšå®¢ä¸­çš„å›¾ç‰‡æè¿°æ˜¯è¿™æ ·çš„ .gqofjebghtjg{zoom: 80%;} ä½†æ˜¯å¦‚æœç”¨é¢å‘å¯¹è±¡çš„æ€æƒ³æ¥ç†è§£ï¼Œä¸€åˆ‡éƒ½å¾ˆç®€å•ã€‚ æœ€å¼€å§‹çš„åˆè¡·æ˜¯æœ‰ä¸€ä¸ªåç«¯åŸºç±»ï¼Œä¸åŒç±»å‹çš„åç«¯åŸºäºæ­¤æ´¾ç”Ÿï¼Œè€Œåç«¯åŒ…å«æœ‰ä¸åŒçš„bufferï¼Œå› æ­¤åˆ›å»ºäº†åç«¯bufferä¸€ç»„åŸºç±»ï¼Œå¹¶ä½œä¸ºåç«¯åŸºç±»çš„æˆå‘˜å˜é‡ï¼Œç›¸åŒçš„æ–¹å¼æœ‰äº†åç«¯buffer-typeç±» ä¸åŒçš„åç«¯æœ‰ä¸åŒçš„æˆå‘˜å˜é‡ï¼Œä¹Ÿå°±æ˜¯ctxï¼Œé€šè¿‡void*å®ç° 3.2CPUåç«¯ç¤ºä¾‹è®²è§£load modelåŠ è½½æ¨¡å‹ä¹‹å‰å…ˆæ ¹æ®ä¸åŒçš„å®å¯ç”¨ä¸åŒçš„åç«¯åˆå§‹åŒ–å‡½æ•°ï¼Œ ä¹‹ååˆ›å»ºå¯¹åº”çš„ggml_contxtï¼Œ åˆ›å»ºå‘é‡æ—¶ï¼Œé¦–å…ˆä¼šå°†å‘é‡å­˜å‚¨åœ¨CPUï¼Œ ä¹‹åé€šè¿‡ggml_backend_alloc_ctx_tensors åˆ›å»ºå¯¹åº”çš„åç«¯buffer,ç„¶åé€šè¿‡ggml_backend_tensor_setå°†å‘é‡ä»CPUå†…å­˜æ¬åˆ°åç«¯å†…å­˜ void load_model(simple_model model, float * a, float * b, int rows_A, int cols_A, int rows_B, int cols_B) // initialize the backend#ifdef GGML_USE_CUDA fprintf(stderr, %s: using CUDA backend , __func__); model.backend = ggml_backend_cuda_init(0); // init device 0 if (!model.backend) fprintf(stderr, %s: ggml_backend_cuda_init() failed , __func__); #endif#ifdef GGML_USE_METAL fprintf(stderr, %s: using Metal backend , __func__); ggml_backend_metal_log_set_callback(ggml_log_callback_default, nullptr); model.backend = ggml_backend_metal_init(); if (!model.backend) fprintf(stderr, %s: ggml_backend_metal_init() failed , __func__); #endif // if there arent GPU Backends fallback to CPU backend if (!model.backend) model.backend = ggml_backend_cpu_init(); int num_tensors = 2; struct ggml_init_params params /*.mem_size =*/ ggml_tensor_overhead() * num_tensors, /*.mem_buffer =*/ NULL, /*.no_alloc =*/ true, ; // create context model.ctx = ggml_init(params); // create tensors model.a = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, cols_A, rows_A); model.b = ggml_new_tensor_2d(model.ctx, GGML_TYPE_F32, cols_B, rows_B); // create a backend buffer (backend memory) and alloc the tensors from the context model.buffer = ggml_backend_alloc_ctx_tensors(model.ctx, model.backend); // load data from cpu memory to backend buffer ggml_backend_tensor_set(model.a, a, 0, ggml_nbytes(model.a)); ggml_backend_tensor_set(model.b, b, 0, ggml_nbytes(model.b)); ggml_backend_cpu_init ggml_backend_cpu_init XXX_backend_cpu_initè´Ÿè´£åˆ›å»ºå¯¹åº”çš„ggml_backend_tç»“æ„ä½“ å¯ä»¥çœ‹åˆ°ç»“æ„ä½“ä¸­çš„ctxæ˜¯æ¯ä¸ªåç«¯æœ‰ä¸€ä¸ªè‡ªå·±çš„ç»“æ„ä½“ è™šå‡½æ•°è¡¨interfaceæ˜¯å…¨å±€å®šä¹‰äº†æ¯ä¸ªåç«¯çš„è¡¨ï¼Œå¦‚cpu_backend_i ggml_backend_t ggml_backend_cpu_init(void) struct ggml_backend_cpu_context * ctx = malloc(sizeof(struct ggml_backend_cpu_context)); if (ctx == NULL) return NULL; ctx-n_threads = GGML_DEFAULT_N_THREADS; ctx-threadpool = NULL; ctx-work_data = NULL; ctx-work_size = 0; ctx-abort_callback = NULL; ctx-abort_callback_data = NULL; ggml_backend_t cpu_backend = malloc(sizeof(struct ggml_backend)); if (cpu_backend == NULL) free(ctx); return NULL; *cpu_backend = (struct ggml_backend) /* .guid = */ ggml_backend_cpu_guid(), /* .interface = */ cpu_backend_i, /* .context = */ ctx ; return cpu_backend;static struct ggml_backend_i cpu_backend_i = /* .get_name = */ ggml_backend_cpu_name, /* .free = */ ggml_backend_cpu_free, /* .get_default_buffer_type = */ ggml_backend_cpu_get_default_buffer_type, /* .set_tensor_async = */ NULL, /* .get_tensor_async = */ NULL, /* .cpy_tensor_async = */ NULL, /* .synchronize = */ NULL, /* .graph_plan_create = */ ggml_backend_cpu_graph_plan_create, /* .graph_plan_free = */ ggml_backend_cpu_graph_plan_free, /* .graph_plan_update = */ NULL, /* .graph_plan_compute = */ ggml_backend_cpu_graph_plan_compute, /* .graph_compute = */ ggml_backend_cpu_graph_compute, /* .supports_op = */ ggml_backend_cpu_supports_op, /* .supports_buft = */ ggml_backend_cpu_supports_buft, /* .offload_op = */ NULL, /* .event_new = */ NULL, /* .event_free = */ NULL, /* .event_record = */ NULL, /* .event_wait = */ NULL, /* .event_synchronize = */ NULL,; ggml_backend_alloc_ctx_tensors æ ¸å¿ƒä»£ç alloc_tensor_rangeæœ¬è´¨å°±æ˜¯æ„é€ å‡½æ•° ggml_backend_buffer_t ggml_backend_alloc_ctx_tensors(struct ggml_context * ctx, ggml_backend_t backend) return ggml_backend_alloc_ctx_tensors_from_buft(ctx, ggml_backend_get_default_buffer_type(backend));ggml_backend_buffer_t ggml_backend_alloc_ctx_tensors_from_buft(struct ggml_context * ctx, ggml_backend_buffer_type_t buft) GGML_ASSERT(ggml_get_no_alloc(ctx) == true); size_t alignment = ggml_backend_buft_get_alignment(buft); size_t max_size = ggml_backend_buft_get_max_size(buft); ggml_backend_buffer_t * buffers = NULL; size_t n_buffers = 0; size_t cur_buf_size = 0; struct ggml_tensor * first = ggml_get_first_tensor(ctx); for (struct ggml_tensor * t = first; t != NULL; t = ggml_get_next_tensor(ctx, t)) size_t this_size = 0; if (t-data == NULL t-view_src == NULL) this_size = GGML_PAD(ggml_backend_buft_get_alloc_size(buft, t), alignment); if (this_size max_size) fprintf(stderr, %s: tensor %s is too large to fit in a %s buffer (tensor size: %zu, max buffer size: %zu) , __func__, t-name, ggml_backend_buft_name(buft), this_size, max_size); for (size_t i = 0; i n_buffers; i++) ggml_backend_buffer_free(buffers[i]); free(buffers); return NULL; if ((cur_buf_size + this_size) max_size) // allocate tensors in the current buffer if (!alloc_tensor_range(ctx, first, t, buft, cur_buf_size, buffers, n_buffers)) return NULL; first = t; cur_buf_size = this_size; else cur_buf_size += this_size; // allocate remaining tensors if (cur_buf_size 0) if (!alloc_tensor_range(ctx, first, NULL, buft, cur_buf_size, buffers, n_buffers)) return NULL; if (n_buffers == 0) #ifndef NDEBUG fprintf(stderr, %s: all tensors in the context are already allocated , __func__);#endif return NULL; ggml_backend_buffer_t buffer; if (n_buffers == 1) buffer = buffers[0]; else buffer = ggml_backend_multi_buffer_alloc_buffer(buffers, n_buffers); free(buffers); return buffer; æ€»ç»“1.ggmlä¸­åˆ†æ˜å¾ˆå¤šåœ°æ–¹éƒ½æ˜¯é¢å‘å¯¹è±¡çš„æ€æƒ³å†™çš„ï¼Œä½†æ˜¯ä¸ºä»€ä¹ˆä¼šç”¨Cè¯­è¨€å†™å‘¢ï¼Ÿ æ›´åŠ ç¨³å®šçš„ABIï¼Œä¸å’Œç¼–è¯‘å™¨å¼ºç›¸å…³ é›¶ä¾èµ–ï¼Œè½»é‡åŒ– æ²¡æœ‰è¿è¡Œæ—¶ï¼Œæ‰‹åŠ¨æ§åˆ¶å†…å­˜æ›´æ–¹ä¾¿","tags":["LLM/ggml"],"categories":["æºç è§£æ/å¤§æ¨¡å‹"]},{"title":"å‡ ç§ç¨‹åºæ¥å£é‡å®šå‘ã€æ’æ¡©æ–¹å¼æ¯”è¾ƒ","path":"/2025/07/29/å‡ ç§ç¨‹åºæ¥å£é‡å®šå‘ã€æ’æ¡©æ–¹å¼æ¯”è¾ƒ/","content":"æœ€è¿‘åœ¨å®éªŒä¸­éœ€è¦åˆ†æç¨‹åºä¸­çš„å †å˜é‡å†…å­˜åˆ†é…æƒ…å†µï¼Œä¸€å¼€å§‹è‡ªå·±çš„å®ç°æ˜¯é‡‡ç”¨llvm IR Passä¿®æ”¹çš„æ–¹å¼ï¼Œåæ¥åœ¨OSDIçš„è®ºæ–‡ä¸­å‘ç°ç›¸å…³çš„æ–¹æ³•é‡‡ç”¨çš„æ˜¯LD_PRELOADçš„æ–¹å¼å®ç°ï¼Œä¸€å¼€å§‹è®¤ä¸ºè¿™ç§æ–¹æ³•ä¼šæ›´åŠ ç®€å•ï¼Œäºæ˜¯è¿›è¡Œäº†å®ç°ï¼Œç»“æœå‘ç°å„æœ‰ç‰¹ç‚¹ã€‚ 1. LLVM IR æ–¹å¼2. LD_PRELOADæ–¹å¼ä»£ç  LD_PRELOADçš„å…¨è¿›ç¨‹çº§åˆ«ï¼šLD_PRELOADæ˜¯åŸºäºå…¨è¿›ç¨‹çº§åˆ«çš„åŠ¨æ€é“¾æ¥ç¬¦å·é‡å®šå‘ã€‚ å¯åŠ¨åŠ è½½æ—¶åŠ è½½æŒ‡å®šçš„.soæ–‡ä»¶ï¼Œç„¶ååç»­æ‰€æœ‰çš„è°ƒç”¨éƒ½ä¼šä½¿ç”¨soæ–‡ä»¶ä¸­æä¾›çš„å®ç°ï¼Œè¿™åŒ…æ‹¬å¼•ç”¨ç¨‹åºä»£ç ã€ç¬¬ä¸‰æ–¹åº“ã€libc æ¯”å¦‚ï¼šé‡å®šå‘äº†ä¸€ä¸ªmallocï¼Œè®°å½•ç¨‹åºä¸­çš„mallocåœ°å€ç„¶åä½¿ç”¨LD_PRELOADçš„æ–¹å¼è¿›è¡Œé‡å®šå‘ã€‚ #include stdio.h#include stdlib.hint main() void* p = malloc(64); // printf(p: %p , p); free(p); return 0; ç†è®ºä»¥ä¸Šä»£ç å€¼è°ƒç”¨ä¸€ä¸ªmalloc,ä½†æ˜¯æ‹¦æˆªé‡å®šå‘ä»¥åå‘ç°æœ‰3ä¸ªmalloc,ä¸æ³¨é‡Šä»£ç ä¸­çš„printfå‡½æ•°ï¼Œè¿˜ä¼šå¤šå‡ºä¸€ä¸ªmallocã€‚ è¿™æ ·çš„å…¨è¿›ç¨‹çº§åˆ«ç‰¹æ€§å¯ä»¥é‡‡é›†åˆ°lib cæœ¬èº«çš„ç‰¹æ€§ï¼Œä½†æ˜¯ä¹Ÿå¯èƒ½ä¼šå¯¹ç¨‹åºåˆ†æä¸å¿…è¦çš„éº»çƒ¦ï¼Œæ¯”å¦‚æˆ‘æœ¬èº«åªæƒ³åˆ†æåº”ç”¨ç¨‹åºçº§åˆ«çš„äº‹åŠ¡ï¼Œå®ç°ç¨‹åºä»£ç ä¸­çš„è¿‡æ»¤å¯ä»¥é€šè¿‡è°ƒç”¨æ ˆè¿‡æ»¤ç­‰æ–¹å¼å®ç°ã€‚","tags":["LD_PRELOAD","LLVM","PIN"]},{"title":"è®ºæ–‡ä¸­å¸¸è§å†…å­˜æ€§èƒ½åˆ†æworkloads","path":"/2025/07/27/è®ºæ–‡ä¸­å¸¸è§å†…å­˜æ€§èƒ½åˆ†æworkloads/","content":"ä¸€ã€åˆ†ç±»è¯´æ˜æ•´ç†æ‰€è¯»åˆ°è®ºæ–‡ä¸­ç»å¸¸ä½¿ç”¨çš„å†…å­˜åˆ†æå·¥ä½œè´Ÿè½½ã€‚ æŒ‰ç…§ç‰¹ç‚¹å¯ä»¥åˆ†ä¸ºå»¶è¿Ÿæ•æ„Ÿå‹ã€å¸¦å®½å¯†é›†å‹ï¼›æŒ‰ç…§ä½œç”¨å¯ä»¥åˆ†ä¸ºAIã€HPCã€Databaseç­‰ åšå®¢ç”¨äºå†…å­˜æ€§èƒ½è¯„ä¼°çš„workloadä¸­æ•´ç†äº†å¸¸è§çš„workloads,ä½†æ˜¯ä¸»è¦è¿˜æ˜¯é‡åœ¨åŸºæœ¬ä»‹ç»ï¼Œæ²¡æœ‰å¯¹å…¶è®¿å­˜ç‰¹å¾ç­‰é•œåƒä»‹ç»ã€‚æœ¬æ–‡å€Ÿé‰´è¿™ç¯‡åšå®¢ï¼Œè‡ªå·±åˆ†æã€è¿è¡Œç›¸å…³workloadsã€‚ äºŒã€LLM inference1.llama.cppè½»é‡åŒ–çš„å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ã€é€‚ç”¨äºåµŒå…¥å‹ç³»ç»Ÿã€è¾¹ç¼˜èŠ‚ç‚¹ä¸Šè¿›è¡Œå¤§æ¨¡å‹æ¨ç†ã€‚ è®¿å­˜ç‰¹å¾ï¼š æ¨¡å‹æƒé‡åŠ è½½é˜¶æ®µï¼šé‡‡ç”¨å¤§å—è¿ç»­å†…å­˜ã€æˆ–è€…å¯é€‰mmap()æ˜ å°„æ¨¡å‹å‚æ•°ã€‚å…·æœ‰è¾ƒå¥½çš„ç©ºé—´å±€éƒ¨æ€§ã€è¾ƒå·®çš„æ—¶é—´å±€éƒ¨æ€§(ä¸€æ¬¡åŠ è½½ä¸€æ¬¡ä½¿ç”¨) æ¨ç†é˜¶æ®µï¼šä¸»è¦æ˜¯KV-Cacheéœ€è¦å¤§é‡å†…å­˜è®¿é—®ï¼Œè¯»å†™é¢‘ç¹ã€æ›´æ–°é¢‘ç¹ã€å„ä¸ªå±‚ä¸­å­˜åœ¨ä¸€äº›å¼ é‡æ“ä½œä¹Ÿéœ€è¦è®¿å­˜ã€‚é«˜è¯»å¯†é›†å‹ å†…å­˜éœ€æ±‚ï¼š â€‹\tåŒå…¶ä»–å¤§æ¨¡å‹æ¨ç†éœ€æ±‚ç›¸ä¼¼ï¼Œå†…å­˜éœ€æ±‚é‡ä¸»è¦æ¥è‡ªæ¨¡å‹æƒé‡ä¸KV-cacheã€‚æ¨¡å‹æƒé‡å†…å­˜ä½¿ç”¨é‡ä¸ç²¾è¯»æœ‰å…³ã€KV-Cacheä¸ä¾èµ–å±‚æ•°æœ‰å…³ã€‚ä¸€ä¸ªqwen-7båœ¨llama.cppçš„å†…å­˜å ç”¨é‡çº¦ä¸º14~16B å…¶ä»–ï¼š â€‹\tllama.cppçš„å†…å­˜ç®¡ç†é‡‡ç”¨ç»Ÿä¸€é¢„åˆ†é…å†…å­˜æ± ï¼Œä½¿ç”¨offsetäºŒæ¬¡åˆ†é…ä¸è®¿é—®ï¼Œæœ€åé›†ä¸­é‡Šæ”¾çš„æ–¹å¼è¿›è¡Œå†…å­˜ç®¡ç†ã€‚å…¶ggmlå†…å­˜ä¸­æœ‰å¯¹å†…å­˜çš„ä¸€æ¬¡æ€§mallocï¼ˆggml_initï¼‰ggml_new_tensorã€ggml_new_tensor_1dè¿›è¡Œå†…å­˜å†…å­˜äºŒæ¬¡åˆ†é…ã€ggml_freeè¿›è¡Œå†…å­˜é‡Šæ”¾ã€‚Arena åˆ†é…å™¨ï¼ˆâ€œæ‰¹å‘å†…å­˜ï¼Œé›¶å”®æŒ‡é’ˆï¼Œæ•´å•æ¸…åœºâ€ï¼‰","tags":["å†…å­˜æ€§èƒ½åˆ†æworkloads"],"categories":["å†…å­˜æ€§èƒ½åˆ†æworkloads"]},{"title":"Qtæºç é˜…è¯»ä¸è®¾è®¡æ¨¡å¼","path":"/2025/07/18/Qtæºç é˜…è¯»ä¸è®¾è®¡æ¨¡å¼/","content":"todo","tags":["Qt","è®¾è®¡æ¨¡å¼"],"categories":["Qt"]},{"path":"/about/index.html","content":"ğŸ§‘â€ğŸ’» About me Hello, welcome to my blog. Iâ€™m Zane Jiang. I graduated with a bachelorâ€™s degree in Computer Science from Nanjing Normal University(NNU), and I am currently pursuing a masterâ€™s degree at the College of Computer Science, Chongqing University(CQU). I have worked as a C++ software development engineer for one year in a company specializing in LED control systems. My current areas of interest include OS,LLVM, CXL, Qt, and more. This blog is used to document some of my reflections on life, work, and study notes. ğŸ“« Contact Email: 2129056867@qq.com GitHub"},{"title":"C++11æ–°ç‰¹æ€§","path":"/notebooks/Interview/C++11æ–°ç‰¹æ€§.html","content":"å¾ˆå¥½çš„é¢è¯•èµ„æ–™ï¼š æ•´ç†äº†ä¸€å¹´çš„Linux C++æ­¦æ—ç§˜ç±ï¼Œä½ æ—©æ™šç”¨å¾—åˆ°ï¼ˆC++è¿›é˜¶å¿…çœ‹ï¼‰ - çŸ¥ä¹ è½¬è½½å¹¶ç®€å•æ•´ç†è‡ªçŸ¥ä¹ ç¨‹åºå–µå¤§äºº 1.å·¦å€¼å¼•ç”¨ä¸å®Œç¾è½¬å‘ç­‰åŸºæœ¬æ¦‚å¿µ: å·¦å€¼ã€å³å€¼ ï¼šæ”¾åœ¨ç­‰å·å·¦è¾¹ï¼Œå–åœ°å€å¹¶ä¸”æœ‰åå­— çš„å°±å«å·¦å€¼ï¼Œåä¹‹å«å³å€¼ int a = b + c ;int a = 4; çº¯å³å€¼:ç”¨äºåˆå§‹åŒ–ä¸€ä¸ªå¯¹è±¡ã€‚ è¿ç®—è¡¨è¾¾å¼äº§ç”Ÿçš„ä¸´æ—¶å˜é‡ã€ä¸å’Œå¯¹è±¡å…³è”çš„åŸå§‹å­—é¢é‡ã€è¿”å›éå¼•ç”¨çš„å‡½æ•°è°ƒç”¨ã€lambdaè¡¨è¾¾å¼ã€thisæŒ‡é’ˆ å°†äº¡å€¼ï¼šä»£è¡¨ä¸€ä¸ªâ€œå³å°†ç»“æŸç”Ÿå‘½å‘¨æœŸâ€çš„å¯¹è±¡ï¼Œ int main() std::string str = Hello World; // str æ˜¯ä¸€ä¸ªå·¦å€¼ // std::move(str) å°†å·¦å€¼ str è½¬æ¢ä¸ºä¸€ä¸ªå°†äº¡å€¼ // å®ƒåœ¨å‘Šè¯‰ç¼–è¯‘å™¨ï¼šâ€œstr å³å°†æ¶ˆäº¡ï¼Œè¯·ç§»åŠ¨å®ƒè€Œä¸æ˜¯æ‹·è´å®ƒâ€ std::string new_str = std::move(str); // æ­¤æ—¶ï¼Œstr çš„èµ„æºï¼ˆåŠ¨æ€åˆ†é…çš„å­—ç¬¦æ•°ç»„ï¼‰è¢«â€œç§»åŠ¨â€åˆ°äº† new_str ä¸­ // str æœ¬èº«ä»ç„¶å­˜åœ¨ï¼ˆæ˜¯ä¸€ä¸ªåˆæ³•çš„å¯¹è±¡ï¼‰ï¼Œä½†å¤„äºâ€œæœ‰æ•ˆä½†æœªæŒ‡å®šçŠ¶æ€â€ // é€šå¸¸æ˜¯ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ï¼Œä½†ä½ ä¸èƒ½ä¾èµ–è¿™ä¸€ç‚¹ï¼Œåªèƒ½å¯¹å®ƒè¿›è¡Œé‡æ–°èµ‹å€¼æˆ–é”€æ¯ std::cout str after move: \\ str \\ std::endl; // å¯èƒ½æ˜¯ std::cout new_str: \\ new_str \\ std::endl; // Hello World return 0;//std::move(str) å°±æ˜¯ä¸€ä¸ªå°†äº¡å€¼ã€‚å®ƒä¸æ˜¯ä¸€ä¸ªæ–°åˆ›å»ºçš„å€¼ï¼ˆä¸æ˜¯çº¯å³å€¼ï¼‰ï¼Œè€Œæ˜¯å³å°†å¤±æ•ˆçš„ç°æœ‰å¯¹è±¡ str çš„å¦ä¸€ç§è¡¨ç°å½¢å¼//ä¸»è¦äº§ç”Ÿæ–¹æ³•ï¼š//1. std::move(a);A a;auto c = std::move(a); // std::move(a) æ˜¯ä¸€ä¸ªå°†äº¡å€¼//2.static_castA(a)A a;auto d = static_castA(a); // static_castA(a) æ˜¯ä¸€ä¸ªå°†äº¡å€¼ å·¦å€¼ã€å³å€¼å¼•ç”¨: å³å€¼å¼•ç”¨ã€‚æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¼•ç”¨ç±»å‹ï¼Œä¸»è¦è®¾è®¡ç”¨æ¥ç»‘å®šåˆ°å³å€¼ï¼ˆç‰¹åˆ«æ˜¯å°†äº¡å€¼ï¼‰ï¼Œå¹¶è¡¨æ˜æ‰€å¼•ç”¨çš„å¯¹è±¡èµ„æºå¯ä»¥è¢«å®‰å…¨åœ°â€ç§»åŠ¨â€æˆ–â€çªƒå–â€ã€‚ int a=5;int b=a;//bæ˜¯å·¦å€¼å¼•ç”¨b=4;int c = 10;//errorï¼Œ10æ— æ³•å–åœ°å€ï¼Œæ— æ³•è¿›è¡Œå¼•ç”¨const int d = 10;//okï¼Œå› ä¸ºæ˜¯å¸¸å¼•ç”¨ï¼Œå¼•ç”¨å¸¸é‡æ•°å­—ï¼Œè¿™ä¸ªå¸¸é‡æ•°å­—ä¼šå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œå¯ä»¥å–åœ°å€int a=4;int b=a;//error,aæ˜¯å·¦å€¼int c=std::move(a);//ok ç§»åŠ¨è¯­ä¹‰æµ…æ‹·è´å®¹æ˜“å¯¼è‡´èµ„æºé‡å¤é‡Šæ”¾ç­‰é—®é¢˜ï¼Œæ·±æ‹·è´ä¼šå¯¼è‡´é¢å¤–çš„å¼€é”€ã€‚ å› æ­¤å¼•å…¥äº†ç§»åŠ¨è¯­ä¹‰ï¼Œä¹Ÿå°±æ˜¯å®ç°äº†æ‰€æœ‰æƒç®¡ç†ï¼Œå·æ‰ä¸€äº›å°†äº¡å€¼çš„èµ„æº C++ä¸­æ‰€æœ‰çš„STLéƒ½å®ç°äº†ç§»åŠ¨è¯­ä¹‰ï¼Œæ–¹ä¾¿ä½¿ç”¨ã€‚ å®ç°ç§»åŠ¨è¯­ä¹‰çš„å…³é”®ç»„ä»¶ 1.å³å€¼å¼•ç”¨ï¼ˆT) 2.ç§»åŠ¨æ„é€ å‡½æ•° class MyString private: char* m_data; size_t m_size; public: // ç§»åŠ¨æ„é€ å‡½æ•° MyString(MyString other) noexcept : m_data(other.m_data), m_size(other.m_size) // å·èµ„æº // å°†æºå¯¹è±¡ç½®äºæœ‰æ•ˆä½†ç©ºçš„çŠ¶æ€ other.m_data = nullptr; other.m_size = 0; ; 3.ç§»åŠ¨èµ‹å€¼è¿ç®—ç¬¦ class MyString public: // ç§»åŠ¨èµ‹å€¼è¿ç®—ç¬¦ MyString operator=(MyString other) noexcept if (this != other) delete[] m_data; // é‡Šæ”¾å½“å‰èµ„æº // å·èµ„æº m_data = other.m_data; m_size = other.m_size; // ç½®ç©ºæºå¯¹è±¡ other.m_data = nullptr; other.m_size = 0; return *this; ;//èµ‹å€¼å’Œæ„é€ çš„åŒºåˆ«ï¼šèµ‹å€¼æ˜¯æ›¿æ¢ï¼Œæ„é€ æ˜¯åˆ›å»ºåŠ èµ‹å€¼ ç¼–è¯‘å™¨ä¼˜åŒ–ï¼šRVONRVOç°ä»£ç¼–è¯‘å™¨ä¼šè¿›è¡Œè¿”å›å€¼ä¼˜åŒ–ï¼ˆRVOï¼‰å’Œå‘½åè¿”å›å€¼ä¼˜åŒ–ï¼ˆNRVOï¼‰ï¼Œæœ‰æ—¶ç”šè‡³æ¯”ç§»åŠ¨è¯­ä¹‰æ›´é«˜æ•ˆ è¿”å›å€¼ä¼˜åŒ–çš„æ—¶æœºï¼š returnçš„å€¼ç±»å‹ä¸å‡½æ•°çš„è¿”å›å€¼ç±»å‹ç›¸åŒ returnçš„æ˜¯ä¸€ä¸ªå±€éƒ¨å¯¹è±¡ MyString create_string() return MyString(Hello); // RVOï¼šç›´æ¥åœ¨ç›®æ ‡ä½ç½®æ„é€ ï¼Œæ— æ‹·è´æ— ç§»åŠ¨MyString create_string_nrvo() MyString result(Hello); return result; // NRVOï¼šç›´æ¥åœ¨ç›®æ ‡ä½ç½®æ„é€ result å®Œç¾è½¬å‘å®Œç¾è½¬å‘æŒ‡çš„æ˜¯åœ¨å‡½æ•°æ¨¡æ¿ä¸­ï¼Œå°†å‚æ•°ä»¥åŸå§‹çš„å€¼ç±»åˆ«ï¼ˆå·¦å€¼æˆ–å³å€¼ï¼‰å’Œconstvolatileé™å®šç¬¦å®Œå…¨ä¸å˜åœ°è½¬å‘ç»™å¦ä¸€ä¸ªå‡½æ•°ã€‚ ç®€å•æ¥è¯´ï¼šä¿æŒå‚æ•°çš„æ‰€æœ‰ç‰¹æ€§ä¸å˜åœ°ä¼ é€’ä¸‹å»ã€‚ ä¸ºä»€ä¹ˆéœ€è¦å®Œç¾è½¬å‘ï¼Ÿåœ¨æ²¡æœ‰å®Œç¾è½¬å‘ä¹‹å‰ï¼Œæ³›å‹ç¼–ç¨‹ä¸­ä¼šé‡åˆ°å‚æ•°ç±»åˆ«ä¸¢å¤±çš„é—®é¢˜ï¼š void wrapper(Foo arg) callee(arg); void wrapper(const Foo arg) callee(arg); void wrapper(Foo arg) callee(std::move(arg)); ä½¿ç”¨æ¨¡æ¿å¯ä»¥ç®€åŒ– templatetypename Tvoid wrapper(T arg) callee(arg); ä½†é—®é¢˜æ˜¯ï¼š å¦‚æœä¼ çš„æ˜¯å³å€¼ï¼ŒT ä¼šæ¨å¯¼æˆ éå¼•ç”¨ç±»å‹ï¼Œå¯¼è‡´å³å€¼å˜æˆå·¦å€¼ã€‚ constvolatile å±æ€§ä¹Ÿå¯èƒ½ä¸¢å¤±ã€‚ ä¸‡èƒ½å¼•ç”¨ä¸å¼•ç”¨æŠ˜å  templatetypename Tvoid wrapper(T arg); è¿™é‡Œçš„T å½“ä¼ å…¥å³å€¼æ—¶ï¼šT æ¨å¯¼ä¸º Uï¼Œäºæ˜¯å‚æ•°ç±»å‹ä¸º U â†’ å³å€¼å¼•ç”¨ï¼› å½“ä¼ å…¥å·¦å€¼æ—¶ï¼šT æ¨å¯¼ä¸º Uï¼Œäºæ˜¯å‚æ•°ç±»å‹ä¸º U â†’ å¼•ç”¨æŠ˜å  â†’ Uã€‚ å¼•ç”¨æŠ˜å è§„åˆ™ï¼š â†’ â†’ â†’ â†’ æ‰€ä»¥ T åœ¨æ¨¡æ¿ä¸­æ—¢èƒ½ç»‘å®šå·¦å€¼ï¼Œä¹Ÿèƒ½ç»‘å®šå³å€¼ã€‚ std::forwardåœ¨ wrapper ä¸­ç›´æ¥å†™ï¼š callee(arg); ä¼šæŠŠæ‰€æœ‰å‚æ•°å½“æˆå·¦å€¼ä¼ é€’ï¼Œå³å€¼çš„æ€§è´¨ä¸¢å¤±ã€‚ éœ€è¦ç”¨ std::forwardT(arg) æ¥â€œæ¡ä»¶è½¬å‘â€ï¼š å¦‚æœ T æ¨å¯¼ä¸º Uï¼Œåˆ™ std::forwardT(arg) è¿”å› Uã€‚ å¦‚æœ T æ¨å¯¼ä¸º Uï¼Œåˆ™ std::forwardT(arg) è¿”å› Uã€‚ è¿™æ ·å³å€¼ä¿æŒå³å€¼ï¼Œå·¦å€¼ä¿æŒå·¦å€¼ï¼Œå®ç°å®Œç¾è½¬å‘ã€‚ å…¸å‹å†™æ³•#include iostream#include utilityvoid callee(int x) std::cout callee(int) ;void callee(const int x) std::cout callee(const int) ;void callee(int x) std::cout callee(int) ;templatetypename Tvoid wrapper(T arg) callee(std::forwardT(arg)); // å®Œç¾è½¬å‘int main() int a = 42; const int b = 100;\t//æ€è€ƒè¾“å‡ºï¼Ÿ wrapper(a); // callee(int) wrapper(b); // callee(const int) wrapper(10); // callee(int) å…¸å‹åº”ç”¨åœºæ™¯1.å£³å‡½æ•° ä¾‹å¦‚æ—¥å¿—ã€è£…é¥°å™¨æ¨¡å¼ã€å‡½æ•°è°ƒç”¨è®¡æ—¶å™¨ templatetypename F, typename... Argsvoid log_and_call(F f, Args... args) std::cout Calling function... ; std::forwardF(f)(std::forwardArgs(args)...); 2.å®¹å™¨æ„é€ å™¨ //vector::emplace_back, map::emplace templatetypename... Argsvoid emplace_back(Args... args) new (storage[size++]) T(std::forwardArgs(args)...); // push_backï¼šéœ€è¦æ˜¾å¼ç§»åŠ¨ names.push_back(std::move(temp)); // ç§»åŠ¨è¯­ä¹‰ // emplace_backï¼šå®Œç¾è½¬å‘å‚æ•°ï¼Œç›´æ¥æ„é€  names.emplace_back(David); // ç›´æ¥åœ¨vectorä¸­æ„é€ ï¼Œæ›´é«˜æ•ˆï¼ 2.æ™ºèƒ½æŒ‡é’ˆC++11 æ ‡å‡†åº“åœ¨ memory å¤´æ–‡ä»¶ä¸­æä¾›äº†ä¸‰ç§ä¸»è¦æ™ºèƒ½æŒ‡é’ˆï¼š std::unique_ptr std::shared_ptr std::weak_ptr unique_ptrstd::unique_ptræ˜¯ä¸€ä¸ªç‹¬å å‹çš„æ™ºèƒ½æŒ‡é’ˆï¼Œå®ƒä¸å…è®¸å…¶å®ƒæ™ºèƒ½æŒ‡é’ˆå…±äº«å…¶å†…éƒ¨æŒ‡é’ˆï¼Œä¹Ÿä¸å…è®¸unique_ptrçš„æ‹·è´å’Œèµ‹å€¼ã€‚ #include iostream#include memorystruct Foo Foo() std::cout Foo ctor ; ~Foo() std::cout Foo dtor ; ;int main() std::unique_ptrFoo p1(new Foo()); // ç‹¬å æ‰€æœ‰æƒ // std::unique_ptrFoo p2 = p1; // é”™è¯¯ï¼Œä¸èƒ½æ‹·è´ std::unique_ptrFoo p3 = std::move(p1); // å¯ä»¥è½¬ç§»æ‰€æœ‰æƒ if (!p1) std::cout p1 is empty ; å…¶å†…éƒ¨å°±æ˜¯å¯¹æŒ‡é’ˆåŒ…äº†ä¸€å±‚ã€ç„¶åç¦ç”¨å…¶æ‹·è´æ„é€ ã€èµ‹å€¼å‡½æ•°ï¼š templatetypename T, typename Deleter = std::default_deleteTclass unique_ptr private: T* ptr; // åŸå§‹æŒ‡é’ˆ Deleter del; // åˆ é™¤å™¨ï¼Œé»˜è®¤è°ƒç”¨ deletepublic: explicit unique_ptr(T* p = nullptr) : ptr(p) ~unique_ptr() if (ptr) del(ptr); // ç¦æ­¢æ‹·è´ unique_ptr(const unique_ptr) = delete; unique_ptr operator=(const unique_ptr) = delete; // æ”¯æŒç§»åŠ¨ unique_ptr(unique_ptr other) noexcept : ptr(other.ptr) other.ptr = nullptr; unique_ptr operator=(unique_ptr other) noexcept if (this != other) reset(); ptr = other.ptr; other.ptr = nullptr; return *this; T* get() const return ptr; T operator*() const return *ptr; T* operator-() const return ptr; void reset(T* p = nullptr) if (ptr) del(ptr); ptr = p; ; shared_ptr shared_ptr ä½¿ç”¨äº†å¼•ç”¨è®¡æ•°ï¼Œæ¯ä¸€ä¸ªshared_ptrçš„æ‹·è´éƒ½æŒ‡å‘ç›¸åŒçš„å†…å­˜ï¼Œæ¯æ¬¡æ‹·è´éƒ½ä¼šè§¦å‘å¼•ç”¨è®¡æ•°+1ï¼Œ æ¯æ¬¡ç”Ÿå‘½å‘¨æœŸç»“æŸææ„çš„æ—¶å€™å¼•ç”¨è®¡æ•°-1ï¼Œåœ¨æœ€åä¸€ä¸ªshared_ptrææ„çš„æ—¶å€™ï¼Œå†…å­˜æ‰ä¼šé‡Šæ”¾ã€‚ æ³¨æ„ç‚¹ï¼š å¯ä»¥è‡ªå®šä¹‰åˆ é™¤å™¨ï¼Œåœ¨å¼•ç”¨è®¡æ•°ä¸º0çš„æ—¶å€™è‡ªåŠ¨è°ƒç”¨åˆ é™¤å™¨æ¥é‡Šæ”¾å¯¹è±¡çš„å†…å­˜ï¼š std::shared_ptrptr(newint,[](int*p)deletep;);std::shared_ptrptr(newint,[](int*p)deletep;); ä¸è¦ç”¨ä¸€ä¸ªè£¸æŒ‡é’ˆåˆå§‹åŒ–å¤šä¸ªshared_ptrï¼Œä¼šå‡ºç°double_freeå¯¼è‡´ç¨‹åºå´©æºƒ é€šè¿‡shared_from_this()è¿”å›thisæŒ‡é’ˆï¼Œä¸è¦æŠŠthisæŒ‡é’ˆä½œä¸ºshared_ptrè¿”å›å‡ºæ¥ï¼Œå› ä¸ºthisæŒ‡é’ˆæœ¬è´¨å°± æ˜¯è£¸æŒ‡é’ˆï¼Œé€šè¿‡thisè¿”å›å¯èƒ½ä¼šå¯¼è‡´é‡å¤ææ„ï¼Œä¸èƒ½æŠŠthisæŒ‡é’ˆäº¤ç»™æ™ºèƒ½æŒ‡é’ˆç®¡ç†ã€‚ classA shared_ptrAGetSelf() returnshared_from_this(); //returnshared_ptrA(this);é”™è¯¯ï¼Œä¼šå¯¼è‡´doublefree ; å°½é‡ä½¿ç”¨make_sharedï¼Œå°‘ç”¨newã€‚ ä¸è¦delete get()è¿”å›æ¥çš„è£¸æŒ‡é’ˆã€‚ è¦é¿å…å¾ªç¯å¼•ç”¨ï¼Œå¾ªç¯å¼•ç”¨å¯¼è‡´å†…å­˜æ°¸è¿œä¸ä¼šè¢«é‡Šæ”¾ï¼Œé€ æˆå†…å­˜æ³„æ¼ã€‚ #include iostream#include memorystruct Node std::shared_ptrNode next; std::shared_ptrNode prev; ~Node() std::cout Node destroyed ; ;int main() auto n1 = std::make_sharedNode(); auto n2 = std::make_sharedNode(); n1-next = n2; n2-prev = n1; std::cout main end ; mainå‡½æ•°è§£é‡Šæ—¶ï¼Œæ ˆä¸Šçš„ n1 è¢«é”€æ¯ - n1å¯¹è±¡ è®¡æ•° -1 1 æ ˆä¸Šçš„ n2 è¢«é”€æ¯ - n2å¯¹è±¡ è®¡æ•° -1 1 ä¸¤è€…çš„å¼•ç”¨è®¡æ•°éƒ½ä¸ä¸º0 ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼ å®ç°ï¼š templatetypename Tclass shared_ptr private: T* ptr; // æŒ‡å‘èµ„æº ControlBlock* ctrl; // æ§åˆ¶å—ï¼ˆåŒ…å«å¼•ç”¨è®¡æ•°ï¼‰ struct ControlBlock size_t strong_count; // å¼ºå¼•ç”¨è®¡æ•°ï¼ˆshared_ptr æ•°é‡ï¼‰ size_t weak_count; // å¼±å¼•ç”¨è®¡æ•°ï¼ˆweak_ptr æ•°é‡ï¼‰ ControlBlock() : strong_count(1), weak_count(0) ;public: explicit shared_ptr(T* p = nullptr) ptr = p; if (p) ctrl = new ControlBlock(); else ctrl = nullptr; ~shared_ptr() release(); void release() if (ctrl) if (--ctrl-strong_count == 0) delete ptr; // æœ€åä¸€ä¸ªå¼ºå¼•ç”¨é”€æ¯èµ„æº if (ctrl-weak_count == 0) delete ctrl; // æ§åˆ¶å—ä¹Ÿé”€æ¯ // æ‹·è´æ„é€ ï¼šå¢åŠ  strong_count shared_ptr(const shared_ptr other) ptr = other.ptr; ctrl = other.ctrl; if (ctrl) ctrl-strong_count++; // ç§»åŠ¨æ„é€ ï¼šè½¬ç§»æ‰€æœ‰æƒ shared_ptr(shared_ptr other) noexcept ptr = other.ptr; ctrl = other.ctrl; other.ptr = nullptr; other.ctrl = nullptr; // è®¡æ•°æ¥å£ size_t use_count() const return ctrl ? ctrl-strong_count : 0; ; weak_ptrè§£å†³å¾ªç¯å¼•ç”¨å¯èƒ½å‡ºç°å†…å­˜æ³„æ¼çš„é—®é¢˜ å¼±å¼•ç”¨ä¸å‚ä¸èµ„æºçš„ç®¡ç† #include iostream#include memorystruct Node std::shared_ptrNode next; std::weak_ptrNode prev; // æ”¹æˆ weak_ptr ~Node() std::cout Node destroyed ; ;int main() auto n1 = std::make_sharedNode(); auto n2 = std::make_sharedNode(); n1-next = n2; n2-prev = n1; // weak_ptrï¼Œä¸å¢åŠ  strong_count std::cout main end ; åœ¨ä½¿ç”¨ weak_ptr è®¿é—®å¯¹è±¡æ—¶ï¼Œå¿…é¡»æ£€æŸ¥å…¶æœ‰æ•ˆæ€§ã€‚ 3.å‡½æ•°å¼ç¼–ç¨‹ std::fuctionä¸lambdalambdaè¡¨è¾¾å¼ï¼Œæä¾›åŒ¿åå‡½æ•°çš„æ–¹å¼ï¼Œå¿«é€Ÿå®šä¹‰å’Œä½¿ç”¨å‡½æ•°å¯¹è±¡ è¦æ³¨æ„æ‚¬ç©ºå¼•ç”¨ std::functionvoid() createCallback() int local_var = 42; // å±é™©ï¼æ•è·äº†å±€éƒ¨å˜é‡ local_var çš„å¼•ç”¨ return []() std::cout local_var; ; // local_var åœ¨è¿™é‡Œè¢«é”€æ¯int main() auto cb = createCallback(); cb(); // æœªå®šä¹‰è¡Œä¸ºï¼æ‰“å°çš„æ˜¯å·²é”€æ¯æ ˆä¸Šçš„åƒåœ¾å€¼ã€‚ for(int id = enCoef9_Rr ; id = enCoef9_Bb ;id++) connect(m_spinBoxs[id],QOverloaddouble::of(QDoubleSpinBox::valueChanged),this,[](double value) OnCoefMatrixSlot(id,value);//id æ’ç­‰äº 0,æœªå®šä¹‰è¡Œä¸º ); é»˜è®¤æƒ…å†µä¸‹ï¼Œä»¥å€¼æ–¹å¼ [=] æ•è·çš„å˜é‡åœ¨ Lambda ä½“ä¸­æ˜¯ const çš„ã€‚å¦‚æœä½ æƒ³ä¿®æ”¹å®ƒä»¬ï¼Œå¿…é¡»åœ¨å‚æ•°åˆ—è¡¨ååŠ ä¸Š mutable å…³é”®å­—ã€‚ int main() int count = 0; // é”™è¯¯ï¼šæ— æ³•åœ¨é mutable lambda ä¸­ä¿®æ”¹æŒ‰å€¼æ•è·çš„å˜é‡ // auto f = [count]() count++; ; // æ­£ç¡®ï¼šä½¿ç”¨ mutable auto f = [count]() mutable count++; std::cout count; // è¾“å‡ºçš„æ˜¯å‰¯æœ¬ï¼Œå¤–éƒ¨çš„ count ä¸å˜ ; f(); // è¾“å‡º 1 std::cout count; // è¾“å‡º 0 ï¼ˆå¤–éƒ¨å˜é‡æœªè¢«ä¿®æ”¹ï¼‰ std::fuctioné€šç”¨çš„å‡½æ•°åŒ…è£…å™¨ï¼Œä¸ºå„ç§å¯è°ƒç”¨å®ä½“ï¼ˆæ™®é€šå‡½æ•°ã€å‡½æ•°æŒ‡é’ˆã€lambdaã€std::bind è¡¨è¾¾å¼ã€å‡½æ•°å¯¹è±¡ç­‰ï¼‰æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„ç±»å‹ã€‚è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥åƒä½¿ç”¨æ™®é€šå˜é‡ä¸€æ ·å­˜å‚¨å’Œä¼ é€’å‡½æ•°ï¼Œæå¤§åœ°å¢åŠ äº†ä»£ç çš„çµæ´»æ€§ã€‚ std::bindå®ƒå¯ä»¥ç”¨æ¥ç»‘å®šä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡çš„éƒ¨åˆ†å‚æ•°ï¼Œé‡æ–°æ’åˆ—å‚æ•°é¡ºåºï¼Œæˆ–è€…è®¾ç½®é»˜è®¤å‚æ•°ï¼Œä»è€Œç”Ÿæˆä¸€ä¸ªæ–°çš„å¯è°ƒç”¨å¯¹è±¡ #include iostream#include functionalusing namespace std::placeholders; // å¯¹äº _1, _2, _3...void print_sum(int a, int b, int c) std::cout a + b + c std::endl;void print_coordinates(int x, int y, int z) std::cout ( x , y , z ) ;class MyClass public: void member_func(int x, const std::string msg) std::cout Member func: x , msg std::endl; ;int main() // 1. ç»‘å®šå‚æ•°ï¼šå°† print_sum çš„ç¬¬ä¸‰ä¸ªå‚æ•°å›ºå®šä¸º 10 auto bind_func1 = std::bind(print_sum, _1, _2, 10); // _1 æ˜¯ç¬¬ä¸€ä¸ªå‚æ•°ï¼Œ_2 æ˜¯ç¬¬äºŒä¸ªå‚æ•° bind_func1(5, 3); // ç­‰ä»·äº print_sum(5, 3, 10); è¾“å‡º 18 // 2. é‡æ’åºå‚æ•°ï¼šæ”¹å˜å‚æ•°é¡ºåº auto bind_func2 = std::bind(print_coordinates, _3, _1, _2); // æ–°é¡ºåºï¼šç¬¬ä¸‰ã€ç¬¬ä¸€ã€ç¬¬äºŒ bind_func2(10, 20, 30); // ç­‰ä»·äº print_coordinates(30, 10, 20); è¾“å‡º (30, 10, 20) // 3. ç»‘å®šæˆå‘˜å‡½æ•° MyClass obj; // ç»‘å®šæˆå‘˜å‡½æ•°éœ€è¦ä¼ é€’ä¸€ä¸ªå¯¹è±¡å®ä¾‹çš„æŒ‡é’ˆæˆ–å¼•ç”¨ï¼ˆè¿™é‡Œç”¨ objï¼‰ // _1 å°†ä½œä¸ºæˆå‘˜å‡½æ•°çš„ç¬¬ä¸€ä¸ªå‚æ•° (int x) auto bind_member = std::bind(MyClass::member_func, obj, _1, Hello); bind_member(42); // ç­‰ä»·äº obj.member_func(42, Hello); // 4. ä¸ std::function ç»“åˆä½¿ç”¨ std::functionvoid(int, int) func = std::bind(print_sum, _1, _2, 100); func(50, 25); // ç­‰ä»·äº print_sum(50, 25, 100); è¾“å‡º 175 return 0; 4.çº¿ç¨‹C++11 æ˜¯ C++ æ ‡å‡†ä¸­ç¬¬ä¸€æ¬¡æ­£å¼å¼•å…¥è·¨å¹³å°çš„çº¿ç¨‹åº“æ”¯æŒçš„ç‰ˆæœ¬ï¼Œå®ƒå°†å¹¶å‘å’Œå¤šçº¿ç¨‹ç¼–ç¨‹çº³å…¥äº†è¯­è¨€å’Œæ ‡å‡†åº“ï¼Œä½¿å¾—å¼€å‘è€…ä¸å†ä¾èµ– pthreadã€Windows API ç­‰å¹³å°ç‰¹å®šçš„æ¥å£ã€‚ c++11æ–°ç‰¹æ€§ä¹‹çº¿ç¨‹ç›¸å…³æ‰€æœ‰çŸ¥è¯†ç‚¹ - ç®€ä¹¦ åŸºç¡€å®ç°ï¼šstd::threadç”¨äºåˆ›å»ºå’Œç®¡ç†çº¿ç¨‹ã€‚ æ„é€ æ—¶æ¥æ”¶ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼ˆå‡½æ•°ã€lambdaã€å‡½æ•°å¯¹è±¡ç­‰ï¼‰ï¼Œä½œä¸ºçº¿ç¨‹çš„å…¥å£ã€‚ æä¾› join()ï¼ˆé˜»å¡ç­‰å¾…å­çº¿ç¨‹ç»“æŸï¼‰å’Œ detach()ï¼ˆåˆ†ç¦»çº¿ç¨‹ï¼Œè®©å…¶åå°è¿è¡Œï¼‰ä¸¤ç§çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹å¼ã€‚ ç¦æ­¢æ‹·è´ï¼ˆé¿å…äºŒä¹‰æ€§ï¼‰ï¼Œæ”¯æŒç§»åŠ¨è¯­ä¹‰ #include iostream#include threadvoid worker(int id) std::cout Thread id is running ;int main() std::thread t(worker, 1); t.join(); // ç­‰å¾…çº¿ç¨‹ç»“æŸ std::mutexstd::mutex m; std::lock_guardstd::mutex lock(m); // ä¸´ç•ŒåŒºstd::unique_lockstd::mutex lock(m);lock.unlock(); // å¯æå‰è§£é”lock.lock(); // å†æ¬¡åŠ é”unique_lockå¼€é”€æ¯”lock_guardæ›´å¤§ std::condition_variableç”¨äºçº¿ç¨‹ä¹‹é—´åŒæ­¥,å¿…é¡»ä¸äº’æ–¥é‡ä¸€èµ·ä½¿ç”¨ã€‚ wait(std::unique_lockstd::mutex lock, Predicate pred)ï¼šé˜»å¡å½“å‰çº¿ç¨‹ï¼Œç›´åˆ°è¢«å”¤é†’ä¸”æ¡ä»¶è°“è¯ pred ä¸º trueã€‚å®ƒä¼šè‡ªåŠ¨é‡Šæ”¾é”ï¼Œå¹¶åœ¨è¢«å”¤é†’åé‡æ–°è·å–é”ã€‚ notify_one()ï¼šå”¤é†’ä¸€ä¸ªç­‰å¾…ä¸­çš„çº¿ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚ notify_all()ï¼šå”¤é†’æ‰€æœ‰ç­‰å¾…ä¸­çš„çº¿ç¨‹ã€‚ å…¸å‹çš„ç”Ÿäº§è€…æ¶ˆè´¹è€…å†™æ³•ï¼š #include iostream#include thread#include mutex#include condition_variable#include queuestd::queueint data_queue;std::mutex mtx;std::condition_variable cv;constexpr int MAX_ITEMS = 10;void producer() for (int i = 0; i MAX_ITEMS; ++i) std::this_thread::sleep_for(std::chrono::milliseconds(100)); std::lock_guardstd::mutex lock(mtx); data_queue.push(i); std::cout Produced: i std::endl; // lock åœ¨è¿™é‡Œææ„è§£é” cv.notify_one(); // é€šçŸ¥ä¸€ä¸ªæ¶ˆè´¹è€… void consumer() while (true) std::unique_lockstd::mutex lock(mtx); // wait ä¼šé‡Šæ”¾ lockï¼Œå¹¶åœ¨è¢«å”¤é†’åé‡æ–°è·å– lock // å¦‚æœ lambda è¿”å› falseï¼Œç»§ç»­ç­‰å¾…ï¼›è¿”å› trueï¼Œåˆ™ç»§ç»­æ‰§è¡Œ cv.wait(lock, [] return !data_queue.empty(); ); int value = data_queue.front(); data_queue.pop(); lock.unlock(); // å¯ä»¥æå‰æ‰‹åŠ¨è§£é”ï¼Œå‡å°‘é”çš„æŒæœ‰æ—¶é—´ std::cout Consumed: value std::endl; if (value == MAX_ITEMS - 1) break; int main() std::thread prod(producer); std::thread cons(consumer); prod.join(); cons.join(); std::future å’Œ std::promise - å¼‚æ­¥ç»“æœstd::futureè¡¨ç¤ºä¸€ä¸ªæœªæ¥ä¼šäº§ç”Ÿçš„å€¼ï¼Œç”¨get()è·å–ç»“æœ,å¯èƒ½ä¼šé˜»å¡ std::promiseæä¾›ç»“æœçš„ç”Ÿäº§è€…ï¼Œå’Œfutureæˆå¯¹å‡ºç°ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€ä¸ªæ˜¯ç”Ÿäº§è€…ï¼Œä¸€ä¸ªæ˜¯æ¶ˆè´¹è€… #include iostream#include thread#include futurevoid worker(std::promiseint p) int result = 42; p.set_value(result); // æŠŠç»“æœä¼ é€’å‡ºå»int main() std::promiseint p; std::futureint f = p.get_future(); std::thread t(worker, std::move(p)); std::cout Result from worker: f.get() std::endl; t.join(); #include iostream#include thread#include futurevoid worker(std::promiseint p) try throw std::runtime_error(something went wrong); catch (...) p.set_exception(std::current_exception()); // ä¼ é€’å¼‚å¸¸ int main() std::promiseint p; std::futureint f = p.get_future(); std::thread t(worker, std::move(p)); try std::cout f.get() std::endl; // è¿™é‡Œä¼šæŠ›å‡ºå¼‚å¸¸ catch (const std::exception e) std::cout Caught exception: e.what() std::endl; t.join(); std::packaged_task#include future#include iostreamint heavy_work(int x) // æ¨¡æ‹Ÿç¹é‡è®¡ç®— return x * x;int main() // å°†å‡½æ•° heavy_work åŒ…è£…æˆä¸€ä¸ªä»»åŠ¡ std::packaged_taskint(int) task(heavy_work); // è·å–ä¸ä»»åŠ¡ç»“æœå…³è”çš„ future std::futureint fut = task.get_future(); // åœ¨çº¿ç¨‹ä¸­è¿è¡Œä»»åŠ¡ï¼ˆä»»åŠ¡å¯¹è±¡ä¸å¯å¤åˆ¶ï¼Œå¿…é¡»ç§»åŠ¨ï¼‰ std::thread t(std::move(task), 10); t.detach(); // å¯ä»¥åˆ†ç¦»ï¼Œç”¨ future æ¥è·å–ç»“æœ std::cout Result: fut.get() std::endl; // è¾“å‡º 100 return 0; std::async#include iostream#include future#include chronoint compute() // æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ std::this_thread::sleep_for(std::chrono::seconds(2)); return 42;int main() // å¼‚æ­¥å¯åŠ¨ compute å‡½æ•° std::futureint fut = std::async(std::launch::async, compute); // åœ¨ä¸»çº¿ç¨‹åšå…¶ä»–äº‹æƒ…... std::cout Doing other work... ; // å½“éœ€è¦ç»“æœæ—¶ï¼Œget() ä¼šé˜»å¡ç›´åˆ°ç»“æœå°±ç»ª int result = fut.get(); std::cout The answer is: result std::endl; return 0; std::atomicstd::atomic æ˜¯ä¸€ä¸ªæ¨¡æ¿ç±»ï¼ˆå¦‚ std::atomicint, std::atomicboolï¼‰ï¼Œå®ƒåŒ…è£…äº†ä¸€ä¸ªç±»å‹ï¼Œå¹¶æä¾›äº†ä¸€ç³»åˆ—ä¿è¯åŸå­æ“ä½œçš„æˆå‘˜å‡½æ•°ã€‚åŸå­æ“ä½œæ„å‘³ç€è¯¥æ“ä½œä»ä»»ä½•çº¿ç¨‹çš„è§†è§’çœ‹ï¼Œéƒ½æ˜¯ä¸å¯åˆ†å‰²çš„ #include atomicstd::atomicint counter(0);// çº¿ç¨‹ 1 (Writer)int new_value = compute_expensive_value();counter.store(new_value, std::memory_order_release); // åŸå­å†™// çº¿ç¨‹ 2 (Reader)int current_value = counter.load(std::memory_order_acquire); // åŸå­è¯»//std::atomicå…è®¸æ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒçš„åŒæ­¥å¼ºåº¦ï¼Œåœ¨ä¿è¯æ­£ç¡®æ€§çš„å‰æä¸‹è¿½æ±‚æè‡´æ€§èƒ½ã€‚//å†…å­˜é¡ºåºé€šè¿‡ std::memory_order æšä¸¾æ¥æŒ‡å®šï¼Œä½œä¸ºå‚æ•°ä¼ é€’ç»™ load, store, fetch_* ç­‰æ“ä½œã€‚counter.fetch_add(1, std::memory_order_relaxed); å…³äºå†…å­˜åºï¼Œè¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤æ‚çš„é—®é¢˜ï¼ŒX86\\Riscvçš„ä¸åŒå¼ºå¼±å†…å­˜åºä¹Ÿæœ‰ä¸åŒå®šä¹‰ä¸å®ç°ã€‚ std::atomic_flag æ˜¯ä¸“ä¸ºå®ç°è‡ªæ—‹é”è€Œè®¾è®¡çš„æœ€ç®€å•çš„åŸå­å¸ƒå°”ç±»å‹ //è‡ªæ—‹é”æ˜¯ä¸€ç§å¿™ç­‰å¾…ï¼ˆBusy-Waitingï¼‰ é”ã€‚å½“ä¸€ä¸ªçº¿ç¨‹å°è¯•è·å–ä¸€ä¸ªå·²ç»è¢«å…¶ä»–çº¿ç¨‹æŒæœ‰çš„è‡ªæ—‹é”æ—¶ï¼Œå®ƒä¸ä¼šç«‹å³è¿›å…¥ç¡çœ çŠ¶æ€ï¼ˆåƒäº’æ–¥é”é‚£æ ·ï¼‰ï¼Œè€Œæ˜¯ä¼šåœ¨ä¸€ä¸ªå¾ªç¯ä¸­ä¸æ–­åœ°æ£€æŸ¥é”æ˜¯å¦å·²ç»è¢«é‡Šæ”¾ï¼ˆå³â€œè‡ªæ—‹â€ï¼‰ï¼Œç›´åˆ°æœ€ç»ˆè·å–åˆ°é”ä¸ºæ­¢ã€‚#include atomicclass Spinlock private: // ATOMIC_FLAG_INIT ç¡®ä¿æ ‡å¿—åˆå§‹ä¸ºâ€œæ¸…é™¤â€ï¼ˆfalseï¼‰çŠ¶æ€ std::atomic_flag lock_flag = ATOMIC_FLAG_INIT;public: void lock() // test_and_set() æ˜¯åŸå­æ“ä½œï¼š // 1. è¯»å–å½“å‰å€¼ // 2. æ— è®ºå½“å‰å€¼æ˜¯ä»€ä¹ˆï¼Œéƒ½å°†å…¶è®¾ç½®ä¸º true // 3. è¿”å›å®ƒè¯»å–åˆ°çš„**æ—§å€¼** while (lock_flag.test_and_set(std::memory_order_acquire)) // å¦‚æœæ—§å€¼æ˜¯ trueï¼Œè¯´æ˜é”å·²è¢«å ç”¨ï¼Œå¾ªç¯ç»§ç»­è‡ªæ—‹ // å¦‚æœæ—§å€¼æ˜¯ falseï¼Œè¯´æ˜æˆåŠŸè·å–é”ï¼Œå¾ªç¯ç»“æŸ // å¯é€‰ï¼šåœ¨è‡ªæ—‹ç­‰å¾…æ—¶æç¤ºCPUé™ä½åŠŸè€—æˆ–åˆ‡æ¢è¶…çº¿ç¨‹ // __builtin_ia32_pause(); // GCC/Clang intrinsic for x86 // std::this_thread::yield(); // å¦‚æœç­‰å¾…æ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œå¯ä¸»åŠ¨è®©å‡ºæ—¶é—´ç‰‡ void unlock() // å°†æ ‡å¿—æ¸…é™¤ï¼ˆè®¾ä¸ºfalseï¼‰ï¼Œé‡Šæ”¾é” lock_flag.clear(std::memory_order_release); ;// ä½¿ç”¨ç¤ºä¾‹Spinlock my_lock;int shared_data = 0;void critical_section() my_lock.lock(); // è·å–é”ï¼Œè‹¥å¤±è´¥åˆ™è‡ªæ—‹ç­‰å¾… shared_data++; // å®‰å…¨åœ°ä¿®æ”¹å…±äº«æ•°æ® // ...å…¶ä»–æ“ä½œ my_lock.unlock(); // é‡Šæ”¾é” è‡ªæ—‹é”ä¸äº’æ–¥é”çš„æ¯”è¾ƒ ç‰¹æ€§ è‡ªæ—‹é” (Spinlock) äº’æ–¥é” (Mutex, e.g., std::mutex) ç­‰å¾…æœºåˆ¶ å¿™ç­‰å¾… (Busy-Waiting)ã€‚çº¿ç¨‹åœ¨CPUä¸Šå¾ªç¯æ£€æŸ¥ï¼Œä¸æ”¾å¼ƒCPUæ—¶é—´ç‰‡ã€‚ é˜»å¡ç­‰å¾… (Blocking-Wait)ã€‚çº¿ç¨‹è¢«æ“ä½œç³»ç»ŸæŒ‚èµ·ï¼Œæ”¾å…¥ç­‰å¾…é˜Ÿåˆ—ï¼Œæ”¾å¼ƒCPUæ—¶é—´ç‰‡ã€‚ å¼€é”€ è·å–é‡Šæ”¾é”çš„å¼€é”€æå°ï¼ˆä¸»è¦æ˜¯åŸå­CPUæŒ‡ä»¤ï¼‰ã€‚ä½†ç­‰å¾…æœŸé—´æ¶ˆè€—CPUå‘¨æœŸã€‚ è·å–é‡Šæ”¾é”çš„å¼€é”€è¾ƒå¤§ï¼ˆéœ€è¦è¿›å…¥æ“ä½œç³»ç»Ÿå†…æ ¸è¿›è¡Œçº¿ç¨‹è°ƒåº¦ï¼‰ã€‚ä½†ç­‰å¾…æœŸé—´ä¸æ¶ˆè€—CPUã€‚ é€‚ç”¨åœºæ™¯ 1. ä¸´ç•ŒåŒºä»£ç éå¸¸çŸ­ï¼ˆæ‰§è¡Œé€Ÿåº¦å¿«ï¼‰ã€‚ 2. ç­‰å¾…æ—¶é—´æçŸ­ã€‚ 3. ä¸å¸Œæœ›å‘ç”Ÿçº¿ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ˆå› å…¶å¼€é”€å¯èƒ½æ¯”çŸ­æš‚ç­‰å¾…æ›´å¤§ï¼‰ã€‚ ä¾‹å¦‚ï¼š å†…æ ¸ç¼–ç¨‹ã€æ— é”æ•°æ®ç»“æ„ã€æ€§èƒ½å…³é”®çš„åº•å±‚ä»£ç ã€‚ 1. ä¸´ç•ŒåŒºä»£ç æ‰§è¡Œæ—¶é—´è¾ƒé•¿ã€‚ 2. ç­‰å¾…æ—¶é—´å¯èƒ½è¾ƒé•¿æˆ–ä¸å¯é¢„æµ‹ã€‚ 3. é€‚ç”¨äºç»å¤§å¤šæ•°åº”ç”¨ç¨‹åºçº§åˆ«çš„å¹¶å‘ã€‚ ä¾‹å¦‚ï¼š æ–‡ä»¶æ“ä½œã€æ•°æ®åº“è®¿é—®ã€å¤æ‚çš„è®¡ç®—è¿‡ç¨‹ã€‚ ç¼ºç‚¹ æµªè´¹CPUèµ„æºã€‚å¦‚æœé”è¢«é•¿æ—¶é—´æŒæœ‰ï¼Œè‡ªæ—‹çº¿ç¨‹ä¼šç©ºè½¬CPUï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆâ€œçƒ§CPUâ€ï¼‰ã€‚ ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ã€‚çº¿ç¨‹åˆ‡æ¢éœ€è¦ä¿å­˜å’Œæ¢å¤å¯„å­˜å™¨çŠ¶æ€ï¼Œå¼€é”€è¾ƒå¤§ã€‚ çŸ­æœŸæŒæœ‰ç”¨è‡ªæ—‹ï¼Œé•¿æœŸæŒæœ‰ç”¨äº’æ–¥ 5.ç±»å‹æ¨å¯¼autoè®©ç¼–è¯‘å™¨åœ¨ç¼–è¯‘æœŸæ ¹æ®åˆå§‹åŒ–è¡¨è¾¾å¼è‡ªåŠ¨æ¨å¯¼å‡ºå˜é‡çš„ç±»å‹ decltypeæŸ¥è¯¢ä¸€ä¸ªè¡¨è¾¾å¼ï¼ˆè€Œéåˆå§‹åŒ–å™¨ï¼‰çš„ç±»å‹ã€‚å®ƒè¿”å›è¯¥è¡¨è¾¾å¼çš„ç²¾ç¡®ç±»å‹ï¼ŒåŒ…æ‹¬å¼•ç”¨å’Œ const é™å®šç¬¦ã€‚","tags":[null]},{"title":"CPPæ‚è®°","path":"/notebooks/Interview/CPPæ‚è®°.html","content":"å…¨å±€é™æ€å˜é‡ã€å‡½æ•°å†…é™æ€å˜é‡ã€attribute((destructor))ææ„é¡ºåºæ„é€ ææ„é¡ºåºçš„ä¸ç¡®å®šæ€§ ä»¥åŠé™æ€å‡½æ•°è·å–çš„å•ä¾‹ã€‚ C++ æ ‡å‡†è§„å®šï¼šåŒä¸€ä¸ªç¼–è¯‘å•å…ƒï¼ˆåŒä¸€ä¸ª cpp æ–‡ä»¶ï¼‰å†…ï¼Œé™æ€å…¨å±€å¯¹è±¡çš„ææ„é¡ºåºä¸æ„é€ é¡ºåºç›¸åã€‚ ä½†ä¸åŒç¼–è¯‘å•å…ƒï¼ˆä¸åŒ cpp æ–‡ä»¶soï¼‰ä¹‹é—´çš„ææ„é¡ºåºæ˜¯æœªå®šä¹‰çš„ã€‚ å±€éƒ¨ staticï¼ˆå³å‡½æ•°å†… staticï¼‰å¯¹è±¡çš„ææ„é¡ºåºä¸å…¶å®šä¹‰é¡ºåºæœ‰å…³ï¼Œä½†ä¹Ÿåªåœ¨åŒä¸€ç¼–è¯‘å•å…ƒå†…æœ‰ä¿è¯ã€‚ è‹¥ä¸€ä¸ªå˜é‡ä»…åœ¨å•ä¸ªæ–‡ä»¶ä¸­å¯è§ï¼Œåˆ™å»ºè®®å°†è¿™ä¸ªå˜é‡å£°æ˜ä¸ºé™æ€å…¨å±€å˜é‡ï¼Œstaticä¿®é¥°çš„é™æ€å…¨å±€å˜é‡ä»…åœ¨å½“å‰æ–‡ä»¶ä¸­å¯è§ã€‚ å¦‚æœä¸€ä¸ªå…¨å±€å˜é‡åªè¢«å•ä¸ªå‡½æ•°ä½¿ç”¨,å°†å…¶æ”¹ä¸ºè¯¥å‡½æ•°çš„é™æ€å±€éƒ¨å˜é‡å¯ä»¥è¿›ä¸€æ­¥é™åˆ¶å˜é‡çš„ä½œç”¨åŸŸ,æé«˜ä»£ç çš„å†…èšæ€§,é™ä½è€¦åˆåº¦ã€‚é™æ€å±€éƒ¨å˜é‡å…·æœ‰å…¨å±€å¯¿å‘½ä½†å±€éƒ¨ä½œç”¨åŸŸçš„ç‰¹ç‚¹, é™æ€å…¨å±€å˜é‡æ˜¯å­˜å‚¨åœ¨**é™æ€æ•°æ®åŒºçš„,**è€Œä¸æ˜¯æ ˆåŒº,å› æ­¤é™æ€å…¨å±€å˜é‡çš„å¤§å°ä¸ä¼šå¯¼è‡´æ ˆæº¢å‡ºã€‚æ ˆæº¢å‡ºé€šå¸¸æ˜¯ç”±äºå‡½æ•°è°ƒç”¨å±‚æ¬¡è¿‡æ·±æˆ–å±€éƒ¨å˜é‡è¿‡å¤§å¯¼è‡´çš„ã€‚ ç±»çš„å†…å­˜å ç”¨ 1.32ä½ç³»ç»Ÿä¸­è™šå‡½æ•°æŒ‡é’ˆä¸º4å­—èŠ‚ï¼Œ64ä½ä¸º8å­—èŠ‚ 2.åªéœ€è¦è€ƒè™‘è™šå‡½æ•°æŒ‡é’ˆï¼Œè™šå‡½æ•°è¡¨ä¸è®¡å…¥æŸä¸ªç±»çš„èµ„æº 3.charå ä¸€å­—èŠ‚ï¼Œä½†æ˜¯éœ€è¦è€ƒè™‘å†…å­˜è°ƒç”¨ 4.å¦‚æœæœ‰è™šç»§æ‰¿ï¼Œåˆ™å¤šä¸€ä¸ªè™šåŸºç±»æŒ‡é’ˆã€‚ 5.ç©ºç±»å ä¸€ä¸ªå­—èŠ‚ï¼ˆç”¨äºæ ‡è¯†ï¼‰ æŒ‡é’ˆå¥½é¢˜ int arr[5]{1,2,3,4,5};åœ¨è¿™ä¸ªæ•°ç»„çš„å®šä¹‰ä¸­ï¼Œé€šå¸¸çš„ç†è§£arræ˜¯æ•°ç»„çš„åœ°å€å³æ•°ç»„é¦–å…ƒç´ çš„åœ°å€ï¼Œè¿›ä¸€æ­¥ç†è§£arræ˜¯ä¸€ä¸ªintå‹çš„æŒ‡é’ˆå¸¸é‡ï¼Œå¸¸é‡+1åœ°å€åç§»sizeof(int)ï¼Œæ‰€ä»¥arr+1æ˜¯é¦–å…ƒç´ ä¸‹ä¸€ä¸ªå…ƒç´ çš„åœ°å€ï¼›è€ƒè™‘åˆ°è¿™ä¸€å±‚å°±ä¸éš¾ç†è§£**arr*çš„å«ä¹‰ï¼Œarræ˜¯å¯¹arrå–åœ°å€ï¼Œç»“æœä¹Ÿæ˜¯ä¸ªåœ°å€ï¼Œåªæ˜¯è¿™ä¸ªåœ°å€çš„ç±»å‹æ˜¯æŒ‡å‘æœ‰5ä¸ªintç±»å‹æ•°æ®çš„æ•°ç»„çš„æŒ‡é’ˆå¸¸é‡ï¼Œè¿™ä¸ªå¸¸é‡+1åœ°å€åç§»5sizeof(int)ã€‚ å„çº§æŒ‡é’ˆç®—å„çº§çš„ï¼š ä¸»è¦å°±æ˜¯ç†è§£ å’Œ * çš„â€œå‡çº§é™çº§â€ï¼› é“¾æ¥ï¼šhttps://www.nowcoder.com/exam/test/89156461/submission?examPageSource=Intelligentpid=62380309testCallback=https%3A%2F%2Fwww.nowcoder.com%2Fexam%2Fintelligent%3FquestionJobId%3D10%26subTabName%3Dintelligent_page%26tagId%3D21000testclass%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91 Copy and Swapä¼ ç»Ÿåšæ³•operator= class MyString private: char* data; // åŠ¨æ€åˆ†é…çš„å­—ç¬¦ä¸²public: // èµ‹å€¼è¿ç®—ç¬¦é‡è½½ MyString operator=(const MyString other) // æ£€æŸ¥è‡ªèµ‹å€¼ if (this == other) return *this; // é‡Šæ”¾å½“å‰å¯¹è±¡çš„èµ„æº delete[] data; // å¤åˆ¶æ•°æ® data = new char[std::strlen(other.data) + 1]; std::strcpy(data, other.data); // è¿”å›å½“å‰å¯¹è±¡çš„å¼•ç”¨ return *this; ; Copy and Swap MyString operator=(const MyString other) // æ£€æŸ¥è‡ªèµ‹å€¼ if (this == other) return *this; MyString tmpother; std::swap(data,other.data); return *this; ä¼˜åŠ¿ï¼š å¼‚å¸¸å®‰å…¨ï¼šä¼ ç»Ÿæ–¹æ³•newæŠ›å‡ºå¼‚å¸¸æ—¶ï¼Œå¯¹è±¡å‡ºäºæ— æ•ˆçŠ¶æ€ã€‚dataå·²ç»è¢«åˆ é™¤ï¼Œä½†æ˜¯åˆ†é…å¤±è´¥ å¼ºå¼‚å¸¸å®‰å…¨æ€§: å¦‚æœä¸€ä¸ªæ“ä½œå› ä¸ºå¼‚å¸¸è€Œå¤±è´¥ï¼Œç¨‹åºçš„çŠ¶æ€ä¼šå›æ»šåˆ°æ“ä½œä¹‹å‰çš„æ ·å­ï¼Œå°±åƒè¿™ä¸ªæ“ä½œä»æ¥æ²¡æ‰§è¡Œè¿‡ä¸€æ · ä»£ç å¤ç”¨ï¼šå¤ç”¨æ‹·è´æ„é€ å‡½æ•° è‡ªåŠ¨èµ„æºç®¡ç†ï¼šè‡ªåŠ¨é‡Šæ”¾tmpèµ„æº C++11 å†™æ³• MyString operator=(MyString other) //å€¼ä¼ é€’ //ä¼ å…¥å·¦å€¼ï¼šæ‹·è´æ„é€  //ä¼ å…¥å³å€¼ï¼šç§»åŠ¨æ„é€  std::swap(data,other.data); return *this; ç§»åŠ¨æ„é€ è¿˜æ˜¯æ‹·è´æ„é€ ï¼Ÿ å·¦å€¼ï¼šå«å¾—å‡ºåå­— å³å€¼ï¼šå«ä¸å‡ºåå­—ï¼ˆä¸´æ—¶å˜é‡ï¼Œstd::moveï¼‰ å·¦å€¼ç”¨æ‹·è´æ„é€ ï¼Œå³å€¼ç”¨ç§»åŠ¨æ„é€ ï¼ˆå·ï¼‰ æ¨¡æ¿æ¨¡æ¿ç‰¹åŒ–ã€åç‰¹åŒ–æ¨¡æ¿ç‰¹åŒ–æ˜¯ä¸ºç‰¹å®šçš„æ¨¡æ¿å‚æ•°æä¾›ç‰¹æ®Šå®ç°çš„æŠ€æœ¯ã€‚å½“é€šç”¨æ¨¡æ¿ä¸é€‚åˆæŸäº›ç‰¹å®šç±»å‹æ—¶ï¼Œå¯ä»¥ä¸ºå…¶æä¾›å®šåˆ¶ç‰ˆæœ¬ã€‚ æ‰€æœ‰æ¨¡æ¿å‚æ•°éƒ½æŒ‡å®šå…·ä½“ç±»å‹å°±å«æ¨¡æ¿å…¨ç‰¹åŒ– åç‰¹åŒ–åªå¯¹éƒ¨åˆ†æ¨¡æ¿å‚æ•°è¿›è¡Œç‰¹åŒ–,å‡½æ•°æ¨¡æ¿ä¸æ”¯æŒåç‰¹åŒ–ï¼Œåªæœ‰ç±»æ¨¡æ¿æ”¯æŒ å‡½æ•°æ¨¡æ¿ç‰¹åŒ– #include iostream#include cstring// é€šç”¨æ¨¡æ¿templatetypename Tvoid print(T value) std::cout General: value std::endl;// å…¨ç‰¹åŒ– - ä¸ºconst char*ç±»å‹templatevoid printconst char*(const char* value) std::cout C-string: \\ value \\ std::endl;// å…¨ç‰¹åŒ– - ä¸ºintç±»å‹templatevoid printint(int value) std::cout Integer: value (0x std::hex value ) std::endl;int main() print(3.14); // è°ƒç”¨é€šç”¨ç‰ˆæœ¬ print(Hello); // è°ƒç”¨const char*ç‰¹åŒ– print(42); // è°ƒç”¨intç‰¹åŒ– return 0; ç±»æ¨¡æ¿ç‰¹åŒ– #include iostream// é€šç”¨æ¨¡æ¿templatetypename Tclass TypeInfo public: static const char* name() return Unknown; ;// å…¨ç‰¹åŒ– - intç±»å‹templateclass TypeInfoint public: static const char* name() return int; ;// å…¨ç‰¹åŒ– - doubleç±»å‹templateclass TypeInfodouble public: static const char* name() return double; ;// å…¨ç‰¹åŒ– - const char*ç±»å‹templateclass TypeInfoconst char* public: static const char* name() return const char*; ;int main() std::cout TypeInfofloat::name() std::endl; // Unknown std::cout TypeInfoint::name() std::endl; // int std::cout TypeInfoconst char*::name() std::endl; // const char* return 0; åç‰¹åŒ– #include iostream// é€šç”¨æ¨¡æ¿ - ä¸¤ä¸ªç±»å‹å‚æ•°templatetypename T, typename Uclass Pair public: void print() std::cout General PairT, U std::endl; ;// åç‰¹åŒ– - ä¸¤ä¸ªç±»å‹ç›¸åŒtemplatetypename Tclass PairT, T public: void print() std::cout Specialized PairT, T std::endl; ;// åç‰¹åŒ– - ç¬¬äºŒä¸ªå‚æ•°ä¸ºinttemplatetypename Tclass PairT, int public: void print() std::cout Specialized PairT, int std::endl; ;int main() Pairdouble, char p1; p1.print(); // General PairT, U Pairfloat, float p2; p2.print(); // Specialized PairT, T Pairstd::string, int p3; p3.print(); // Specialized PairT, int return 0;//æŒ‡é’ˆç±»å‹è¿›è¡Œåç‰¹åŒ–// é€šç”¨æ¨¡æ¿templatetypename Tclass Wrapper public: static const char* type() return Value; ;// åç‰¹åŒ– - æŒ‡é’ˆç±»å‹templatetypename Tclass WrapperT* public: static const char* type() return Pointer; ;// åç‰¹åŒ– - æŒ‡å‘æŒ‡é’ˆçš„æŒ‡é’ˆtemplatetypename Tclass WrapperT** public: static const char* type() return Pointer-to-Pointer; ;int main() std::cout Wrapperint::type() std::endl; // Value std::cout Wrapperint*::type() std::endl; // Pointer std::cout Wrapperint**::type() std::endl; // Pointer-to-Pointer return 0; å¯å˜å‚æ•°æ¨¡æ¿åŸºæœ¬ç”¨æ³•ï¼š templatetypename... Args // Argsæ˜¯æ¨¡æ¿å‚æ•°åŒ…void function(Args... args) // argsæ˜¯å‡½æ•°å‚æ•°åŒ… // å¤„ç†å‚æ•°... #include iostream// åŸºç¡€æƒ…å†µï¼š0ä¸ªå‚æ•°æ—¶è¿”å›0templatetypename TT sum(T value) return value;// é€’å½’æ±‚å’Œtemplatetypename T, typename... ArgsT sum(T first, Args... args) return first + sum(args...);// è®¡ç®—å‚æ•°ä¸ªæ•°templatetypename... Argsstd::size_t count(Args... args) return sizeof...(args); // sizeof... æ“ä½œç¬¦è·å–å‚æ•°åŒ…å¤§å°int main() std::cout sum(1, 2, 3, 4, 5) std::endl; // 15 std::cout sum(1.5, 2.5, 3.5) std::endl; // 7.5 std::cout count(1, a, hello, 3.14) std::endl; // 4 return 0; éç±»å‹æ¨¡æ¿å‚æ•°(å¸¸é‡æ¨¡æ¿)cudaä¸­ç”¨çš„å¤šï¼Œç”¨äºç¼–è¯‘å™¨å¸¸é‡ä¼˜åŒ– template int Nint sumArray(int (arr)[N]) int sum = 0; for (int i = 0; i N; i++) sum += arr[i]; return sum;int a[5] = 1,2,3,4,5;int total = sumArray(a); // N=5ï¼Œç¼–è¯‘æœŸç¡®å®š ç±»å‹è½¬æ¢è¿ç®—ç¬¦static_cast é™æ€è½¬æ¢ç”¨äºåœ¨ç¼–è¯‘æ—¶å·²çŸ¥çš„ï¼Œæœ‰é€»è¾‘å…³è”çš„ç±»å‹ä¹‹é—´çš„è½¬æ¢ åœºæ™¯ //åŸºæœ¬æ•°æ®ç±»å‹ä¹‹é—´çš„è½¬æ¢int i = 10;double d = static_castdouble(i); // int - double//æ´¾ç”Ÿç±»æŒ‡é’ˆ/å¼•ç”¨ - åŸºç±»æŒ‡é’ˆ/å¼•ç”¨ï¼ˆå‘ä¸Šè½¬æ¢ï¼ŒUpcastingï¼‰ã€‚è¿™æ˜¯å®‰å…¨çš„ï¼Œå¹¶ä¸”æ˜¯éšå¼è½¬æ¢çš„æ˜¾å¼å†™æ³•ã€‚class Base ;class Derived : public Base ;Derived derived;Base* basePtr = static_castBase*(derived); // å®‰å…¨//åŸºç±»æŒ‡é’ˆ/å¼•ç”¨ - æ´¾ç”Ÿç±»æŒ‡é’ˆ/å¼•ç”¨ï¼ˆå‘ä¸‹è½¬æ¢ï¼ŒDowncastingï¼‰ã€‚ä¸å®‰å…¨Base* basePtr = new Derived(); // å®é™…ä¸ŠæŒ‡å‘ä¸€ä¸ªDerivedå¯¹è±¡Derived* derivedPtr = static_castDerived*(basePtr); // å¯ä»¥ï¼Œä½†æœ‰é£é™©//ä»»ä½•å…·æœ‰è½¬æ¢æ„é€ å‡½æ•°çš„ç±»å‹è½¬æ¢class MyClass public: MyClass(int x) // è½¬æ¢æ„é€ å‡½æ•°;int num = 5;MyClass obj = static_castMyClass(num); dynamic_caståŠ¨æ€è½¬æ¢ç”¨äºå®‰å…¨çš„åœ¨ç»§æ‰¿å‚å·®ç»“æ„ä¸­è¿›è¡Œå‘ä¸‹è½¬æ¢æˆ–è€…äº¤å‰è½¬æ¢ï¼Œä¾èµ–è¿è¡Œæ—¶ç±»å‹ä¿¡æ¯RTTI ç”¨æ³•ï¼š å°†åŸºç±»æŒ‡é’ˆæˆ–å¼•ç”¨å®‰å…¨çš„è½¬æ¢ä¸ºæ´¾ç”Ÿç±»çš„æŒ‡é’ˆæˆ–è€…å¼•ç”¨ï¼Œå¿…é¡»ç”¨äºå¤šæ€ç±»å‹ï¼ˆè‡³å°‘å«æœ‰ä¸€ä¸ªè™šå‡½æ•°ï¼‰ â€‹\tè½¬æ¢æˆåŠŸä¼šè¿”å›ç›®æ ‡ç±»å‹çš„æŒ‡é’ˆï¼Œè½¬æ¢å¤±è´¥è¿”å›nullæˆ–è€…std::bad_cast class Base virtual void foo() ; // å¤šæ€åŸºç±»ï¼ˆæœ‰è™šå‡½æ•°ï¼‰class Derived : public Base ;Base* basePtr = new Derived(); // æ­£ç¡®æŒ‡å‘æ´¾ç”Ÿç±»// å®‰å…¨å‘ä¸‹è½¬æ¢Derived* derivedPtr = dynamic_castDerived*(basePtr);if (derivedPtr != nullptr) // è½¬æ¢æˆåŠŸï¼Œå¯ä»¥ä½¿ç”¨derivedPtr else // è½¬æ¢å¤±è´¥Base* basePtr2 = new Base(); // æŒ‡å‘åŸºç±»æœ¬èº«Derived* derivedPtr2 = dynamic_castDerived*(basePtr2);// derivedPtr2 å°†æ˜¯ nullptrï¼// å¼•ç”¨è½¬æ¢try Derived derivedRef = dynamic_castDerived(*basePtr); catch (const std::bad_cast e) std::cout è½¬æ¢å¤±è´¥: e.what() std::endl; const_cast å¸¸é‡è½¬æ¢ç”¨äºä¿®æ”¹ç±»å‹çš„ const æˆ– volatile å±æ€§ã€‚è¿™æ˜¯å”¯ä¸€èƒ½â€œå»æ‰â€ const å±æ€§çš„è½¬æ¢æ“ä½œç¬¦ ä¸»è¦ä½¿ç”¨æ–¹å¼å°±æ˜¯å»æ‰constå±æ€§ï¼Œä»¥ä¾¿æ¥å—ä¸€ä¸ªéconstå‚æ•°ä½†æ˜¯ä¸ä¼šä¿®æ”¹è¿˜æ—§API void printString(char* str) // ä¸€ä¸ªæ—§çš„ã€ä¸ä¿®æ”¹strçš„å‡½æ•° std::cout str std::endl;const char* myStr = Hello, World!;// printString(myStr); // é”™è¯¯ï¼šä¸èƒ½å°†const char* ä¼ é€’ç»™char*printString(const_castchar*(myStr)); // å¯è¡Œï¼Œä½†æœ‰é£é™© reinterpret_cast é‡æ–°è§£é‡Šè½¬æ¢è¿›è¡Œä½çº§çš„ã€åº•å±‚çš„ã€â€œé‡æ–°è§£é‡Šâ€æ¯”ç‰¹æ¨¡å¼çš„è½¬æ¢ã€‚å®ƒå¯ä»¥å°†ä¸€ä¸ªæŒ‡é’ˆè½¬æ¢ä¸ºä»»ä½•å…¶ä»–ç±»å‹çš„æŒ‡é’ˆï¼Œç”šè‡³æ˜¯ä¸€ä¸ªæ•´æ•°ã€‚ ä¸è¿›è¡Œä»»ä½•æ ¼å¼æ£€æŸ¥æˆ–å®‰å…¨æ€§æ£€æŸ¥ï¼Œå¯ç§»æ¤æ€§å·® åœºæ™¯ //åœ¨å‡½æ•°æŒ‡é’ˆç±»å‹ä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚//åœ¨æŒ‡é’ˆå’Œè¶³å¤Ÿå¤§çš„æ•´æ•°ç±»å‹ä¹‹é—´è¿›è¡Œè½¬æ¢ï¼ˆå¦‚ void* è½¬ uintptr_tï¼‰ã€‚int* ip = new int(65);// å°†intæŒ‡é’ˆæ¯«æ— å…³ç³»åœ°è½¬æ¢ä¸ºcharæŒ‡é’ˆï¼Œç„¶åæ‰“å°å…¶æŒ‡å‘çš„å€¼char* cp = reinterpret_castchar*(ip);std::cout *cp; // è¾“å‡º A (å› ä¸º65æ˜¯Açš„ASCIIç )","tags":[null]},{"title":"nk01(tx-network)","path":"/notebooks/Interview/nk01(tx-network).html","content":"1.5å±‚ç½‘ç»œåˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Œè®²è®²æ¯å±‚ä»€ä¹ˆåè®®ï¼Œæœ‰ä»€ä¹ˆä¸œè¥¿2.MTUåŒ…å«å“ªäº›å±‚çš„æ•°æ®ï¼Œå¤§å°ä¸€èˆ¬å¤šå¤§æ€ä¹ˆè®¡ç®—3.MTUå’ŒMSSåŒºåˆ«4.TCPæ€ä¹ˆä¿è¯å¯é çš„13.ä½ ä½œä¸ºä¸€ä¸ªä¸€ç«¯çš„ç¨‹åºï¼Œæ˜¯æ€ä¹ˆçŸ¥é“æ˜¯ç½‘ç»œæ‹¥å¡è¿˜æ˜¯æ˜¯é“¾è·¯ä¸¢åŒ…çš„ 27.kä¸ªä¸€ç»„ç¿»è½¬é“¾è¡¨ ä½œè€…ï¼šé™é™åœ°çœ‹ä½ ä»¬è¡¨æ¼”é“¾æ¥ï¼šhttps://www.nowcoder.com/feed/main/detail/ebd659f61ec743d89c402d24311ca250æ¥æºï¼šç‰›å®¢ç½‘","tags":[null,null]},{"title":"ä¾¯æ·C++å†…å­˜ç®¡ç†æœºåˆ¶","path":"/notebooks/Interview/ä¾¯æ·C++å†…å­˜ç®¡ç†æœºåˆ¶.html","content":"C++å†…å­˜è°ƒç”¨ ç¬¬ä¸€èŠ‚ C++ primitives","tags":[null]},{"title":"ai_hpc_cuda","path":"/notebooks/Interview/ai_hpc_cuda.html","content":"NvidiaGPUCUDAç›¸å…³ï¼š1.æè¿°ä¸€ä¸‹SMçš„ç»“æ„ï¼Œåœ¨å†™kernelçš„æ—¶å€™å…±äº«å†…å­˜å¤§å°å’Œå¯„å­˜å™¨æ–‡ä»¶æ•°é‡éœ€è¦æ³¨æ„å—ï¼Ÿ SMæ˜¯NVIDIA GPUçš„æ ¸å¿ƒè®¡ç®—å•å…ƒ,åŒ…å« CUDA coreï¼Œæœ€æ ¸å¿ƒçš„åŸºæœ¬è®¡ç®—å•å…ƒï¼Œå¤„ç†æ•´å½¢å’Œå•ç²¾åº¦æµ®ç‚¹è¿ç®—ã€‚ å¯„å­˜å™¨æ–‡ä»¶ã€ Warp Schedulerçº¿ç¨‹æ•°è°ƒåº¦å™¨ï¼Œ å…±äº«å†…å­˜ L1cache ç­‰ å†™kernelæ—¶å…±äº«å†…å­˜å¤§å°å’Œå¯„å­˜å™¨æ–‡ä»¶æ•°é‡ç›´æ¥å½±å“SMçš„æ´»è·ƒçº¿ç¨‹æŸæ•°é‡ï¼ˆOccupancyï¼‰â€”-å³SMä¸ŠåŒæ—¶å¯æ‰§è¡Œçš„çº¿ç¨‹æŸæ•°ä¸æœ€å¤§å¯æ”¯æŒçº¿ç¨‹æŸæ•°çš„æ¯”ç‡ã€‚ å…±äº«å†…å­˜å¤§å°ï¼š æ³¨æ„ï¼šå¿…é¡»æ³¨æ„ã€‚å…±äº«å†…å­˜æ˜¯æŒ‰å—åˆ†é…çš„æœ‰é™èµ„æºã€‚ å½±å“ï¼šæ¯ä¸ªå—ç”³è¯·çš„å…±äº«å†…å­˜è¶Šå¤§ï¼Œä¸€ä¸ªSMä¸Šèƒ½åŒæ—¶é©»ç•™çš„çº¿ç¨‹å—å°±è¶Šå°‘ï¼Œä¼šé™ä½å ç”¨ç‡ï¼ˆOccupancyï¼‰ï¼Œå¯èƒ½å½±å“æ€§èƒ½ã€‚ å¯„å­˜å™¨æ•°é‡ï¼š æ³¨æ„ï¼šå¿…é¡»æ³¨æ„ã€‚å¯„å­˜å™¨æ˜¯æŒ‰çº¿ç¨‹åˆ†é…çš„æœ‰é™èµ„æºã€‚ å½±å“ï¼š æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨çš„å¯„å­˜å™¨è¶Šå¤šï¼Œä¸€ä¸ªSMä¸Šèƒ½åŒæ—¶é©»ç•™çš„çº¿ç¨‹å°±è¶Šå°‘ï¼ŒåŒæ ·ä¼šé™ä½å ç”¨ç‡ã€‚ å¯„å­˜å™¨ä½¿ç”¨è¿‡å¤šä¼šå¯¼è‡´å¯„å­˜å™¨æº¢å‡ºï¼ˆRegister Spillingï¼‰ï¼Œç¼–è¯‘å™¨è¢«è¿«å°†å˜é‡å­˜å‚¨åˆ°æ…¢é€Ÿçš„å…¨å±€å†…å­˜ä¸­ï¼Œä¸¥é‡æŸå®³æ€§èƒ½ã€‚ 2.å…±äº«å†…å­˜å’Œå¯„å­˜å™¨åˆ†åˆ«åº”è¯¥å­˜æ”¾å“ªäº›æ•°æ®ï¼Œå…¶ç”¨é‡ä¸SMä¸Šæ´»è·ƒçš„çº¿ç¨‹å—çš„å…³ç³»ã€‚å…±äº«å†…å­˜ ä»å…¨å±€å†…å­˜é¢„åŠ è½½çš„æ•°æ®å—ã€ä¸­é—´è®¡ç®—ç»“æœï¼ˆå¦‚è§„çº¦è¿ç®—çš„å±€éƒ¨å’Œï¼‰ ä½œç”¨ï¼šåä½œã€ç¼“å­˜ã€é€šä¿¡ å¯„å­˜å™¨ çº¿ç¨‹ç§æœ‰çš„å±€éƒ¨æ•°æ® ä½œç”¨ï¼šç§æœ‰æ€§ã€é«˜æ€§èƒ½ å…³ç³» SMä¸Šçš„æ´»è·ƒçº¿ç¨‹å—æ•°é‡åŒæ—¶å—å…±äº«å†…å­˜æ€»é‡å’Œå¯„å­˜å™¨æ€»é‡çš„ç¡¬æ€§çº¦æŸï¼Œæœ€ç»ˆçš„å®é™…æ•°é‡æ˜¯ä»¥ä¸‹ä¸‰ä¸ªè®¡ç®—ç»“æœä¸­çš„æœ€å°å€¼ï¼š SMæ”¯æŒçš„æœ€å¤§çº¿ç¨‹å—æ•°ï¼ˆæ¶æ„é™åˆ¶ï¼‰ã€‚ SMå…±äº«å†…å­˜æ€»é‡ / æ¯å—ç”³è¯·çš„å…±äº«å†…å­˜å¤§å°ã€‚ SMå¯„å­˜å™¨æ€»é‡ / (æ¯çº¿ç¨‹å¯„å­˜å™¨æ•°é‡ * æ¯å—çº¿ç¨‹æ•°)ã€‚ 3.bankå†²çªæ˜¯ä»€ä¹ˆï¼Ÿæè¿°å…·ä½“ç»“æ„ï¼Œå¦‚ä½•è§£å†³ï¼ŸBankå†²çªä¸ºäº†æä¾›é«˜å¸¦å®½ï¼Œå…±äº«å†…å­˜è¢«ç‰©ç†ä¸Šåˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªï¼ˆé€šå¸¸æ˜¯32ä¸ªï¼Œä¸Warpå¤§å°å¯¹åº”ï¼‰åŒæ ·å¤§å°çš„ã€èƒ½åŒæ—¶è¢«è®¿é—®çš„å†…å­˜æ¨¡å—ï¼Œè¿™äº›æ¨¡å—ç§°ä¸º Bankã€‚ ç†æƒ³æƒ…å†µï¼ˆæ— å†²çªï¼‰ï¼š å¦‚æœä¸€ä¸ªWarpä¸­çš„32ä¸ªçº¿ç¨‹åˆ†åˆ«è®¿é—®32ä¸ªä¸åŒBankä¸­çš„åœ°å€ï¼ˆæˆ–è€…è®¿é—®åŒä¸€ä¸ªBankä¸­çš„å®Œå…¨ç›¸åŒçš„ä¸€ä¸ªåœ°å€ï¼Œå³å¹¿æ’­ï¼‰ï¼Œé‚£ä¹ˆæ‰€æœ‰è¿™äº›è®¿é—®éƒ½å¯ä»¥åœ¨ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…ä¸€æ¬¡æ€§å®Œæˆã€‚ å†²çªæƒ…å†µï¼š å¦‚æœä¸€ä¸ªWarpä¸­çš„å¤šä¸ªçº¿ç¨‹è®¿é—®äº†åŒä¸€ä¸ªBankä¸­çš„ä¸åŒåœ°å€ï¼Œå°±ä¼šå‘ç”ŸBankå†²çªã€‚ç¡¬ä»¶å¿…é¡»å°†è¿™äº›å†²çªçš„è®¿é—®æ‹†åˆ†æˆå¤šä¸ªæ²¡æœ‰å†²çªçš„å‘¨æœŸä¾æ¬¡æ‰§è¡Œã€‚æœ‰nä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ä¸ªBankçš„ä¸åŒåœ°å€ï¼Œå°±éœ€è¦nä¸ªæ—¶é’Ÿå‘¨æœŸæ¥å®ŒæˆåŸæœ¬ä¸€ä¸ªå‘¨æœŸå°±èƒ½å®Œæˆçš„å·¥ä½œã€‚ Bankç¼–å·Bankç¼–å· (åœ°å€å­—èŠ‚åç§»é‡ 4å­—èŠ‚) % 32 è§£å†³æ ¸å¿ƒæ€è·¯æ˜¯ï¼šæ”¹å˜æ•°æ®åœ¨å…±äº«å†…å­˜ä¸­çš„å¸ƒå±€æˆ–è®¿é—®æ¨¡å¼ï¼Œç¡®ä¿ä¸€ä¸ªWarpå†…çš„çº¿ç¨‹è®¿é—®ä¸åŒçš„Bankã€‚ æ–¹æ³•ä¸€ï¼šå†…å­˜å¡«å……ï¼ˆMemory Paddingï¼‰ é—®é¢˜ï¼š åœ¨æ“ä½œäºŒç»´æ•°ç»„ï¼ˆä¾‹å¦‚çŸ©é˜µï¼‰çš„Tileæ—¶ï¼Œå¦‚æœæ•°ç»„çš„å®½åº¦æ˜¯Bankæ•°é‡ï¼ˆ32ï¼‰çš„æ•´æ•°å€ï¼Œé‚£ä¹ˆåŒä¸€è¡Œä¸­ç›¸é‚»çš„å…ƒç´ ä¼šä½äºä¸åŒçš„Bankï¼Œä½†åŒä¸€åˆ—ä¸­ç›¸é‚»çš„å…ƒç´ ä¼šå› ä¸ºå›ºå®šçš„æ­¥é•¿è€Œè½åœ¨åŒä¸€ä¸ªBanké‡Œã€‚å½“çº¿ç¨‹æŒ‰åˆ—è¯»å–æ—¶ï¼Œå°±ä¼šå¯¼è‡´ä¸¥é‡çš„Bankå†²çªã€‚ è§£å†³æ–¹æ¡ˆï¼š åœ¨å£°æ˜å…±äº«å†…å­˜æ•°ç»„æ—¶ï¼Œäººä¸ºåœ°ç»™æ¯ä¸€è¡Œå¢åŠ ä¸€äº›å¤šä½™çš„â€œå¡«å……â€å…ƒç´ ï¼Œä½¿å®é™…çš„è¡Œé•¿ï¼ˆPitchï¼‰ä¸å†æ˜¯32çš„æ•´æ•°å€ã€‚ ç¤ºä¾‹ï¼šä¸€ä¸ª32x32çš„Tile cpp // å¯èƒ½äº§ç”ŸBankå†²çªçš„å£°æ˜__shared__ float tile[32][32];// ä½¿ç”¨å¡«å……é¿å…Bankå†²çªçš„å£°æ˜ï¼ˆä¾‹å¦‚ï¼Œå¤šåŠ 1ä¸ªå…ƒç´ ï¼‰__shared__ float tile_padded[32][33]; // 33ä¸å†æ˜¯32çš„å› æ•° è¿™æ ·ï¼ŒåŸæ¥åœ¨åŒä¸€åˆ—ä¸Šçš„å…ƒç´  tile[0][0], tile[1][0], tile[2][0]â€¦ ç°åœ¨å˜æˆäº† tile_padded[0][0], tile_padded[1][0], tile_padded[2][0]â€¦ã€‚è®¡ç®—å®ƒä»¬çš„Bankç¼–å·ï¼š (0 / 4) % 32 = 0 ( (1 * 33 * 4) / 4 ) % 32 = (33) % 32 = 1 ( (2 * 33 * 4) / 4 ) % 32 = (66) % 32 = 2å®ƒä»¬è¢«å·§å¦™åœ°åˆ†æ•£åˆ°äº†ä¸åŒçš„Bankä¸­ï¼Œä»è€Œé¿å…äº†å†²çªã€‚ æ–¹æ³•äºŒï¼šæ”¹å˜è®¿é—®æ¨¡å¼æˆ–ç®—æ³•è®¾è®¡æ ¸å‡½æ•°æ—¶ï¼Œå°½é‡è®©ä¸€ä¸ªWarpå†…çš„çº¿ç¨‹è®¿é—®è¿ç»­çš„å…±äº«å†…å­˜åœ°å€ã€‚å› ä¸ºè¿ç»­åœ°å€é€šå¸¸æ˜ å°„åˆ°ä¸åŒçš„Bankï¼Œè¿™æ˜¯æœ€å‹å¥½çš„è®¿é—®æ¨¡å¼ã€‚ æ–¹æ³•ä¸‰ï¼šä½¿ç”¨ä¸åŒçš„å¹¿æ’­æœºåˆ¶å¦‚æœç¡®å®éœ€è¦è®©å¤šä¸ªçº¿ç¨‹è¯»å–åŒä¸€ä¸ªå€¼ï¼Œåº”å°½é‡ç¡®ä¿å®ƒä»¬è®¿é—®çš„æ˜¯å®Œå…¨ç›¸åŒçš„åœ°å€ï¼Œè¿™ä¼šè§¦å‘å¹¿æ’­æœºåˆ¶ï¼Œåœ¨ä¸€ä¸ªå‘¨æœŸå†…å®Œæˆæ“ä½œï¼Œè€Œä¸æ˜¯äº§ç”Ÿå†²çªã€‚ 4.è¯´ä¸€ä¸‹åˆ†æ”¯å†²çªï¼ˆçº¿ç¨‹æŸåˆ†åŒ–ï¼‰ï¼Œå¦‚æœwarpå†…æœ‰å†²çªï¼Œéƒ¨åˆ†ç¬¦åˆifæ¡ä»¶ï¼Œéƒ¨åˆ†ç¬¦åˆelseæ¡ä»¶ï¼Œæ˜¯å¦éœ€è¦ç­‰å¾…ï¼Ÿåˆ†æ”¯å†²çªå‘ç”Ÿåœ¨åŒä¸€ä¸ªWarpå†…éƒ¨çš„çº¿ç¨‹æ‰§è¡Œäº†ä¸åŒçš„æ§åˆ¶æµè·¯å¾„æ—¶ã€‚ä¾‹å¦‚ï¼Œéƒ¨åˆ†çº¿ç¨‹æ»¡è¶³ifæ¡ä»¶ï¼Œè€Œå¦ä¸€éƒ¨åˆ†çº¿ç¨‹æ»¡è¶³elseæ¡ä»¶ã€‚ ä¸²è¡ŒåŒ–æ‰§è¡Œï¼š GPUçš„Warpè°ƒåº¦å™¨ä¼šè®©Warpå…ˆæ‰§è¡Œæ‰€æœ‰èµ°ifè·¯å¾„çš„çº¿ç¨‹ã€‚æ­¤æ—¶ï¼Œé‚£äº›æœ¬è¯¥èµ°elseè·¯å¾„çš„çº¿ç¨‹åœ¨è¿™ä¸ªé˜¶æ®µæ˜¯è¢«ç¦ç”¨ï¼ˆmasked outï¼‰ çš„ï¼Œå®ƒä»¬ä¸ä¼šæ‰§è¡Œä»»ä½•æ“ä½œï¼Œä½†å¿…é¡»ç­‰å¾…ã€‚ å†æ¬¡æ‰§è¡Œï¼š å½“ifè·¯å¾„æ‰§è¡Œå®Œæ¯•åï¼Œè°ƒåº¦å™¨ä¼šå†è®©Warpæ‰§è¡Œæ‰€æœ‰èµ°elseè·¯å¾„çš„çº¿ç¨‹ã€‚åŒæ ·ï¼Œæ­¤æ—¶èµ°ifè·¯å¾„çš„çº¿ç¨‹è¢«ç¦ç”¨å¹¶ç­‰å¾…ã€‚ æ±‡åˆåç»§ç»­ï¼š å½“æ‰€æœ‰ä¸åŒçš„æ§åˆ¶æµè·¯å¾„éƒ½æ‰§è¡Œå®Œæ¯•åï¼ŒWarpå†…çš„æ‰€æœ‰çº¿ç¨‹æ‰ä¼šåœ¨æ±‡åˆç‚¹ï¼ˆreconvergence pointï¼‰ é‡æ–°åŒæ­¥ï¼Œå¹¶ç»§ç»­ä¸€èµ·æ‰§è¡Œåç»­çš„ç›¸åŒæŒ‡ä»¤ã€‚ å› æ­¤ï¼Œåˆ†æ”¯å†²çªçš„æ€§èƒ½ä»£ä»·æ˜¯ï¼šæ‰§è¡Œæ—¶é—´å˜æˆäº†æ‰€æœ‰ä¸åŒè·¯å¾„æ‰§è¡Œæ—¶é—´çš„æ€»å’Œï¼Œè€Œä¸æ˜¯å…¶ä¸­æœ€é•¿è·¯å¾„çš„æ—¶é—´ã€‚ æ€æ ·é¿å…çº¿ç¨‹æŸåˆ†åŒ– æ ¸å¿ƒæ€æƒ³ï¼šåŒä¸€ä¸ªWarpå†…çš„æ•°æ®å…·æœ‰ç›¸åŒçš„ç‰¹æ€§ï¼Œä»è€Œæ‰§è¡Œç›¸åŒçš„æŒ‡ä»¤è·¯å¾„ã€‚ é¢„å¤„ç†æ•°æ®ï¼Œä½¿åŒä¸€Warpæ•°æ®ç‰¹å¾ä¸€è‡´ è°“è¯æ‰§è¡Œ ç”¨æ¡ä»¶èµ‹å€¼ ?: æ›¿ä»£çŸ­å°çš„ if-else 5.ç”¨è¿‡TensorCoreå—ï¼Ÿäº†è§£TensorCoreçš„åŸç†å—ï¼ŸTensor Coreæ˜¯ä¸€ç§ä¸“ä¸ºæ‰§è¡ŒçŸ©é˜µä¹˜ç´¯åŠ è¿ç®—è€Œè®¾è®¡çš„ä¸“ç”¨ç¡¬ä»¶å•å…ƒï¼Œä»Voltaæ¶æ„å¼€å§‹å¼•å…¥ã€‚å…¶æ ¸å¿ƒåŸç†å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š 1. è®¡ç®—æ¨¡å¼ï¼šD A * B + Cå®ƒçš„æ ¸å¿ƒæ˜¯æ‰§è¡Œä¸€ä¸ªå›ºå®šçš„è®¡ç®—æ“ä½œï¼šæ¥æ”¶ä¸¤ä¸ªå°çŸ©é˜µAå’ŒBï¼Œä¸ä¸€ä¸ªç´¯åŠ çŸ©é˜µCç›¸ä¹˜åç›¸åŠ ï¼Œå¾—åˆ°ç»“æœçŸ©é˜µDã€‚ A, B, C, D éƒ½æ˜¯ç‰¹å®šç»´åº¦çš„å°çŸ©é˜µï¼ˆå¦‚ 16x16, 8x32, 32x8 ç­‰ï¼‰ã€‚ è®¡ç®—A * Bæ˜¯å®Œæ•´ç²¾åº¦çš„ï¼Œå…¶ç»“æœä¸Cç›¸åŠ åï¼Œå†ä»¥ç›®æ ‡ç²¾åº¦ï¼ˆå¦‚FP32FP16INT8ï¼‰å­˜å‚¨åˆ°Dã€‚ 2. æ··åˆç²¾åº¦è®¡ç®—ï¼šè¿™æ˜¯å…¶å®ç°æ€§èƒ½çªç ´çš„å…³é”®ã€‚å®ƒä½¿ç”¨ä½ç²¾åº¦è¾“å…¥æ¥å®ç°é«˜ååé‡å’Œä½åŠŸè€—ï¼Œä½†ä½¿ç”¨é«˜ç²¾åº¦è¿›è¡Œç´¯åŠ ä»¥ä¿æŒæ•°å€¼ç¨³å®šæ€§ã€‚ å¸¸è§æ¨¡å¼ï¼š FP16 è¾“å…¥ (A, B) + FP16 æˆ– FP32 çš„ç´¯åŠ å™¨ (C) - FP16 æˆ– FP32 è¾“å‡º (D)ã€‚ å…¶ä»–æ¨¡å¼ï¼š ä¹Ÿæ”¯æŒINT8ã€INT4ã€BF16ç­‰è¾“å…¥ç²¾åº¦ï¼Œä»¥åŠTF32ï¼ˆåœ¨AmpereåŠä»¥åæ¶æ„ä¸­ï¼‰ã€‚ 3. æé«˜çš„ååé‡ï¼šæ¯ä¸ªTensor Coreæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥æ‰§è¡Œå¤§é‡çš„ä¹˜åŠ è¿ç®—ï¼ˆFMA operationsï¼‰ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªV100çš„SMä¸­çš„æ¯ä¸ªTensor Coreæ¯å‘¨æœŸå¯ä»¥æ‰§è¡Œä¸€ä¸ª 8x4 * 4x8 - 8x8 çš„MMAæ“ä½œï¼Œè¿™ç›¸å½“äº 64 æ¬¡ä¹˜åŠ è¿ç®—ï¼ˆ128 FLOPSï¼‰ æ¯å‘¨æœŸã€‚è¿™ä¸ä¼ ç»Ÿçš„CUDA Coreï¼ˆæ¯å‘¨æœŸ1æ¬¡ä¹˜åŠ ï¼‰ç›¸æ¯”ï¼Œååé‡æå‡äº†ä¸¤ä¸ªæ•°é‡çº§ã€‚ 4. ç¼–ç¨‹æ¨¡å‹ï¼šWarp-Level OperationTensor Coreçš„æ“ä½œæ˜¯åœ¨çº¿ç¨‹æŸçº§åˆ«è¿›è¡Œçš„ã€‚ä¸€ä¸ªWarpå†…çš„çº¿ç¨‹éœ€è¦åä½œæ¥å…±åŒåŠ è½½ä¸€ä¸ªå¤§çš„è¾“å…¥çŸ©é˜µçš„å„ä¸ªå°å—ï¼ˆTileï¼‰åˆ°å¯„å­˜å™¨ä¸­ï¼Œç„¶åè°ƒç”¨ä¸€æ¡æŒ‡ä»¤ï¼ˆå¦‚wmma::mma_syncï¼‰æ¥è®©Tensor Coreç¡¬ä»¶æ‰§è¡Œæ•´ä¸ªå°çŸ©é˜µçš„è¿ç®—ã€‚ ä¸ºä»€ä¹ˆç”¨float4å‘é‡æ¥å­˜å–æ•°æ®ï¼Ÿæœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ ä¸ºä»€ä¹ˆç”¨åŒç¼“å†²ä¼˜åŒ–ï¼Ÿäº†è§£cudaæµå’Œcuda graphå—ï¼Ÿ é™¤äº†MPIï¼Œæœ‰çŸ¥é“ç°åœ¨ç”¨çš„æ›´å¤šçš„GPUé€šä¿¡åº“å—ï¼Ÿ åœ¨Nsight Computingä¸­ï¼Œç»å¸¸å…³æ³¨çš„ä¸å†…å­˜ç›¸å…³çš„æŒ‡æ ‡ã€‚æœ‰å…³æ³¨L1 Cacheå‘½ä¸­ç‡å—ï¼Ÿ GPUæŒ‡ä»¤é›†ä¼˜åŒ–æ–¹é¢äº†è§£å—ï¼Ÿæœ‰åšè¿‡PTXç›¸å…³çš„ä¼˜åŒ–å—ï¼Ÿ GEMMæ˜¯è®¡ç®—å¯†é›†å‹è¿˜æ˜¯è®¿å­˜å¯†é›†å‹ç®—å­ï¼Ÿ çŸ¥é“cutlassä¸­å¦‚ä½•å¯¹GEMMè¿›è¡Œä¼˜åŒ–çš„å—ï¼Ÿ è®­ç»ƒæ¨ç†äº†è§£Transformerå—ï¼Ÿåº•å±‚æ˜¯ä»€ä¹ˆç»“æ„ï¼Ÿcudaä¸­å¦‚ä½•ä¼˜åŒ–ï¼Ÿè¯´ä¸€ä¸‹ä½ å¯¹å¤§æ¨¡å‹çš„ç†è§£ã€‚cudaä¸­å¦‚ä½•å†™Softmaxï¼ŸæŸä¸ªå‚æ•°è¿‡å¤§å¦‚ä½•è§£å†³ï¼ŸDropoutå’ŒBatchNormåœ¨è®­ç»ƒå’Œæ¨ç†æ—¶æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿè¯´ä¸€ä¸‹ä½ äº†è§£çš„æ— ç›‘ç£å­¦ä¹ ç®—æ³•ã€‚çŸ¥é“Faster Transformerå—ï¼Ÿæœ‰äº†è§£å¦‚ä½•å®ç°çš„å—ï¼ŸPaged Attentionæœ‰äº†è§£å—ï¼ŸçŸ¥é“TensorRTå—ï¼Ÿéƒ¨ç½²è¿‡æ¨ç†æ¨¡å‹å—ï¼Ÿ","tags":[null,null]},{"title":"æ§å°é¡¹ç›®ä¸iSeté¡¹ç›®å·²ä½¿ç”¨QtæŠ€èƒ½ç‚¹æ•´ç†","path":"/notebooks/Interview/æŠ€èƒ½ç‚¹æ•´ç†.html","content":"Qtä¸QMLçŸ¥è¯†æ€»ç»“Qtä¸­çš„è®¾è®¡æ¨¡å¼ä¸­é—´æ»‘åŠ¨çš„slider 2. doubleSpinBox3. iSetæ–°å»ºé¡¹ç›®çš„ä¸¤ç§æ¨¡å¼ListWidgetã€é€‰ä¸­çŠ¶æ€è®¾ç½®ä¸ºå›¾æ ‡æ¨¡å¼4.QTreeWidget æ¡†æ¶ã€è¡¨å¤´ã€æ ·å¼è¡¨ã€ä»£ç† Qt QTreeWidgetæ ‘å½¢æ§ä»¶ç”¨æ³•è¯¦è§£_qtreewidgetç”¨æ³•_ç¿ç§‘çŸ¥è¯†äº‘çš„åšå®¢-CSDNåšå®¢ 2. Qtå¤§æ¨¡å—1. Qt DPæŒ‡é’ˆ2. è§†å›¾æ¨¡å‹æœºåˆ¶3. è§†å›¾æ¡†æ¶4. QStyle é«˜åº¦è‡ªå®šä¹‰å®ç°5. å…ƒå¯¹è±¡ä¸ä¿¡å·æ§½æœºåˆ¶6.æ„å»ºç³»ç»Ÿ7.QInvokeMethod8.å›½é™…åŒ–3. Qtç»†èŠ‚1. åŸºç¡€æ§ä»¶2. Undoæ“ä½œ3. svgæ“ä½œ4. Qtä¸åœ¨å¯¹è±¡æ ‘çš„å·¥å…·æ±‡æ€»5.Qtä¸­æœ‰æœ‰ç”¨çš„å®ï¼šQ_LIKELY 6.paintåœ¨installä¸­ç»˜åˆ¶ 4. Qté”¦ä¸Šæ·»èŠ±1. åŠ¨ç”»çŸ¥è¯†2. æ‹–æ‹½3. æ’ä»¶æœºåˆ¶4.æ¨¡å—åŒ–æ„å»º5. Qtä¸­çš„è®¾è®¡æ¨¡å¼1. å•ä¾‹æ¨¡å¼2. è´£ä»»é“¾æ¨¡å¼3. æ¥å£æ¨¡å¼4. é€‚é…å™¨æ¨¡å¼5.è§‚å¯Ÿè€…æ¨¡å¼ï¼Œ çº¿ç¨‹è§‚å¯Ÿã€æ—¶é—´å‹ç¼© 6.å…¨å±€ä¿¡å·å•ä¾‹è½¬å‘ç±» MAINOPERATIONVIEW_EXPORT bool MainOperationView_Init(IISetWidget ** ppWidget, QWidget * parent) if (ppWidget == nullptr || parent == nullptr) return false; *ppWidget = new CMainOperationView(parent); return true; 6. C++çŸ¥è¯†c++11æ–°ç‰¹æ€§ï¼Œæ‰€æœ‰çŸ¥è¯†ç‚¹éƒ½åœ¨è¿™äº†ï¼ - çŸ¥ä¹ (zhihu.com) this_thread ++ lambdaçš„å‘ for(int id = enCoef9_Rr ; id = enCoef9_Bb ;id++) connect(m_spinBoxs[id],QOverloaddouble::of(QDoubleSpinBox::valueChanged),this,[](double value) OnCoefMatrixSlot(id,value); ); id æ’ç­‰äº 0 å¤šç»§æ‰¿ä¸QOBject private è™šç»§æ‰¿ class CBaseprivate:\tvirtual void virtualPrivateFuntion() std::coutbase virtualPrivateFuntion;\tï¼›class CSub :public CBase\tprivate:\tvirtual void virtualPrivateFuntion() override std::coutsub virtualPrivateFuntion;\tint main()\tCBase* pObject = new CSub();\tpObject-virtualPrivateFuntion();//ç»“æœï¼šsub virtualPrivateFuntionï¼Œ//ç»“è®ºï¼šå­ç±»ç»§æ‰¿çˆ¶ç±»çš„private virtualå¯ä»¥é‡å†™ å¯å˜å‚æ•°ã€å˜å‚æ¨¡æ¿ å‡½æ•°åŒ…è£…å™¨ std::shared_ptrresetã€make_shared å³å€¼å¼•ç”¨C++åå°„å…ƒç¼–ç¨‹Metaprogram is a program about a program. 7.æ‚é¡¹QStatusBaræ’ä»¶æœºåˆ¶è§£è€¦å¿«æ·é”®ISet7.0 æ¥å£è®¾è®¡ MVC8.è½®å­1.å•ä¾‹2.å·¥ä½œçº¿ç¨‹å°è£…3.stl è¿­ä»£å™¨æ¨¡å¼å’Œé€‚é…å™¨æ¨¡å¼æŠ¥é”™æ•´ç†ï¼š QMenu æ²¡æœ‰æ·»åŠ Actionæ—¶ï¼Œä¸èƒ½ç›´æ¥visibleæˆ–è¿™execï¼› setGeometry: Unable to set geometry çš„ä¸€ç§è§£å†³åŠæ³•æ˜¯é‡å†™sizehintï¼Œè€Œä¸æ˜¯ä½¿ç”¨setFixedSizeï¼› å·¥å…·ä½¿ç”¨AddressSanitizerï¼ˆä¸é€‚ç”¨ä¸MinGWï¼‰[AddressSanitizer å®šä½åµŒå…¥å¼cc++å†…å­˜é”™è¯¯ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/436177229#:~:text=AddressSanitizer ï¼ˆåˆå ASanï¼‰æ˜¯ C%2FC%2B%2B çš„å†…å­˜é”™è¯¯æ£€æµ‹å™¨ã€‚ AddressSanitizer ç”± google,çš„ä¸€éƒ¨åˆ†ï¼Œè€Œä» 4.8 ç‰ˆå¼€å§‹é€æ¸æˆä¸º GCC çš„ä¸€éƒ¨åˆ†ã€‚ è¿™ä¹Ÿæ„å‘³ç€å¦‚æœäº¤å‰ç¼–è¯‘å™¨ç‰ˆæœ¬ä½äº 4.8 ï¼Œæ˜¯æ— æ³•ä½¿ç”¨çš„ã€‚) Qt æ‹¾é— 008 åœ¨ Qt ä¸­ä½¿ç”¨ Address Sanitizer - ç®€ä¹¦ (jianshu.com) åœ¨Qtä¸­ä½¿ç”¨gcc 4.8.0çš„åœ°å€æ¶ˆæ¯’å‰‚(Address Sanitizer) MTunerè½¯ä»¶ã€ç²¾é€‰ã€‘åŸºäºMTunerè½¯ä»¶è¿›è¡Œqtçš„mingwç¼–è¯‘ç¨‹åºçš„å†…å­˜æ³„æ¼æ£€æµ‹_mtuneræ€ä¹ˆä½¿ç”¨_yantuguiguziPGJçš„åšå®¢-CSDNåšå®¢","tags":[null]},{"title":"Hexo","path":"/notebooks/other/hexo.html","content":"Hexoéƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°çš„ä¸€äº›é—®é¢˜å›¾ç‰‡ä¸Typoraå…¼å®¹ç½‘ä¸Šç»™äº†å¾ˆå¤šæ–¹æ³•ï¼Œå°è¯•æ²¡æœ‰æ•ˆæœï¼Œè‡ªå·±å°è¯•çš„æ–¹æ¡ˆï¼š å¸è½½æ’ä»¶hexo-asset-image: yarn remove hexo-asset-image,GitHubæœ‰ä¿®æ”¹çš„å¯¹åº”æ’ä»¶ï¼Œä½†æ˜¯ä½¿ç”¨æ— æ•ˆæœ typoraé…ç½® Typoraæ–°æ’å…¥å›¾ç‰‡è·¯å¾„æ˜¾ç¤ºä¸ºï¼š Hexoéƒ¨ç½²æ—¶æ­£å¸¸æ˜¾ç¤º Hexoä¸ç”Ÿæ•ˆé—®é¢˜Hexoéƒ¨ç½²åˆ°githubä¸Šä¸ç”Ÿæ•ˆï¼Œç½‘ä¸Šè§£å†³æ–¹æ¡ˆè¯´éœ€è¦é™¤Mainæˆ–è€…Masteråˆ†æ”¯ä»¥å¤–é¢å¤–æ„å»ºä¸€ä¸ªåˆ†æ”¯ï¼Œç„¶åç½‘ç«™æ¨é€åˆ°è¿™ä¸ªåˆ†æ”¯ä¸Šï¼Œå®é™…ä½¿ç”¨ä¸ç®¡ç”¨ã€‚ é¦–å…ˆï¼Œåªéœ€è¦ç»´æŠ¤ä¸€ä¸ªä¸»åˆ†æ”¯ï¼Œä¸éœ€è¦å…¶ä»–åˆ†æ”¯ï¼› å…¶æ¬¡ï¼Œhexo -dæ‰§è¡Œä»¥åï¼Œmainåˆ†æ”¯ä¸­å³ä½¿å·²ç»æ›´æ–°äº†ä»£ç ï¼Œä½†æ˜¯github pageæ›´æ–°ä¹Ÿéœ€è¦ä¸€æ®µæ—¶é—´ï¼Œéƒ¨ç½²é¢‘ç¹ä¼šäº§ç”Ÿæ’é˜Ÿ ä»“åº“ä¸»é¡µgithub-pagesä¸Šå¯ä»¥è§‚å¯Ÿåˆ°ç”Ÿæˆé™æ€é¡µé¢çš„è¿›åº¦ã€‚","tags":[null]},{"title":"perfä½¿ç”¨","path":"/notebooks/other/perfä½¿ç”¨.html","content":"Perfä½¿ç”¨ æ‚è®°1.æ–‡æ¡£1.man+perf -hé‡åˆ°æ–°å·¥å…·å½“ç„¶æœ€å¥½çš„æ–¹å¼æ˜¯è¯»æ–‡æ¡£ï¼Œä½†æ˜¯ç½‘ç»œä¸Šæ‰¾åŠå¤©ä¹Ÿæ²¡æœ‰æ‰¾åˆ°å¾ˆå¥½çš„perfæ‰‹å†Œï¼Œæœ€åå‘ç°åœ¨GPTçš„æŒ‡å¼•ä¸‹ï¼Œæœ€å¥½çš„æ‰‹å†Œå®³å¾—æ˜¯linux manæ‰‹å†Œã€‚ ä¸Šæ‰‹æœ€å¿«æœ€å…¨é¢çš„æ–¹å¼ï¼šhelp+man é¦–å…ˆperf -hæŸ¥çœ‹å„æ¡å­å‘½ä»¤åŸºæœ¬åŠŸèƒ½ã€‚ åœ¨ä½¿ç”¨å­å‘½ä»¤æ—¶ man perf-recordã€man perf-scriptæŸ¥çœ‹å„æ¡å­å‘½ä»¤çš„è¯¦ç»†åŠŸèƒ½ã€‚ è¸©å‘æ¡ˆä¾‹ï¼š æŠ˜è…¾åŠå¤©perf recordè®°å½•çš„L3 missï¼Œperf scriptæŸ¥çœ‹å¯¹åº”çš„ç»“æœï¼Œå‘ç°é‡Œé¢æœ‰ä¸€äº›åœ°å€ï¼Œå’Œç¨‹åºmallocæ—¶çš„åœ°å€è¿›è¡ŒåŒ¹é…å‘ç°éƒ½æ²¡æœ‰è®¿é—®ç¨‹åºmallocçš„ä½ç½®ï¼Œæœ€åå‘ç°å…¶ä¸­çš„åœ°å€æ˜¯ipè€Œä¸æ˜¯è®¿é—®çš„å†…å­˜åœ°å€ã€‚å‡ ç•ªæŸ¥æ‰¾èµ„æ–™æ— æœï¼Œæœ€åå‘ç°perf recordä¸­ä½¿ç”¨-då‚æ•°æ‰ä¼šæ˜¾ç¤ºaddr 2.eventæŸ¥çœ‹å„ä¸ªäº‹ä»¶çš„è¯¦ç»†æè¿°ï¼Œåœ¨intel å®˜æ–¹çš„äº‹ä»¶åº“ä¸­æŸ¥æ‰¾å¯¹åº”çš„äº‹ä»¶åŠŸèƒ½ https://perfmon-events.intel.com/index.html?pltfrm=skylake_server.html 3.æ–‡ç« ä¸ä¼˜åŒ–æ¡ˆä¾‹https://www.brendangregg.com/ https://weedge.github.io/perf-book-cn/zh/chapters/3-CPU-Microarchitecture/3-8_Modern_CPU_design_cn.html 2.è¸©å‘æ‚è®°perfäº‹ä»¶å†²çª","tags":[null]},{"title":"ASPLOS`25 Systematic CXL Memory Characterization and Performance Analysis at Scale","path":"/notebooks/paper/ASPLOS-25-Systematic-CXL-Memory-Characterization-and-Performance-Analysis-at-Scale.html","content":"Systematic CXL Memory Characterization and Performance Analysis at Scale Jinshu Liu Virginia Tech https://github.com/MoatLab/Melody 1.IntroductionCurrently, there is a significant gap in research that explores detailed CXL characteristics and their impact on memory-intensive workloads at scale, in depth, and across the full spectrum of sub-Î¼s latencies. In particular, how do CXL devices differ in detailed performance characteristics beyond average latency and bandwidth metrics? How (much) does CXLâ€™s long (and longer) latency affect CPU efficiency and workload performance? What are the underlying causes and how do we analyze it? Exsiting works focus on coarse-grained analysis and overlook several critical aspects: (i) CXL performance stability (i.e., tail latencies); (ii) CPU tolerance to prolonged CXL latencies across various workloads, and the architectural implications of CXL; and (iii) the lack of systematic approach to dissect workload performance and CPU inefficiency under CXL. So: introduce Melody, a comprehensive framework for detailed CXL performance characterization. The first analysis of CXL characteristics beyond average latency and bandwidth across 4 real CXL devices. An extensive evaluation of CXLâ€™s performance implications across diverse workloads. A systematic approach for workload performance analysis under CXL. contributions(in my view): â€‹\t1.MELODY,a framwork to measure CXL perfomence. â€‹\t2.An in-depth study of CXL tail latencies (like caption). â€‹\t3.Root-cause analysis approach 2.BackgroundHow CPU backend and CXL MC process Load and Store request? .nnbutvhwqoog{zoom:200%;} Request types: The CPU issues two types of load requests: Demand and Prefetch. Demand loads are memory reads that CPU requests from (CXL) MC only when it is needed for computation. Prefetch reads are predictive reads directed by prefetchers, e.g., â€œL1PFâ€ and â€œL2PFâ€ in Figure 2a. Stores are first queued in the â€œstore buffer.â€ Each store request triggers a Read-for-ownership (RFO) for cache coherence from CXLDRAM, followed by a Write upon cache eviction. MC ï¼š Memory requests to the CXL MC are encapsulated(compress) in a specific packet format, known as Flits , for transmission over CXLPCIe. Upon arrival, the CXL controller (â€œCXL Ctrlâ€) parses the request and places it in the request queue. The request scheduler then selects the next request to process based on the scheduling policy and other factors such as thermal management for low latency, high bandwidth, and reliability. Requests are then passed to the command scheduler, which issues appropriate low-level DDR commands to the DRAM chips. 3.CXL Device Characterization3.1 Testbed Concern: work load: cloud workloads (in-memory caching and databases such as Redis [13] and VoltDB [21], CloudSuite [1], and Phoronix [12]), graph processing (GAPBS [22], PBBS [19]), data analytics (Spark [30]), MLAI (GPT-2 [5], MLPerf [14], Llama [9]), SPEC CPU 2017 [18], and PARSEC [24]. 3.2 CXL latency stability and its relationship with bandwidth Terms distinction: Loaded latencies: memory access latency under high utilization Idle latency: occurs when the system experiences minimal load è¿™ä¸€éƒ¨åˆ†å®ç°äº†ä¸€ä¸ªMIOï¼Œé€šè¿‡å¤šæ¬¡æŒ‡é’ˆè¿½è¸ªè®°å½•ä¸€æ¬¡rdtscæ—¶é—´æˆ³æ¥è®¡ç®—average latencyï¼Œå¹¶é‡‡ç”¨MLCæ¥éªŒè¯MIOã€‚æµ‹è¯•äº†ä¸€äº›tail latency ä¸bandwidthä¹‹é—´çš„å…³ç³»ï¼Œç»“æœå‡å¯ä»¥æƒ³åˆ°ã€‚ ä¸€ä¸ªæµ‹é‡å†…å­˜å‹åŠ›çš„æ–¹æ³•ï¼šå°†æŒ‡é’ˆè¿½è¸ªè®¿é—®çº¿ç¨‹å’Œ32ä¸ªAVXè®¿å­˜çº¿ç¨‹ä¸€èµ·bindåˆ°ä¸€ä¸ªnuma nod(co-locate) CXL latency vs. bandwidth under various readwrite ratios. Local DRAM achieves the highest bandwidth under a read-only workload, whereas NUMA and all CXL devices (except CXL-C) achieve minimal bandwidth in read-only scenarios. This is because NUMA and CXL links are bidirectional, allowing them to sustain higher bandwidth under mixed readwrite workloads CXL devices demonstrate significant variability Impact of CPU prefetchers on (tail) latency. Prefetching does not fully mitigate CXL-induced tail latencies. Reasoning. æœ¬èŠ‚ä¸­æµ‹å‡ºçš„ç»“æœå‘ç°å°¾å»¶è¿Ÿç­‰æ€§èƒ½å·®è·å¾ˆå¤§ï¼Œè¿™æ ·çš„ç»“è®ºå…¶å®ä½œç”¨ä¸å¤§ã€‚ä½†æ˜¯æ€§èƒ½å·®å¼‚å¤§å¯ä»¥ä½œä¸ºå…¶ä»–æ€§èƒ½ç ”ç©¶çš„æŒ‘æˆ˜å’ŒåŠ¨æœº 1.CXLåè®®ä¼ è¾“å±‚ä¸è¿æ¥å±‚çš„å®ç°æœ¬èº«å¼•å…¥äº†æ€§èƒ½å¼€é”€ 2.MC æ§åˆ¶å™¨å®ç°æœ¬èº« 4 Workload Characterization è®¨è®ºäº†ä¸€äº›å·¥ä½œè´Ÿè½½çš„å»¶è¿Ÿæ•æ„Ÿæ€§ç­‰ï¼Œæ­¤å‰è®ºæ–‡å·²ç»æœ‰è¿‡ 5 Spa for CXL Slowdown Analysis5.2 Challenges and Limitations of State-of-the-ArtChallenge:1.Identifying the underlying CPU eventsmetrics that can correlate to the slowdowns is challenging. It is even more challenging to establish a precise correlation between workload performance and architecture-level performance metrics, Why not TMA? TMA does not provide a differential analysis to interpret pipeline differences resulting from varying backend memory (i.e., CXL vs. local DRAM). TMA is unable to precisely correlate architecture level metrics with workload slowdowns. 5.3 Spa: A Bottom-Up Approach DRAM (Demand Load) Slowdown:These misses denote demand read misses, excluding RFO and prefetch requests. Store Slowdown :Incoming store requests queued in the store buffer are dequeued upon completion. Some writes issue RFO requests before execution. If the store buffer fills up, these RFOs would hinder load efficiency, causing CPU stalls. Cache Slowdown:On SKX, most cache slowdown occurs in L2 due to a significant rise in stall cycles for L1 load misses with CXL. Conversely, on SPREMR, LLC experiences the bulk of slowdown, with a notable increase in stall cycles for L2 load misses with CXL. key finding: This reduces L2 prefetcherâ€™s coverage of both demand reads and L1 prefetch. L1 prefetches would either miss entirely in L2 or at best, they would hit on a pending L2 prefetch in L2. Consequently, CXL also negatively impacts L1 prefetcherâ€™s timeliness.Loads that would have otherwise hit in the cache if L1 prefetches were timely, now are delayed. Consequently, overall prefetch efficiency suffers and stalls on caches increase. ç”±äºCXLçš„é•¿å»¶è¿Ÿï¼ŒL2é¢„å–çš„ä¿¡æ¯æ—¶æ•ˆæ€§é™ä½ï¼Œå½“L1éœ€è¦ç›¸åº”æ•°æ®çš„æ—¶å€™ï¼ŒL2è¿˜æ²¡æœ‰é¢„å–å›æ¥ï¼Œå¯¼è‡´L1è®¤ä¸ºmissï¼Œäºæ˜¯è®¿é—®L2,å†æ¬¡å‘å‡ºè¯·æ±‚ã€‚åŸæœ¬å¯ä»¥å‘½ä¸­çš„Loadè¯·æ±‚å˜å¾—ä¸å‘½ä¸­ã€‚ intelæ²¡æœ‰è®¡æ•°å™¨ç›´æ¥è§‚æµ‹L1Pf-L2-hitä¸missçš„æƒ…å†µï¼Œå¯ä»¥é€šè¿‡ä¸€äº›å…¶ä»–çš„è®¡æ•°å™¨é—´æ¥çš„è§‚æµ‹æƒ…å†µã€‚ å‘ç°ï¼šL2PF-L3-misså‡å°‘ï¼ŒL1PF-L3-misså¢å¤šï¼ŒL2PFL3-hitä¸å˜ï¼Œå› æ­¤æ¨å¯¼å‡ºï¼šL2é¢„å–å™¨ä½æ•ˆé¢„å–ï¼ŒL1é¢„å–å¢å¤šã€‚ 5.5 5.6 Workload Slowdown Diversity Period-based Slowdown AnalysisAn approach to convert time-based sampling data into a period-based slowdown analysis. 5.7 Spa Use CasesPerformance tuning. For example, to mitigate the slowdown bursts observed in 605.mcf (Figure 16b), we first identify memory accesses during bursty periods (e.g., exceeding 10%) using binary instrumentation via Intel Pin. Next, we pinpoint the source code responsible for high slowdowns using addr2line. Our analysis reveals that two performance-critical objects, each 2GB in size, are contributing to the slowdown. ä½œè€…æåˆ°çš„ä¸¤ä¸ªcaseï¼Œä¸€ä¸ªæ˜¯ç”¨æ¥åšæ€§èƒ½ä¼˜åŒ–ï¼Œä¸€ä¸ªæ˜¯ä½œä¸ºæ€§èƒ½æŒ‡æ ‡æ¥è¿›è¡Œåˆ†å±‚ï¼Œè¿™ä¸¤ä¸ªç‚¹å…¶å®éƒ½æ˜¯å’Œåä¸€ç¯‡è®ºæ–‡æœ‰è”ç³»ï¼Œåšé“ºå«ã€‚ ä¸è¶³ä¸æœºä¼šï¼š ä½œè€…åœ¨éªŒè¯cache slow downçš„ä¸»è¦åŸå› çš„ æ–¹æ³•æ˜¯ï¼š To validate this, we disable all the hardware prefetchers (L1 and L2) and measure workload slowdowns. With prefetchers off, we found virtually no stall cycles on cacheã€‚è¿™æ ·çš„æ–¹æ³•å¹¶ä¸æ·±å…¥ï¼Œä¸ºä»€ä¹ˆé™ä½ï¼Ÿè¿™äº›å€¼å¾—æ·±æŒ–ï¼Œä½†æ˜¯éœ€è¦ä¸€äº›ç¡¬ä»¶æ¢ç´¢ã€‚ å…³äºé¢„å–ï¼Œå¯ä»¥å¢åŠ é¢„å–å™¨çš„æ·±åº¦(ä¹Ÿå°±æ˜¯å†å¤šé¢„å–å‡ ä¸ªå‘¨æœŸ)ç›´æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ 5.7ä¸­è®²åˆ°äº†ä¸€ä¸ªå…³äºSPAçš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œé€šè¿‡å‰–æSPAä¸­çš„slowdownæ¥åˆ†æslowdownï¼Œç„¶åæŠŠslowdownä¸¥é‡çš„å˜é‡æ”¾ç½®åˆ°CXLï¼Œè¿™æ ·çš„æ–¹æ³•æˆ‘è§‰å¾—ååˆ†é€‚ç”¨ã€‚","tags":[null]},{"title":"CYY-RV64.zip","path":"/notebooks/paper/CYY-RV64.zip.html","content":"å­¦ä¹ ä¸€ä¸‹CYYå¸ˆå…„çš„å·¥ä½œï¼Œpart1 https://www.rv64.zip/ BackgroundMotivation1.ç†æƒ³çš„RISC-Væ¿å­åº”å½“åŒ…å«ä¸€ç»„æ ‡å‡†çš„æŒ‡ä»¤æ‹“å±•RVA23U64,ä½†æ˜¯ç›®å‰çš„ç”Ÿæ€ä¸‹ï¼Œä¸åŒç¡¬ä»¶æ”¯æŒçš„æ‹“å±•ä¸æ ‡å‡†å¹¶ä¸ä¸€è‡´ï¼› 2.ç¼–è¯‘å™¨å’ŒCPUæ²¡æœ‰é’ˆå¯¹æ–°æ‹“å±•è¿›è¡Œä¼˜åŒ–çš„è¯ï¼Œç›²ç›®æ‰“å¼€æ–°æ‹“å±•åè€Œä¼šå¯¼è‡´ç¨‹åºæ€§èƒ½ä¸‹é™ Existing solution1.target_clones attributes æ”¹ä»£ç ï¼Œç»´æŠ¤æˆæœ¬é«˜ é—´æ¥è°ƒç”¨å¼€é”€ï¼š When using target_clones or target_version, the compiler will use GNU IFUNC to dispatch the function call to the correct version at runtime. This introduces an overhead of an indirect function call, and also refuses some optimizations such as inlining. When compiling without -fno-plt or with -fno-pic, things will be worse since it requires 2 level call to the function (the first level is PLT call). å‰ç½®çŸ¥è¯†ï¼š PLTï¼ˆProcedure Linkage Table) PLT æ˜¯åŠ¨æ€é“¾æ¥ï¼ˆå…±äº«åº“ï¼‰ä¸­ç”¨äºå®ç° å»¶è¿Ÿç»‘å®šï¼ˆLazy Bindingï¼‰ çš„æ ¸å¿ƒç»“æ„ï¼Œè§£å†³ç¨‹åºè°ƒç”¨å…±äº«åº“å‡½æ•°æ—¶çš„è·³è½¬é—®é¢˜ã€‚ é¦–æ¬¡è°ƒç”¨å‡½æ•°æ—¶ï¼š ç¨‹åºè·³è½¬åˆ° PLT è¡¨ä¸­çš„å¯¹åº”æ¡ç›®ï¼ˆå¦‚ printf@pltï¼‰ã€‚ PLT æ¡ç›®åŒ…å«ä¸€æ¡è·³è½¬æŒ‡ä»¤ï¼Œé»˜è®¤æŒ‡å‘ åŠ¨æ€é“¾æ¥å™¨ï¼ˆ_dl_runtime_resolveï¼‰ã€‚ åŠ¨æ€é“¾æ¥å™¨è§£æå‡½æ•°çœŸå®åœ°å€ï¼Œå¹¶å›å¡«åˆ° GOTï¼ˆGlobal Offset Tableï¼‰ã€‚ åç»­è°ƒç”¨æ—¶ï¼š PLT ç›´æ¥é€šè¿‡ GOT è·³è½¬åˆ°çœŸå®å‡½æ•°åœ°å€ï¼ˆæ— éœ€å†æ¬¡è§£æï¼‰ã€‚ -fno-plt é€‰é¡¹å¯ç»•è¿‡ PLTï¼Œç›´æ¥é€šè¿‡ GOT è°ƒç”¨ IFUCNï¼ˆIndirect Functionï¼‰ è¿è¡Œæ—¶åŠ¨æ€é€‰æ‹©å‡½æ•°çš„å…·ä½“å®ç°,é€šè¿‡å‡½æ•°æŒ‡é’ˆè·³è½¬ï¼Œæ¯”ç›´æ¥è°ƒç”¨å¤šä¸€æ¬¡å¯»å€ï¼Œåœ°å€è¿è¡Œæ—¶ç¡®å®šï¼Œæ— æ³•å†…è” å®šä¹‰æ—¶é€šè¿‡ __ attribute__((ifunc(resolver)))æ ‡è®°å‡½æ•°ï¼Œæä¾›ä¸€ä¸ªè§£æå™¨å‡½æ•°ã€‚ static void* my_func_resolver() if (__builtin_cpu_supports(avx2)) return my_func_avx2; else return my_func_default;void my_func() __attribute__((ifunc(my_func_resolver))); æœ€ä½³æ¡ˆä¾‹ï¼šGLibé€šè¿‡IFUNCä¸ºmemcpyæä¾›äº†å¤šä¸ªå®ç°ã€‚ Solution1.Decoupled function clone tableâ€‹\tç›¸å½“äºå°†target_clones attributesä»å‡½æ•°å±‚æå‡åˆ°äº†æ–‡ä»¶å±‚ï¼Œä¸éœ€è¦ä¿®æ”¹æºä»£ç ã€‚patch 2.Automatic function clone table generationâ€‹\tæ ¹æ®perfç»“æœé€‰æ‹©æœ€ä½³çš„result 3.é’ˆå¯¹ç›´æ¥è°ƒç”¨æäº†ä¸€äº›ç¼–è¯‘å™¨ç«¯å’ŒCPUç«¯çš„æ”¯æŒ æœŸå¾…CYYå¸ˆå…„çš„æ­£å¼è®ºæ–‡,åç»­ç»§ç»­å­¦ä¹  Other1.è‹±è¯­è¡¨è¾¾è¯»èµ·æ¥å¥½èˆ’æœ 2.ç±»ä¼¼çš„æ–¹æ¡ˆåœ¨box64ä¹‹ç±»çš„äºŒè¿›åˆ¶ç¿»è¯‘åœºæ™¯ä¸‹ä¹Ÿå¤§æœ‰ç”¨å¤„ã€‚","tags":[null]},{"title":"ISCA`25 LIA A Single-GPU LLM Inference Acceleration with Cooperative AMX-Enabled CPU-GPU Computation and CXL Offloading","path":"/notebooks/paper/ISCA-25-LIA-A-Single-GPU-LLM-Inference-Acceleration-with-Cooperative-AMX-Enabled-CPU-GPU-Computation-and-CXL-Offloading.html","content":"Abstractâ€‹\tå•GPUçš„å†…å­˜å®¹é‡é™åˆ¶äº†å¤§æ¨¡å‹æ¨ç†ï¼Œä½¿å¾—ä½¿ç”¨æˆæœ¬é«˜æ˜‚çš„å¤šGPUéƒ¨ç½²æˆ–è€…åœ¨æ…¢é€ŸPCIEä¼ è¾“å¯¼è‡´æ€§èƒ½å—é™çš„CPU-GPUéƒ¨ç½²ååˆ†å¿…è¦ã€‚åœ¨è¿™ä¸ªå·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆbenchmarkäº†æœ€æ–°çš„å¸¦æœ‰AMXçš„Intel CPUï¼ŒåŒ…æ‹¬4th SPRæ¶æ„å’Œ 6th GNRæ¶æ„çš„è‡³å¼ºå¤„ç†å™¨ï¼Œè¯æ˜çŸ©é˜µä¹˜æ³•çš„å¸¦å®½è¾¾åˆ°äº†20TFLOPSå’Œ40TFLOPSï¼Œéƒ½æ¯”å¾—ä¸Šä¸€äº›æœ€æ–°çš„GPU.\tè¿™äº›å‘ç°è§£é”äº†æ›´åŠ å¹¿æ³›çš„CPUè®¡ç®—å¸è½½ï¼Œå‡å°‘CPU-GPUä¼ è¾“ï¼Œä¸ä¹‹å‰ä»£é™…çš„CPUç›¸æ¯”ç¼“è§£äº†å¸¦å®½ç“¶é¢ˆã€‚ è¡¥å……ï¼šç®—åŠ›åˆ†æ1.TFLOPS(Trillions of Floating-Point Operations Per Second):æ¯ç§’ä¸‡äº¿æ¬¡æµ®ç‚¹æ•°è¿ç®— 20~40TFLOPSä¸ºä¸­ç­‰ç®—åŠ›æ°´å¹³ 2.ç®—åŠ›åœºæ™¯ä¸­ï¼Œæ›´å¸¸ä½¿ç”¨ååé‡(Throughput)TFLOPSè€Œéç†è®ºå³°å€¼ç®—åŠ›ï¼ŒThroughput æ›´è´´è¿‘å®é™…ä»»åŠ¡çš„æ€§èƒ½è¡¨ç°ï¼ŒThroughput ä¹Ÿæ˜¯ä¼˜åŒ– LLM æ¨ç†æ€§èƒ½çš„æ ¸å¿ƒç›®æ ‡ 3.å¸¸è§GPU ç®—åŠ›ï¼š 4090 83TFLOPS | A100 312 FLOPS åŸºäºä»¥ä¸Šå‘ç°ï¼Œæˆ‘ä»¬è®¾è®¡äº†LIAï¼Œä¸€ä¸ªå•GPUå¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ï¼ŒååŒAMXä½¿èƒ½çš„CPU-GPUè®¡ç®—ä»¥åŠCXLå¸è½½ï¼ŒLIAç³»ç»Ÿçš„å¸è½½äº†è®¡ç®—åˆ°CPUä¸Šï¼Œä¼˜åŒ–äº†å»¶è¿Ÿå’Œå¸¦å®½ã€‚è¿™ä¸ªæ¡†æ¶åŒæ ·ä»‹ç»äº†ä¸€ä¸ªå†…å­˜å¸è½½ç­–ç•¥ï¼Œè¿™ä¸ªç­–ç•¥æ— ç¼çš„é›†æˆäº†ä¾¿å®œçš„CXL-DDRå†…å­˜å¢å¼ºäº†å¸¦å®½é©±åŠ¨å‹ä»»åŠ¡çš„æ€§èƒ½è¡¨ç°ã€‚åœ¨æœ‰ä¸€å¼ H100çš„SPRç³»ç»Ÿä¸Šï¼ŒLIAå¯¹æ¯”ä¹‹å‰çš„å•GPUæ¨ç†æ¡†æ¶ï¼Œè¾¾åˆ°äº†5.1åˆ°19å€çš„å»¶è¿Ÿé™ä½ä»¥åŠ3.7åˆ°5.1å€çš„å¸¦å®½ã€‚å¹¶ä¸”ï¼ŒLIAéƒ¨ç½²äº†CXLå¸è½½ï¼Œäº§ç”Ÿäº†ä¸€ä¸ªé¢å¤–çš„1.5å€å¸¦å®½æå‡ï¼ˆå¯¹æ¯”çº¯DDRæ–¹æ¡ˆï¼‰å’Œ1.8å€çš„æœ€å¤§batch size æå‡ã€‚ 1 Introductionâ€‹\tLLMåœ¨è®¸å¤šé¢†åŸŸé‡Šæ”¾å·¨å¤§çš„æ½œåŠ›ï¼Œç„¶è€Œï¼Œè¿™ç§å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ä¼´éšç€å·¨å¤§çš„èŠ±è´¹ï¼ˆæŒ‡ä¸æ–­æ‰©å¤§çš„å‚æ•°è§„æ¨¡ï¼‰ã€‚æœ€è¿‘çš„å¤§æ¨¡å‹éƒ½è®¾è®¡äº†å·¨å¤§çš„å‚æ•°é‡ï¼Œå¹¶ä¸” ä¼¼ä¹ä¸¾ä¾‹å‚æ•°ä¸Šé™ç¨³å®šçº¿è¿˜ååˆ†é¥è¿œã€‚è¿™äº›å‚æ•°é‡çš„å¢åŠ å¼•å‘äº†ä¸€ä¸ªå·¨å¤§çš„æŠ€æœ¯æŒ‘æˆ˜ï¼šåœ¨ä¸€å¼ GPUå†…ä¿å­˜æ¨¡å‹å‚æ•°å’Œä¸­é—´å€¼ï¼ˆæ¯”å¦‚KV-cacheå’Œæ¿€æ´»å€¼ï¼‰å˜å¾—infeasibleã€‚å³ä½¿æœ€æ–°çš„GPUä¾‹å¦‚H100è¾¾åˆ°äº†94GBçš„æ¿è½½HBMå†…å­˜ï¼Œä½†æ˜¯ä¾æ—§éš¾ä»¥é¢å¯¹æ¨ç†æ—¶çš„å†…å­˜éœ€æ±‚ã€‚é’ˆå¯¹å•GPUçš„èƒ½åŠ›é™åˆ¶ï¼Œæœ€è¿‘çš„ä¸€äº›å·¥ä½œå·²ç»è½¬å‘äº†å¤šGPUéƒ¨ç½²ï¼Œè¿™åˆ©ç”¨äº†æ¨¡å‹çš„å¹¶è¡Œæ€§ã€‚ç„¶è€Œè¿™äº›æ–¹æ³•åœ¨éå¸¸æ˜‚è´µçš„ï¼ŒåŒæ—¶æ“ä½œèµ·æ¥ååˆ†å¤æ‚ã€‚ä¾‹å¦‚ï¼Œéƒ¨ç½²ä¸€ä¸ª175bilionçš„å‚æ•°çš„OPTæ¨¡å‹è‡³å°‘éœ€è¦5å¼ H100GPUï¼Œæ€»èŠ±è´¹è¶…è¿‡150000åˆ€ã€‚å› æ­¤ï¼Œé€šè¿‡å¢åŠ GPUçš„æ•°é‡æ˜¯ä¸€ç§åœ¨ä¸€äº›é«˜æ€§ä»·æ¯”çš„ç»æµåœºæ™¯ä¸­ä¸æ˜¯ä¸€ä¸ªå¯è¡Œçš„æ–¹æ¡ˆã€‚è®¸å¤šå‹ç¼©æŠ€æœ¯ï¼Œä¾‹å¦‚é‡åŒ–ã€å‰ªæã€ä»¥åŠæ¨¡å‹è’¸é¦ï¼ˆdistillation)å·²ç»è¢«æå‡ºæ¥å‡è½»å¤§æ¨¡å‹å¯æ‹“å±•æ€§çš„è´Ÿæ‹…ï¼Œå°½ç®¡è¿™äº›æ–¹æ³•å‡è½»äº†å†…å­˜éœ€æ±‚ï¼Œç„¶è€Œä»–ä»¬é€šå¸¸ä»¥æŸå¤±æ¨¡å‹ç²¾åº¦ä¸ºä»£ä»·ï¼Œå¹¶ä¸”ä»ç„¶éœ€è¦å¤šGPUã€‚ä¸€ä¸ªå¯é€‰æ‹©çš„æ–¹å‘æ˜¯ç³»ç»Ÿçº§åˆ«çš„å¸è½½ï¼Œå°†æ¨¡å‹å‚æ•°å­˜å‚¨åœ¨æ›´å¤§çš„CPUå†…å­˜ä¸­ç„¶åæŒ‰éœ€ä¼ è¾“åˆ°GPUä¸­ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é¢ä¸´ä»–è‡ªå·±çš„å†…å­˜ç“¶é¢ˆï¼ŒåŸå› æ˜¯PCIEçš„å¸¦å®½æœ‰é™ï¼ˆH100 çš„PCIEå¸¦å®½æ˜¯64GBï¼ŒPCIe5.0),è¿™è§æ»¡äº†CPU-GPUçš„ä¼ è¾“ï¼Œå¯¼è‡´äº†å¤§é‡çš„æ¨ç†å»¶è¿Ÿã€‚ â€‹\tä¸ºäº†å‡è½»å¤§é‡æ•°æ®çš„ä¼ è¾“å¼€é”€ï¼Œä¸€äº›æ–¹æ³•å·²ç»æå‡ºé€‰æ‹©ä¸€äº›å±‚åœ¨CPUä¸Šè¿›è¡Œè®¡ç®—ï¼Œç„¶è€Œï¼Œè¿™äº›CPUã€GPUååŒçš„æ¡†æ¶çš„æ•ˆç‡è¢«CPUè®¡ç®—å¸¦å®½é™åˆ¶ï¼ŒFlexGenå’ŒFastDecodeè¿™ä¸¤ä¸ªå·¥ä½œå¸è½½äº†è®¡ç®—æœ€ä¸æ•æ„Ÿçš„å­å±‚åˆ°CPUï¼Œç„¶è€ŒPowerInfoerå¸è½½å†·ç¥ç»å…ƒåˆ°CPUï¼Œè¿™æ˜¾è‘—é™ä½äº†æ¨¡å‹çš„ç²¾åº¦ã€‚é™¤äº†å¤æ‚æ€§ä»¥å¤–ï¼Œå¤§æ¨¡å‹éœ€è¦æ ¹æ®åº”ç”¨çš„éœ€æ±‚è¿è¡Œä¸åŒbatch sizeçš„æ¨ç†æ“ä½œã€‚è™šæ‹ŸåŠ©æ‰‹ã€æœç´¢å¼•æ“è¿™è¿™ç±»é¢å‘ç”¨æˆ·æ¥å£çš„è¯·æ±‚å…·æœ‰å°batch ä½å»¶è¿Ÿçš„ç‰¹ç‚¹ï¼Œå¿«é€Ÿå“åº”å½±å“äº†ç”¨æˆ·çš„ä½¿ç”¨ä½“éªŒã€‚ç›¸åï¼Œbenchmarkã€ä¿¡æ¯æå–ä¹‹ç±»çš„ä»»åŠ¡å…·æœ‰å»¶è¿Ÿä¸æ•æ„Ÿæ€§çš„ä»»åŠ¡ï¼Œå¤§batchã€é«˜å¸¦å®½æ˜¯éå¸¸é‡è¦çš„ã€‚ â€‹\tä¸ºäº†å¤„ç†è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†LIAæ¡†æ¶ï¼Œä¸€ä¸ªå•GPUæ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œä½¿ç”¨äº†AMXå’ŒCXLæŠ€æœ¯é€‚é…äº†å°batchå’Œå¤§batchåœºæ™¯ã€‚LIAä¸»è¦æœ‰3ç‚¹è´¡çŒ®ï¼š AMXçŸ©é˜µä¹˜æ³•çš„ç»¼åˆæ€§èƒ½åˆ†æã€‚ AMXé©±åŠ¨çš„CPU-GPUååŒå¤§æ¨¡å‹æ¨ç†æ¿€ç´  ä½¿ç”¨CXLå†…å­˜æ¥æ‹“å±•å¸¦å®½ LIAä¸»è¦æœ‰ä¸¤ä¸ªç»„ä»¶ç»„æˆï¼šC1:å‰ç«¯ç®—æ³•ï¼Œå†³å®šäº†é‚£äº›å­å±‚å¸è½½åˆ°CPUï¼›C2ï¼šåç«¯æ‰§è¡Œï¼Œæ— ç¼çš„é›†æˆäº†AMX CPU ã€GPUã€‚LIAå…è®¸æ‰€æœ‰çš„å­å±‚å¸è½½åˆ°AMXä½¿èƒ½çš„CPUä¸Šã€‚ å‰ç«¯ç»„ä»¶è€ƒè™‘äº†ä¸€äº›å†å²å› ç´ æ¥å†³ç­–æœ€ä¼˜çš„å¸è½½ç­–ç•¥ï¼Œè¿™äº›å› ç´ åŒ…æ‹¬æ¯ä¸ªç»™å®šäº†batch size å’Œtoken lengthå­å±‚çš„æ¯å­—èŠ‚æ“ä½œé‡ã€CPU-GPUä¼ è¾“æ•°æ®é‡ã€CPUä¸GPUçš„è®¡ç®—ååé‡å’Œå†…å­˜å¸¦å®½ã€‚å°†è¿™äº›å˜é‡è€ƒè™‘åœ¨å†…ï¼ŒLIAæœ€å¤§åŒ–äº†èµ„æºåˆ©ç”¨ç‡ï¼Œæœ€å°åŒ–äº†ç«¯åˆ°ç«¯å»¶è¿ŸLIAåˆ©ç”¨äº†å¤§æ¨¡å‹çš„ä¸€ä¸ªç‰¹æ€§ï¼šä¹Ÿå°±æ˜¯æ¯å­—èŠ‚æ“ä½œæ¯”ä¼šéšç€æ‰¹æ¬¡å¤§å°å’Œè¾“å…¥é•¿åº¦åŠ¨æ€æ³¢åŠ¨ã€‚è¿™ä½¿å¾—åœ¨ä»¥åç³»ç»Ÿä¸­ï¼Œåˆ©ç”¨æ‰€ç»™çš„æ‰¹å¤§å°å’Œè¾“å…¥é•¿åº¦å†³å®šå¸è½½ç­–ç•¥ï¼Œèƒ½å¤Ÿå¾—åˆ°æœ€å°çš„å¸è½½å»¶è¿Ÿã€‚ åç«¯æ‹“å±•äº†IPEX(è¿™ä¸ªæ‹“å±•åŸæœ¬æ˜¯ç”¨æ¥ç»™GPUæˆ–è€…å•ä¸€çš„CPUè¿›è¡ŒåŠ é€Ÿ)æ¥æ— ç¼çš„é›†æˆCPUå’ŒGPUã€‚åç«¯æ‹“å±•åŒæ ·å¼•å…¥äº†è¿›ä¸€æ­¥å¢å¼ºGPUå†…å­˜å’ŒCPU-GPUè®¡ç®—èµ„æºçš„ä¼˜åŒ–ã€‚ ä½¿ç”¨CXLå†…å­˜æ—¶ä¸»è¦å°†æ¨¡å‹å‚æ•°å¸è½½ åˆ°CXLå†…å­˜ï¼Œè€ŒDDRå†…å­˜åˆ™å­˜å‚¨ä¸­é—´å€¼ã€‚ 2.Background2.1 LLM inference å¤§æ¨¡å‹ç”±embeddingencoding layerç»„æˆï¼ŒNä¸ªdecoder layers ,LM head(linear å’Œ softmax). decoder layersä¸»å¯¼äº†æ¨ç†æ—¶é—´å’Œå†…å­˜æ¶ˆè€— ä¸€ä¸ªdecoder layerç”±å¤šä¸ªå­å±‚ç»„æˆï¼ŒåŒ…æ‹¬çŸ©é˜µä¹˜æ³•ã€ å±‚å½’ä¸€åŒ–ã€æ®‹å·®å’Œsotfmaxã€‚ Nä¸ªdecoder æœ‰ä¸€æ ·çš„ç»“æ„ï¼Œä¸ä¸€æ ·çš„å‚æ•°ã€‚ æ¨¡å‹æ¥å—äº†è¾“å…¥tokenåºåˆ—ï¼Œç„¶åç”Ÿæˆè¾“å‡ºtokenï¼Œè€ŒååˆæŠŠæ–°è¾“å‡ºçš„tokenä½œä¸ºè¾“å…¥ï¼Œç›´åˆ°ç»“æŸã€‚ 3 Performance Bottlenecks of Offloading Frameworks for LLM Inference","tags":[null,null]},{"title":"OCP China 2024 CXL è®ºå›å­¦ä¹ ç¬”è®°","path":"/notebooks/paper/OCP-China-2024-CXL-è®ºå›å­¦ä¹ ç¬”è®°.html","content":"OCP China 2024 CXLè®ºå› å­¦ä¹ ç¬”è®°ä¼šè®®é“¾æ¥ é˜¿é‡Œäº‘ æ•°æ®ä¸­å¿ƒé«˜æ€§èƒ½Scale Up äº’è”ç³»ç»Ÿè¶‹åŠ¿ å­”é˜³ é˜¿é‡Œäº‘è¶…é«˜é€Ÿäº’è”è´Ÿè´£äºº èƒ¡æ–‡æ™® CXLéƒ¨åˆ† Scale Up äº‘çš„è§’åº¦ å…³æ³¨ä¸¤ä¸ªè®¡ç®— ï¼š é€šç”¨è®¡ç®—ã€GPUè®¡ç®— é€šç”¨è®¡ç®—ä¸Šï¼š è€ƒè™‘å¼¹æ€§åˆ†æï¼šå­˜å‚¨ä¸Š-äº‘ç›˜æŠ€æœ¯ ç½‘ç»œ-CIPUç½‘ç»œè™šæ‹ŸåŒ– å†…å­˜ä¸Š-CXL GPUä¸Šï¼šå¤§æ¨¡å‹å•æ¬¡ä»»åŠ¡ï¼Œæ•°æ®å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œã€tensorå¹¶è¡Œã€ä¸“å®¶å¹¶è¡Œï¼Œéƒ½å…·æœ‰è¾ƒé«˜çš„å¸¦å®½è¦æ±‚ CXL æœºæŸœå†…çš„èµ„æºå¼¹æ€§å®ç°éœ€è¦æ»¡è¶³é«˜æ€§èƒ½æ¥å£ã€èµ„æºå…±äº«ã€æè‡´å¼¹æ€§ã€è½¯ä»¶ç”Ÿæ€å…¼å®¹æ€§ç­‰è¦æ±‚ã€‚CXLç‰¹æ€§ç¬¦åˆè¿™äº›è¦æ±‚ã€‚CXLå°†ä¸€è‡´æ€§è®¿é—®ä»CPUå†…éƒ¨æ‹“å±•åˆ°CPUå’Œå†…å­˜ä¹‹é—´ï¼Œå®ç°å¤šæœåŠ¡å™¨ä¹‹é—´çš„äº’è”ã€‚ CXLçš„æ¼”è¿› GIM ï¼š P2P ï¼š DSPä¸type3äº’è”ï¼Œtype3å¯ä»¥åˆ†é…ç»™DSPæˆ–è€…host HBR-PBR:ä¸æ­¢æ ‘çŠ¶ã€æ˜ŸçŠ¶ã€ç½‘ç»œçŠ¶ E3.s çƒ­æ’æ‹”ï¼Œä¾¿äºå¯æ‹“å±• JBOM å¤§å®¹é‡ PEMEM ï¼šæ”¯æŒ2.0ï¼Œæ»¡è¶³rediså®æ—¶æ€§æŒä¹…åŒ–ç­‰è¦æ±‚ åŸºäº å†…å­˜ä¸CPUå®ç°èµ„æºè§£è€¦ CXLåœ¨å°æ•°æ®ä¸Šä¼ è¾“æ€§èƒ½å¤§å¤§æé«˜ï¼› intel: CXL on Intel Xeon@ Platform èµµæ£®æ— CXL overview CXL Specification Summary","tags":[null]},{"title":"é¾™èœ¥CXLè®²è§£-é«˜æ˜¾æ‰¬","path":"/notebooks/paper/é¾™èœ¥CXLè®²è§£-é«˜æ˜¾æ‰¬.html","content":"CXLæŠ€æœ¯ä»‹ç»å¯¹è§†é¢‘é“¾æ¥çš„PPTæ¬è¿ï¼Œæ–¹ä¾¿å¿«é€Ÿé˜…è¯» é«˜æ˜¾æ¨ æµªæ½® ç»¼è¿° åè®®åè®®æ¼”è¿› 1.1å†…å­˜æ‹“å±• 2.0å†…å­˜èµ¤åŒ– 3.0ç‰¹æ€§ CXLå­åè®® CXLè®¾å¤‡ CXL Fabric å‚è€ƒVPNï¼Œä¸‹è¾¹ä¸¤å¼ ä¸ºå•switch CXL RASç‰¹æ€§ å†…å­˜çƒ­æ’æ‹”ï¼Ÿå¦‚ä½•é¿å…å®•æœº CXLåˆå§‹åŒ– RCRB CXL 1.1è·‘CXL2å®ç°åè®®å…¼å®¹ CXLæ–¹æ¡ˆ æ± åŒ–ç®¡ç†ï¼šFMä¸­çš„bindå’ŒUnBind ä¸šç•Œæ–¹æ¡ˆ è¡¥å……","tags":[null]},{"title":"OSDI'25 Tiered Memory Management Beyond Hotness","path":"/notebooks/paper/OSDI-25-Tiered-Memory-Management-Beyond-Hotness.html","content":"Tiered Memory Management Beyond Hotness Jinshu Liu Hamid Hadian Hanchen Xu Huaicheng Li Virginia Tech https://github.com/MoatLab/SoarAlto/ Virginia è¿™ä¸ªMoatLabå¯¹CXLå†…å­˜çš„ç ”ç©¶å¾ˆæ·±å…¥ï¼Œä¹‹å‰çš„Pond(ASPLOS `23)ã€Melodyï¼ˆASPLOS`25ï¼‰éƒ½å‡ºè‡ªè¿™ä¸ªå®éªŒå®¤ 1.IntroductionHot data is not always performance-critical and can reside in the slow-tier without degrading performance . Latency mitigation techniques, such as memory-level parallelism (MLP), obscure the true cost of memory accesses 1.å…ˆå‰çš„å·¥ä½œé€šè¿‡å¯å‘å¼æˆ–è€…å†…å­˜è®¿é—®æˆæœ¬é—´æ¥çš„ååº”MLPçš„å½±å“ï¼Œä½†æ˜¯ä»ç„¶ç¼ºå°‘å‡†ç¡®çš„MLPå»ºæ¨¡å’ŒæŒ‡æ ‡ã€‚ 2.ç°æœ‰çš„å†…å­˜åˆ†å±‚æ–¹æ³•å…·æœ‰éš¾ä»¥è½»é‡åŒ–å’Œä¸å‡†ç¡®çš„ç‰¹ç‚¹ã€‚å°¤å…¶æ˜¯ä¸€å¼€å§‹å…ˆæ”¾ç½®æœ¬åœ°å†…å­˜çš„æ–¹æ³•æœ¬èº«å°±æ˜¯æ¬¡ä¼˜çš„ï¼Œå¹¶ä¸”æ¿€è¿›çš„è¿ç§»ç­–ç•¥ä¼šå¯¼è‡´è¿‡åˆ†çš„è¿ç§»ã€‚ æ‰€ä»¥ä½œè€…å°±å®šä¹‰äº†ä¸€ä¸ªMLPå½±å“çš„æŒ‡æ ‡ï¼ŒAOLï¼Œå¹¶ä¸”ç”¨æ¥è¾…åŠ©æ”¾ç½®å†³ç­–å’Œè¿ç§»å†³ç­–ã€‚ Propose Amortized Offcore Latency (AOL), a novel performance metric that accurately quantifies the performance impact of memory accesses by integrating memory latency and MLP. æ”¾ç½®å†³ç­–ç­–ç•¥SOARåŸºäºAOLè¿›è¡Œæ’åºï¼Œç„¶åä»¥æ­¤å†³å®šæ”¾ç½®ã€‚ALTOä¾é AOLæ¥è¿›è¡Œé¡µé¢æå‡çš„è¿‡æ»¤ï¼Œå¯ä»¥ä¸TPPç­‰ç­–ç•¥è¿›è¡Œç»“åˆã€‚ 2.Background and MotivationMLPåæ˜ ç­‰å¾…å†…å­˜æ§åˆ¶å™¨å®ç°çš„å†…å­˜è¯·æ±‚æ•°é‡ã€‚ high-MLP access patternsï¼š array traversalsã€‚ low MLPï¼špointer-chasing with depedent requests æŠŠä¸¤ä¸ªç±»å‹çš„è®¿å­˜ä¸€èµ·è·‘ï¼Œç„¶åä¸åŒçš„åˆ†å±‚ç­–ç•¥ä¾ç…§ä¸åŒçš„ç­–ç•¥è·‘äº†æµ‹æ€§èƒ½ï¼Œå‘ç°æŠŠæ•°ç»„è®¿é—®çš„æ”¾åˆ°å¿«é€Ÿå±‚ï¼Œåè€Œä¼šä½¿æ€§èƒ½é™ä½ã€‚ 3.Memory Performance PredictionRelating Slow-tier Performance to CPU Stallsç¦»çº¿åˆ†æ Performance degradation on the slow-tier is predominantly caused by increased CPU stalls due to LLC misses, which we refer to as LLC-Stalls å¼ºè°ƒåŒºåˆ†LLC-misså’ŒLLC-Stall æ…¢é€Ÿå±‚å•æ¬¡missé€ æˆçš„å»¶è¿Ÿæ›´é•¿ï¼Œå‡è®¾ç›¸åŒçš„miss,æ…¢é€Ÿå±‚ä¹Ÿä¼šæœ‰æ›´é•¿çš„LLS-Stall. è®ºæ–‡ä¸­è®²åˆ°åŸºäºLLC-Stallæ¥é¢„æµ‹å‡é€Ÿçš„è¯¯å·®ä½äº4%ï¼Œå¼€æºä»¥åå¯ä»¥é¢„æµ‹ä¸€ä¸‹åŸºäºLLC-Missçš„ï¼ˆè€ƒè™‘é¢„å–å™¨çš„å½±å“ï¼‰ã€‚ LLC-Stalls for Performance Predictionåœ¨çº¿é¢„æµ‹ å‘ç°å¿«é€Ÿå±‚å‘ç”ŸCPUStallçš„åœ¨æ…¢é€Ÿå±‚ä¹Ÿä¼šå‘ç”Ÿã€‚ æ‰€ä»¥ç”¨P SLLCcæ¥é¢„æµ‹æ…¢é€Ÿå±‚çš„å‡é€Ÿã€‚ AOL for Accurate Predictionè¿›ä¸€æ­¥ç ”ç©¶å‘ç°ï¼ŒPåœ¨ä½MLPçš„åœºæ™¯ä¸‹å‡†ç¡®ï¼Œä½†æ˜¯åœ¨é«˜MLPçš„åœºæ™¯ä¸‹å¹¶ä¸å‡†ç¡®ã€ä¸»è¦æ˜¯å¿½ç•¥äº†MLPçš„å½±å“ï¼Œé«˜MLPä¼šå‡å°‘é•¿å»¶è¿Ÿçš„å½±å“ã€‚ éšç€å»¶è¿Ÿçš„å¢åŠ ï¼ŒMLPçš„å»¶è¿Ÿæ©ç›–å—ç›Šä¼šé™ä½ã€‚ å› æ­¤å®šä¹‰äº†AOLï¼š æŒ‡æ ‡ äº‹ä»¶ å«ä¹‰ ğ‘ ğ¿ğ¿ğ¶ CYCLE ACTIVITY.STALLS L3 MISS L3 Missæ—¶å¯¼è‡´çš„Stall c CPU_CLK_UNHALTED.THREAD éHaltä¸‹çš„æ—¶é’Ÿå‘¨æœŸæ•° A1 OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DATA_RD L2 Miss åã€è¯·æ±‚å®Œæˆå‰ï¼Œè¿™äº›å†…å­˜è¯»å–è¯·æ±‚åœ¨ SQ ä¸­ç­‰å¾…çš„å‘¨æœŸæ•°æ¢è¨€ä¹‹ï¼Œæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸæ£€æŸ¥æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€ä¸ªloadè¯·æ±‚ï¼Œæœ‰å°±åŠ 1 A2 OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD L2 miss åï¼Œæ¯ä¸ªå‘¨æœŸæœ‰å¤šå°‘ä¸ªæœªå®Œæˆçš„ Demand Load è¯·æ±‚åœ¨SQä¸­ç­‰å¾…ï¼Œå³ï¼šè¯·æ±‚å †ç§¯çš„æ·±åº¦å‹åŠ›ã€‚ A3 OFFCORE REQUESTS.DEMAND DATA RD L2 miss åï¼Œè¢«å‘å¾€ uncore çš„ load è¯·æ±‚çš„æ¬¡æ•°ã€‚ å»¶è¿Ÿè®¡ç®—è¿ç”¨åˆ°äº†æ’é˜Ÿè®ºä¸­çš„Little`sæ³•åˆ™:å¹³å‡åœ¨ç³»ç»Ÿä¸­çš„é¡¹æ•° L = åˆ°è¾¾ç‡ Î» Ã— å¹³å‡å“åº”æ—¶é—´ W ç»“åˆäº‹ä»¶ï¼š L æŸä¸ªæ—¶é—´æ®µå†…ï¼Œåœ¨ uncore æ­£åœ¨ç­‰å¾…å®Œæˆçš„è¯·æ±‚æ•°ï¼ˆå•ä½ï¼šä¸ªï¼‰ï¼Œå³ â€œæ¯å‘¨æœŸ outstanding çš„è¯·æ±‚æ•°â€ Î» è¯·æ±‚åˆ°è¾¾é€Ÿç‡ï¼ˆå•ä½ï¼šè¯·æ±‚å‘¨æœŸï¼‰â‰ˆ æ€»è¯·æ±‚æ•° æ€»å‘¨æœŸæ•° W æ¯ä¸ªè¯·æ±‚åœ¨ç³»ç»Ÿä¸­åœç•™çš„æ—¶é—´ï¼ˆå•ä½ï¼šå‘¨æœŸï¼‰â†’ å¹³å‡å»¶è¿Ÿ W = L / Î» = å¹³å‡ outstanding è¯·æ±‚æ•° / åˆ°è¾¾é€Ÿç‡ æ ¹æ®æ’é˜Ÿç†è®ºï¼Œè®¡ç®—å¾—1ã€‚ MLPæ˜¯å¹³å‡æ¯ä¸ªå‘¨æœŸå†…å¤šå°‘ä¸ªinflightå†…å­˜è¯·æ±‚ï¼Œè¡¡é‡å†…å­˜è®¿é—®çš„å¹¶è¡Œåº¦ã€‚ A2ä»£è¡¨æ€»çš„å †ç§¯è¯·æ±‚æ•°ï¼Œæ€»çš„å †ç§¯è¯·æ±‚æ•°ï¼ˆA2ï¼‰é™¤ä»¥æ€»çš„å †ç§¯å‘¨æœŸæ•°ï¼ˆA1),å¾—åˆ°æ¯ä¸ªå‘¨æœŸçš„å¹³å‡inflightè¯·æ±‚æ•°ã€‚ 1ã€2ä»£å…¥çš„AOLã€‚ å»¶è¿Ÿé™¤ä»¥å¹¶è¡Œè¯·æ±‚ï¼Œå¾—åˆ°äº†ä¸€ä¸ªå¹¶è¡Œè¯·æ±‚ä¸‹å•ä¸ªè¯·æ±‚çš„å»¶è¿Ÿå½±å“ã€‚ ç„¶åä½œè€…å®šä¹‰äº†å‡é€Ÿæ¨¡å‹ï¼šS P x K. k f(AOL)çš„å‡½æ•°æ˜¯ç”¨SPä¸AOLè¿›è¡Œåˆ†æï¼Œåå‘å‘ˆç°å‡ºç‰¹å®šçš„æ¸è¿›åŒæ›²çº¿ï¼Œåæ¨å‡ºäº†å…¶æ•°å­¦æ¨¡å‹ã€‚ å…³äºaå’Œbï¼Œä¸ç¡¬ä»¶ç›¸å…³è€Œä¸å·¥ä½œè´Ÿè½½æ— å…³çš„å¸¸æ•°ï¼Œä¸¤ä¸ªç‰¹å®šçš„åœºæ™¯ï¼ˆæŒ‡é’ˆè¿½è¸ªã€æ•°ç»„è®¿é—®ï¼‰èƒ½å¤Ÿæ¨å‡ºï¼ˆä¼°è®¡å¾…å®šç³»æ•°æ³•ï¼‰ åˆ†æï¼š AOLå¢åŠ æ—¶ï¼ˆMLPå‡å°æˆ–è€…Latencyå¢å¤§ï¼‰ï¼ŒKè¶‹è¿‘åˆ°ä¸Šç•Œ1ï¼ŒSæ¥è¿‘P,é¢„æµ‹ç”±LLC.stallcå†³å®šã€‚ç›¸åï¼ˆMLPå¢å¤§æˆ–è€…Latencyå‡å°‘ï¼‰ï¼ŒKè¶‹è¿‘ä¸‹ç•Œ0ï¼ŒSå‡å° æœ‰äº†é¢„æµ‹æ¨¡å‹ä»¥åï¼ŒåŸºäºæ—¶é—´åºåˆ—é¢„æµ‹äº† 4.Soar: Rank-based Static Object Allocationç°æœ‰çš„åˆæ¬¡æ”¾ç½®çš„åˆ†å±‚æ–¹æ¡ˆç›®çš„æ˜¯æœ€å¤§åŒ–åˆ©ç”¨å¿«é€Ÿå±‚å†…å­˜ã€‚ ä½œè€…å¸Œæœ›å¯»æ‰¾ä¸€ç§æ–¹æ³•æœ€åˆå°±èƒ½ç²¾å‡†æ”¾ç½®å†…å­˜ï¼Œé™ä½å†…å­˜è¿ç§»å¼€é”€ã€‚ è¯»åˆ°è¿™å¥è¯çš„æ—¶å€™è¿™éš¾å—ã€‚ã€‚ æŒ‘æˆ˜ï¼š While AOL-based prediction is effective at the workload level, it falls short for individual objects due to the semantic gap between architectural events and object-level memory accesses. å°½ç®¡AOLé¢„æµ‹åœ¨workloadçº§åˆ«èƒ½å¤Ÿè¡¨ç°å¾—å¾ˆå¥½ï¼Œä½†æ˜¯å´æ— æ³•åœ¨å•ä¸ªå˜é‡ä¸Šè¡¨ç°å¾ˆå¥½ã€‚ key insightï¼š â€‹\tdistribute CPU stalls across objects proportionally to their relative access frequencies based on the observed MLP and latencies, thereby approximating each objectâ€™s performance impact to application performance accurately. Object-Level Performance Profilingâ€‹\tPeriodically collects and processes three types of metrics: object metadata via object tracking memory accesses via PEBS-based LLC-miss sampling temporal performance via AOL-based prediction â‘ -â‘¡Object TrackingFlow é€šè¿‡LD_PRELOADçš„æ–¹å¼æ‹¦æˆªä¿®æ”¹ï¼Œè®°å½•äº”å…ƒç»„å¯¹è±¡æµ â‘¢-â‘£ç”¨PEBSè®°å½•LLC missesã€è®¿é—®æ—¶é—´æˆ³å’Œvaddr â‘¤-â‘¥åŸºäºAOLé¢„æµ‹æ€§èƒ½ â‘¦ åˆå¹¶ä¸‰ä¸ªå¯¹è±¡æµï¼ŒåŸºäºæ—¶é—´æˆ³æ¥åˆ¤æ–­åœ°å€ï¼Œæœ‰äº†è®¿é—®æ—¶é—´æˆ³ï¼Œå¯ä»¥è®¡ç®—è®¿é—®æ¬¡æ•°ä»¥åŠè®¿é—®æ¯”ä¾‹ã€‚ â‘§å°†è®¿å­˜æ¯”ä¾‹ä¸AOLå‡é€Ÿé¢„æµ‹ç»“åˆï¼Œè®¡ç®—å‡é€Ÿå¾—åˆ† å…·ä½“è®¡ç®—ç®—æ³•ï¼š æç«¯åœºæ™¯ä¸‹å¹¶è¡Œå°‘ï¼ŒMLP1ï¼Œå‡é€Ÿæ‰“åˆ†ç­‰äºæ—¶é—´æ®µå‡é€ŸP*è®¿å­˜æ¯”ä¾‹R é«˜MLPæ—¶ï¼Œç¼©å°è¯„åˆ† ä½MLPæ—¶ï¼Œæ”¾å¤§è¯„åˆ† ä½œè€…éšåè§£é‡Šäº†æ€æ ·è®¾è®¡çš„factorï¼Œä»¥åŠè®¡ç®—å•ä½å­—èŠ‚å¾—åˆ†ç­‰ã€‚ Object Allocationä¾ç„¶æ˜¯æ‰“åˆ†ä¹‹åè¿›è¡Œæ’åºï¼Œtopk æ”¾ç½®åˆ°å¿«é€Ÿå±‚ å½±å“æ’åä¸ä¸€å®šä¸è¯·æ±‚é¡ºåºç›¸åŒï¼Œå¦‚æœæ‰“åˆ†ä½çš„å…ˆåˆ°äº†ï¼Œåç»­æ‰“åˆ†é«˜çš„è¯·æ±‚åˆ°äº†ä¼šä½¿å¾—æ‰“åˆ†ä½çš„è¯·æ±‚é™çº§ã€‚ é—®é¢˜ï¼šæ˜¯ä¾æ®è°ƒç”¨æ ˆæ¥è¿›è¡Œåˆ†ç»„å¯¹å˜é‡è¿›è¡Œæ ‡è¯†çš„ï¼Œè¿™æ ·åœ¨ä¸€ä¸ªå‡½æ•°å†…éƒ¨è¿›è¡Œå†…å­˜åˆ†é…æ—¶ï¼Œå¤§å®¶è°ƒç”¨æ ˆéƒ½ç›¸åŒï¼Œè¿™æ ·å¹¶æ— æ³•åŒºåˆ†ã€‚ å…·ä½“è¦çœ‹ä»£ç å®ç°æ˜¯å¦åŒºåˆ†æ—¶ç©ºè°ƒç”¨ï¼Ÿ ç‰¹åˆ«æŒ‡å‡ºå¯ä»¥ä¸ä¸€äº›å¼‚æ„å†…å­˜æ„ŸçŸ¥çš„å†…å­˜åˆ†é…å™¨åŒæ—¶ä½¿ç”¨ï¼ˆmemkindã€Unified Memory Framework) Use Cases and Limitations1.HPCã€åœ¨çº¿æœåŠ¡è¿™ç§é•¿æ—¶é—´è®¿é—®çš„åº”ç”¨ï¼Œé™æ€åˆ†é…ä¸å†æœ€ä¼˜ 2.å‡è®¾å¯¹è±¡æ˜¯å‡åŒ€çš„ï¼Œå¯¹è±¡å†…éƒ¨çš„è®¿é—®æ¯ä¸€é¡µé¢‘ç‡éƒ½å·®ä¸å¤šã€‚ 5.Alto: AOL-based Adaptive Page Migrationsç°åœ¨æ–¹æ¡ˆçš„ä¸è¶³ï¼š 1.æŸäº›è¿ç§»æ²¡æœ‰ã€‚åªæ˜¯è¡¨é¢çƒ­ 2.è¿ç§»å¼€é”€å¾ˆå¤§ï¼Œç­–ç•¥åˆ°å•æ¬¡è¿ç§»éœ€è¦12us,è®¿é—®åˆ°è¿ç§»ä¸­çš„é¡µå¯¼è‡´CPU stall 3.CXLä¸localçš„å»¶è¿Ÿå’Œå¸¦å®½éƒ½åœ¨ç¼©å°ï¼Œè¿ç§»å¼€é”€çš„å½±å“å°±æ˜¾å¾—å¾ˆå¤§ 4.å†·é¡µä¸æ˜¯çœŸçš„å†·ã€‚ è™½ç„¶ç”¨ AOLï¼ˆAmortized Offcore Latencyï¼‰æ¥è®¾è®¡åŸºäºæ€§èƒ½æ„ŸçŸ¥çš„é¡µè¿ç§»ï¼ˆpage-level migrationï¼‰ç­–ç•¥æ˜¯å¾ˆæœ‰å‰æ™¯çš„ï¼Œä½†ç›®å‰ä»é¢ä¸´ä¸€äº›ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¦‚ä½•ç”¨ç°æœ‰ç²—ç²’åº¦ç¡¬ä»¶æ€§èƒ½è®¡æ•°å™¨ï¼ˆperformance countersï¼‰å‡†ç¡®ä¼°ç®—å•ä¸ªå†…å­˜é¡µçš„æ€§èƒ½å½±å“æ–¹é¢ã€‚ æ–¹æ³•å¾ˆç®€å•ï¼Œå°±æ˜¯ç”¨AOLè¾…åŠ©å¹³æ—¶çš„æ–¹æ³•å†³ç­–ä¸€ä¸‹ï¼š è€Œåè®²äº†ä¸TPPã€Nomadã€NBTç­‰æ–¹æ³•çš„é›†æˆã€‚ 6.Evaluation å…³æ³¨1ï¼šCXLæ¨¡æ‹Ÿæ–¹å¼ï¼šSKX lowering the uncore frequency and disabling cores on one NUMA node å…³æ³¨2ï¼šworkloads : GAPBSã€MLã€cachingã€SPEC2017 æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ’åº ALTOæ•ˆæœã€‚ ä¸è¶³ä¸æœºä¼šï¼š1.ä»MLPçš„è§’åº¦åˆ†æï¼Œå’Œé¢„å–æœ‰å…³ç³»å—ï¼Ÿå¯¹äºé¢„å–çš„å½±å“ï¼ˆå¦‚æœè¿™ä¸ªä¸œè¥¿èƒ½é‡åŒ–ï¼Œä¹Ÿèƒ½åˆ†æå‡ºå¾ˆå¤šä¸œè¥¿ï¼‰ 2.å¹¶æ²¡æœ‰è€ƒè™‘åŒºåˆ†è¯»å†™æ¯”ä¾‹çš„å½±å“ï¼Ÿ 3.æœ¬æ–‡ä¸­ç¬¬4èŠ‚æåˆ°çš„é€šè¿‡è®¿å­˜æ¯”ä¾‹æ¥åˆ†é…å†…å­˜slowdownçš„åšæ³•æ˜¯å¦åˆç†ï¼Ÿ æ˜¯å› ä¸ºå…¶æŒ‡æ ‡æ˜¯åŸºäºperf statçš„ï¼Œå¦‚æœå…¨éƒ¨ç”¨perf recordçš„æ–¹æ³•æ˜¯å¦ä¼šæ›´åŠ ç²¾ç¡®ï¼Ÿè¿™ä¸€ç‚¹ä½œè€…æ²¡æœ‰è¯¦ç»†æè¿°ã€‚ hard 4.å…¨éƒ¨æ”¾åœ¨è¿è¡Œæ—¶è¿›è¡Œå˜é‡åˆ†æä¼šä¸ä¼šå‘ç”Ÿé‡‡æ ·ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œåœ¨NeoMemä¸­ä¹Ÿæœ‰ï¼Ÿä½†æ˜¯å¦‚ä½•è§£å†³ï¼Ÿå¯ä¸å¯ä»¥ç»“åˆNeoMemå®Œå…¨æ•è·æ•°æ®æµï¼Ÿ åŸºäºé‡‡æ ·ï¼Œé•¿ç”Ÿå‘½å‘¨æœŸçš„å¯èƒ½é‡‡é›†åˆ°ï¼ŒçŸ­ç”Ÿå‘½å‘¨æœŸå–æ ·ã€‚ æœºå™¨çš„æ‹“å±•æ€§ï¼Œé’ˆå¯¹SPXï¼Œå…¶ä»–çš„SPRã€EMRçš„å¯¹åº”äº‹ä»¶çš„æ‹“å±•æ€§æ›¿ä»£å¦‚ä½•ï¼Œæ˜¯å¦éƒ½åªæ˜¯PEBSï¼Ÿ ä¹±åºæ ¡æ­£çš„å½±å“å¤§ä¸å¤§ï¼Ÿ ä¾‹å¦‚ä¸‰æ®µå¼çš„ï¼Œç¬¬ä¸€æ¬¡è¿›è¡Œçƒ­ç‚¹ä»£ç è¯†åˆ«ï¼Œç¬¬äºŒæ¬¡å°†çƒ­ç‚¹ä»£ç å…¨éƒ¨å¸è½½åˆ°CXLï¼Œç„¶ååˆ©ç”¨Neomemæ•è·traceï¼Œä»è€Œå‡†ç¡®æ„ŸçŸ¥ï¼Œæœ€åæ ¹æ®å†³ç­–å®ç°æ•°æ®æ”¾ç½®ï¼Ÿ hard 5.ç»“åˆå†…å­˜åˆ†é…å™¨è¿›è¡Œå°å˜é‡é¡µå†…é›†ä¸­ä¼˜åŒ–ï¼Œå¤§å˜é‡çš„è®¿é—®æ˜¯å¦é›†ä¸­ï¼Ÿä¸é›†ä¸­çš„è¯å¯ä»¥ç”¨perfé‡‡é›†åœ°å€ï¼Œç„¶åç»˜åˆ¶è®¿å­˜ç›´æ–¹å›¾ã€‚","tags":[null]},{"title":"LLVM","path":"/notebooks/compiler_kernel/LLVM/LLVM.html","content":"å…¥é—¨llvmç¬”è®° 1.æ–°æ—§æ–°å¢passæµç¨‹ 2CRTPï¼ˆå¥‡å¼‚é€’å½’æ¨¡æ¿æ¨¡å¼ï¼‰(ä»¥ä¸‹å†…å®¹åŸºäºAIç”Ÿæˆåä¿®æ”¹) é€šå¸¸é€šè¿‡ç»§æ‰¿çš„æ–¹å¼å®ç°å•ä¾‹æ¨¡å¼ä¹Ÿæ˜¯è¿™æ ·ï¼Œåªæ˜¯ä¸çŸ¥é“å«è¿™ä¸ªåå­— CRTPï¼ˆCuriously Recurring Template Patternï¼Œå¥‡å¼‚é€’å½’æ¨¡æ¿æ¨¡å¼ï¼‰æ˜¯C++ä¸­çš„ä¸€ç§é«˜çº§æ¨¡æ¿ç¼–ç¨‹æŠ€æœ¯ï¼Œé€šè¿‡è®©ä¸€ä¸ªç±»ç»§æ‰¿è‡ªä»¥è‡ªèº«ä¸ºæ¨¡æ¿å‚æ•°çš„åŸºç±»æ¨¡æ¿ï¼Œå®ç°é™æ€å¤šæ€æˆ–ä»£ç å¤ç”¨ã€‚ template typename Derivedclass Base /* åŸºç±»ä½¿ç”¨Derivedç±»å‹ */ ;class MyClass : public BaseMyClass /* æ´¾ç”Ÿç±»å°†è‡ªèº«ä½œä¸ºæ¨¡æ¿å‚æ•°ä¼ é€’ç»™åŸºç±» */ ; æ ¸å¿ƒä½œç”¨1. é™æ€å¤šæ€ï¼ˆç¼–è¯‘æ—¶å¤šæ€ï¼‰ åŠ¨æ€å¤šæ€ï¼ˆè™šå‡½æ•°ï¼‰çš„é—®é¢˜ï¼šè¿è¡Œæ—¶è™šè¡¨æŸ¥æ‰¾å¯¼è‡´æ€§èƒ½å¼€é”€ã€‚ CRTPçš„è§£å†³æ–¹æ¡ˆï¼šåŸºç±»åœ¨ç¼–è¯‘æ—¶é€šè¿‡æ¨¡æ¿å‚æ•°ç›´æ¥è°ƒç”¨æ´¾ç”Ÿç±»çš„æ–¹æ³•ã€‚ template typename Derivedclass Animal public: void speak() static_castDerived*(this)-speakImpl(); // ç¼–è¯‘æ—¶ç¡®å®šè°ƒç”¨ ;class Cat : public AnimalCat public: void speakImpl() std::cout Meow ; ;class Dog : public AnimalDog public: void speakImpl() std::cout Woof ; ;// ä½¿ç”¨AnimalCat cat;cat.speak(); // è¾“å‡º Meowï¼ˆæ— è™šå‡½æ•°å¼€é”€ï¼‰ 2. ä»£ç å¤ç”¨ åŸºç±»å¯æä¾›é€šç”¨é€»è¾‘ï¼Œæ´¾ç”Ÿç±»é€šè¿‡ç‰¹åŒ–å®ç°å·®å¼‚éƒ¨åˆ†ã€‚ template typename Derivedclass Counter protected: static int count;public: Counter() ++count; static int getCount() return count; ;template typename Derivedint CounterDerived::count = 0;// ç»Ÿè®¡å¯¹è±¡å®ä¾‹æ•°çš„ç±»class Widget : public CounterWidget ;class Gadget : public CounterGadget ;// ä½¿ç”¨Widget w1, w2;Gadget g1;std::cout Widget::getCount(); // è¾“å‡º 2std::cout Gadget::getCount(); // è¾“å‡º 1 CRTP vs è™šå‡½æ•° ç‰¹æ€§ CRTP è™šå‡½æ•° å¤šæ€æ—¶æœº ç¼–è¯‘æ—¶ è¿è¡Œæ—¶ æ€§èƒ½ æ— é¢å¤–å¼€é”€ï¼ˆç›´æ¥è°ƒç”¨ï¼‰ è™šè¡¨æŸ¥æ‰¾å¼€é”€ çµæ´»æ€§ ç±»å‹å›ºå®šï¼ˆæ¨¡æ¿å‚æ•°éœ€æ˜ç¡®ï¼‰ æ”¯æŒè¿è¡Œæ—¶ç±»å‹åŠ¨æ€æ›¿æ¢ é€‚ç”¨åœºæ™¯ é«˜æ€§èƒ½åº“ã€æ¡†æ¶åŸºç¡€è®¾æ–½ éœ€è¦è¿è¡Œæ—¶åŠ¨æ€è¡Œä¸ºçš„æƒ…å†µ CRTPçš„å…¸å‹åº”ç”¨åœºæ™¯ ç¼–è¯‘æ—¶å¤šæ€ï¼šå¦‚æ•°å­¦åº“ä¸­çš„å‘é‡çŸ©é˜µè¿ç®—ï¼ˆEigenåº“ï¼‰ã€‚ å¯¹è±¡è®¡æ•°ï¼šç»Ÿè®¡ä¸åŒæ´¾ç”Ÿç±»çš„å®ä¾‹æ•°é‡ã€‚ Mixinæ¨¡å¼ï¼šä¸ºç±»åŠ¨æ€æ·»åŠ åŠŸèƒ½ï¼ˆå¦‚LLVMçš„PassInfoMixinï¼‰ã€‚ é“¾å¼è°ƒç”¨ï¼šè¿”å›æ´¾ç”Ÿç±»å¼•ç”¨ä»¥å®ç°é“¾å¼è¯­æ³•ï¼ˆreturn static_castDerived(*this);ï¼‰ã€‚ 3 LLVMä¸CPPå®ç°DenseMapä¸stdMapdyn_castä¸RTTI isadef-use user-valueä¸ºä»€ä¹ˆllvmä¸­Userä¼šç»§æ‰¿value 4 æ”¯é…æ ‘åŸºæœ¬æ¦‚å¿µæ”¯é…æ ‘ wiki ä¸¥æ ¼æ”¯é…ï¼ˆStrict Dominationï¼‰ï¼šå¦‚æœ A æ”¯é… B ä¸” A â‰  Bï¼Œåˆ™ç§° A ä¸¥æ ¼æ”¯é… Bã€‚ ç«‹å³æ”¯é…è€…ï¼ˆImmediate Dominator, idomï¼‰ï¼šå¯¹äºæŸä¸ªåŸºæœ¬å— Bï¼Œå…¶è¢«ä¸¥æ ¼æ”¯é…çš„æ‰€æœ‰åŸºæœ¬å—ä¸­ï¼Œç¦» B æœ€è¿‘çš„é‚£ä¸ªç§°ä¸º B çš„ç«‹å³æ”¯é…è€…ã€‚ LLVMä¸­çš„ä½¿ç”¨åœºæ™¯ æ­»ä»£ç æ¶ˆé™¤ (Dead Code Elimination) æ­»ä»£ç æ¶ˆé™¤æœ‰å¤šç§æ–¹æ³•å¤šç§ç²’åº¦ï¼Œè¿™é‡Œblockä¸ºç²’åº¦å¯ä»¥ä½¿ç”¨æ”¯é…æ ‘æ–¹æ³• å¦‚æœä¸€ä¸ªåŸºæœ¬å—ä¸åœ¨å…¥å£å—çš„æ”¯é…æ ‘ä¸Šï¼Œé‚£è¯´æ˜å®ƒåœ¨æŸäº›è·¯å¾„ä¸Šæ ¹æœ¬æ— æ³•åˆ°è¾¾ï¼Œå› æ­¤å¯èƒ½æ˜¯ä¸å¯è¾¾ä»£ç ã€‚ if (!DT-dominates(entry, B)) B-eraseFromParent(); // åˆ é™¤ä¸å¯è¾¾çš„åŸºæœ¬å— å¾ªç¯è¯†åˆ« (Loop Identification) LICMï¼ˆLoop-Invariant Code Motionï¼‰æ˜¯ä¸€ç§ç»å…¸çš„å¾ªç¯ä¼˜åŒ–ç­–ç•¥ã€‚è¦å®‰å…¨åœ°å°†ä¸€æ¡æŒ‡ä»¤ä»å¾ªç¯ä½“ä¸­ç§»å‡ºï¼ˆå¤–æåˆ°å‰ç½®å—ä¸­ï¼‰ï¼Œå¿…é¡»ä¿è¯å…¶åœ¨æ‰€æœ‰å¾ªç¯å…¥å£éƒ½è¢«æ‰§è¡Œã€‚ åˆ¤æ–­æŸæ¡æŒ‡ä»¤çš„åŸºæœ¬å¼€æ˜¯å¤Ÿè¢«å¾ªç¯å…¥å£å—æ”¯é…ï¼Œå¦‚æœæ”¯é…ï¼Œåˆ™è¯´æ˜æ¯æ¬¡éƒ½ä¼šæ‰§è¡Œè¿™æ¡æŒ‡ä»¤ï¼Œå¯ä»¥å¤–æ é™æ€å•èµ‹å€¼èŠ‚ç‚¹Î¦ èŠ‚ç‚¹æ’å…¥ å…³é”®ç±»ä¸å…³é”®æ¥å£ DominatorTreeï¼šæ ¸å¿ƒæ”¯é…æ ‘å®ç°ï¼Œllvm/IR/Dominators.h DominatorTreeWrapperPassï¼šå°†æ”¯é…æ ‘å°è£…ä¸ºåˆ†æPass DominatorTreeAnalysisï¼šæ”¯é…æ ‘åˆ†æ DominatorTree DT = getAnalysisDominatorTreeWrapperPass().getDomTree(); ä½œç”¨ï¼š invoke callCallBaseInvokeInst å¤„ç†å™¨ç¡¬ä»¶è®¡æ•°pt LBR PEBS","tags":[null]},{"title":"Kernel-compile","path":"/notebooks/compiler_kernel/Linux kernel/Kernel-compile.html","content":"å†…æ ¸ç¼–è¯‘#æŸ¥çœ‹å½“å‰å†…æ ¸ç‰ˆæœ¬uname -a#æºç è·å–sudo apt-get install linux-sourcecd /usr/srctar xvf linux-source-*.tar.bz2cd linux-source-*#è¡¥ä¸åº”ç”¨patch -p1 /path/to/patch.diff#`-p1`é€‰é¡¹å¯èƒ½éœ€è¦æ ¹æ®è¡¥ä¸æ–‡ä»¶çš„æ ¼å¼è¿›è¡Œè°ƒæ•´ã€‚make menuconfig #æˆ–è€…oldconfig,æœ¬è´¨æ˜¯é…ç½®/usr/src/configmake -j$(nproc)#æ ¹æ® .config é…ç½®æ–‡ä»¶ç¼–è¯‘å†…æ ¸ã€å†…æ ¸æ¨¡å—å’Œå…¶ä»–å¿…è¦çš„æ–‡ä»¶ï¼Œç”Ÿæˆå†…æ ¸é•œåƒï¼ˆvmlinuzï¼‰å’Œå…¶ä»–ç›¸å…³çš„æ–‡ä»¶#ç¼–è¯‘è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°æ¯åŒ…å¤´æ–‡ä»¶æˆ–è€…å…¶ä»–é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç‰ˆæœ¬åŸå› ï¼Œé’ˆå¯¹æŠ¥é”™è§£å†³å³å¯#å†…æ ¸å®‰è£…#å®‰è£…è¿‡ç¨‹å¯èƒ½ä¼šå‡ºç°å¤´æ–‡ä»¶æŠ¥é”™æˆ–è€…ç¼ºåº“ã€æˆ–å®‰è£…å®Œæˆåç¼ºåº“ï¼Œåªéœ€è¦aptå®‰è£…å¯¹åº”çš„åº“å°±å¥½ï¼Œmakeè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨hook#å®‰è£…å†…æ ¸æ¨¡å—(åœ¨è¿è¡Œæ—¶å¯ä»¥åŠ è½½æˆ–å¸è½½çš„æ¨¡å—)#ä»ç¼–è¯‘è¾“å‡ºçš„ç›®å½•ï¼ˆå¦‚ lib/modules/kernel_version/ï¼‰,å¹¶æ‰§è¡Œ depmod æ¥ç”Ÿæˆæ¨¡å—ä¾èµ–å…³ç³»sudo make modules_install#å†…æ ¸é•œåƒï¼ˆå¦‚ vmlinuzï¼‰ã€é…ç½®æ–‡ä»¶ï¼ˆå¦‚ configï¼‰ã€ç¬¦å·è¡¨æ–‡ä»¶ï¼ˆå¦‚ System.mapï¼‰å’Œ initrd é•œåƒå®‰è£…åˆ° /boot ç›®å½•sudo make install#æ›´æ–°å¯åŠ¨å¼•å¯¼ç¨‹åºsudo update-grup å…³äºé…ç½®é€‰é¡¹ç›¸å…³æ“ä½œï¼Œå‚è€ƒï¼š:star::star:Linux å†…æ ¸åŠ¨æ‰‹ç¼–è¯‘å®ç”¨æŒ‡å— KGDBé…ç½®ç¼–è¯‘é€‰é¡¹ å‚è€ƒèµ„æ–™KGDBåŸç†åˆ†æåŠè¿œç¨‹æŒ‚è½½è°ƒè¯•ARM64å†…æ ¸ å†…æ ¸å¯åŠ¨å‚æ•° kgdboc=ttyS0,115200 kgdbwait kgdbtcp=192.168.1.2:1234 kgdboc=ttyS0,115200ï¼šè®¾ç½®ä¸²å£è°ƒè¯•ï¼ˆå¯é€‰ï¼‰ kgdbwaitï¼šå¯åŠ¨æ—¶ç­‰å¾…è°ƒè¯•å™¨è¿æ¥ kgdbtcp=192.168.1.2:1234ï¼šè¢«è°ƒè¯•ä¸»æœºçš„IPå’Œç«¯å£ æ°¸ä¹…ä¿®æ”¹ï¼š/etc/default/grubä¸‹GRUB_CMDLINE_LINUXå˜é‡ proxmox-boot-toolproxmox-boot-toolï¼Œä¸€ä¸ªè„šæœ¬ï¼Œè®¾ç½®å¯åŠ¨å†…æ ¸ã€å¢åˆ å†…æ ¸ç­‰,ä½¿ç”¨è®¾ç½®grubå†…æ ¸å¯åŠ¨å‚æ•°çš„æ–¹å¼ä¸ä¸€å®šç”Ÿæ•ˆçš„æƒ…å†µä¸‹å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·ã€‚ proxmox-boot-tool git clone https://git.proxmox.com/git/proxmox-kernel-helper.gitä¹‹å make debä¼šåœ¨å½“å‰è·¯å¾„ä¸‹ç”Ÿæˆå¯¹åº”çš„debåŒ…ï¼Œapt installå®‰è£…åå¯ä»¥æ­£å¸¸ä½¿ç”¨/usr/sbin/proxmox-boot-tool å‚è€ƒé“¾æ¥ï¼šhttps://kernelnewbies.org/KernelBuild","tags":[null]},{"title":"Neoperf_study","path":"/notebooks/compiler_kernel/Linux kernel/Neoperf-study.html","content":"NeoPerf study æœ¬æ–‡ä¸»è¦ä¸ºå­¦ä¹ è®ºæ–‡ã€ŠNeoMem: HardwareSoftware Co-Design for CXL-Native Memory Tieringã€‹çš„å·¥ä½œï¼Œåˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œç”¨æˆ·æ€ã€å†…æ ¸ä»¥åŠFPGAéƒ¨åˆ†ï¼Œå†…æ ¸å¼€æºä»“åº“åœ°å€ä¸ºï¼š PKUZHOUlinux ä»£ç åŸºäºlinuxå†…æ ¸ä»£ç 6.0å¼€å§‹ä¿®æ”¹ã€‚ ç”±äºåˆæ­¥æ¢ç´¢linuxå†…æ ¸ä»£ç ï¼Œæ‰€ä»¥æ²¡æœ‰æŒ‰ç…§è‡ªé¡¶å‘ä¸‹çš„è§†è§’åˆ†æä»£ç ï¼Œè€Œæ˜¯åŸºäºgitæäº¤è®°å½•ï¼Œå€ŸåŠ©AIä¸äº’è”ç½‘æœç´¢ï¼Œå¹³é“ºé‡åˆ°çš„ç›¸å…³çŸ¥è¯†ã€‚ç‰ˆæœ¬ä¸æ–­æ›´æ–°â€¦â€¦ a naive neoprof drivercommit ID 9bd35383 æœ¬æ¬¡ä¸»è¦åœ¨driverç›®å½•ä¸‹æäº¤äº†ä¸€ä¸ªé©±åŠ¨neoperf: ä¸»è¦æ˜¯å®ç°äº†ä¸€äº›å¯¹å¤–è®¾çš„IOæ“ä½œ Linuxå†…æ ¸é…ç½®æ–‡ä»¶KconfigKconfigæ–‡ä»¶ç”¨äºå®šä¹‰å†…æ ¸é…ç½®èœå•ï¼Œè¿™äº›èœå•å¯ä»¥åœ¨ç¼–è¯‘å†…æ ¸æ—¶å¯ç”¨æˆ–ç¦ç”¨ç‰¹å®šçš„åŠŸèƒ½ã€‚ #Kconfigæ–‡ä»¶config NEOPROF#å®šä¹‰äº†ä¸€ä¸ªåä¸º`NEOPROF`çš„å†…æ ¸é…ç½®é€‰é¡¹ï¼Œå°†åœ¨å†…æ ¸é…ç½®èœå•ä¸­åˆ›å»ºé€‰é¡¹\tbool Enable Neoprofiler #boolç±»å‹ï¼Œæ˜¯å¦å¯ç”¨ default n #é»˜è®¤ä¸å¯ç”¨ åœ¨å†…æ ¸ç¼–è¯‘è¿‡ç¨‹ä¸­å¯ä»¥åœ¨Driversä¸‹æŸ¥æ‰¾åˆ° Kconfigæœ‰å…¶ç‹¬ç‰¹çš„è¯­æ³•ï¼Œä¹Ÿæ˜¯å¯ä»¥ä¸€å±‚ä¸€å±‚åŒ…è£¹ä¸‹å»ï¼šmenuã€sourceã€endmenuç­‰ç»„æˆäº†ç¼–è¯‘é€‰é¡¹é…ç½®è¿‡ç¨‹ä¸­çš„æ ‘çŠ¶èœå• Kconfigè®¾ç½®å¯¹åº”çš„ç¼–è¯‘å˜é‡åï¼ŒmakefileæŒ‡å¯¼æ„å»ºç¼–è¯‘çš„è¿‡ç¨‹ä¸­ä¼šåˆ©ç”¨è¿™äº›å˜é‡ï¼Œä»è€Œå®ç°é€‰æ‹©æ€§çš„ç¼–è¯‘ neoperf.hä¸»è¦æ–°å¢äº†å››ä¸ªæ¥å£ï¼Œå¯¹neoprofè®¾å¤‡ï¼ˆæ­¤å¤„æŒ‡Type2-CXLè®¾å¤‡ï¼‰è¿›è¡Œè®¿é—®ï¼š /* * The following functions are used to access the neoprof device*/u64 get_nr_hotpages(void);//è·å–å½“å‰ç³»ç»Ÿä¸­çš„çƒ­é¡µæ•°é‡u64* get_hotpages(void);//è·å–çƒ­é¡µu64 get_hotness_threshold(void);//è·å–çƒ­åº¦é˜ˆå€¼void set_hotness_threshold(u64 threshold);//è®¾ç½®çƒ­åº¦é˜ˆå€¼ neoperf.cé©±åŠ¨å¼€å‘hello worldneoperf.c ä»¥ä¸‹éƒ¨åˆ†å‚è€ƒé©±åŠ¨å¼€å‘çŸ¥è¯†ï¼šhttps://www.cnblogs.com/downey-blog/p/10500828.html module_init(neoprof_init);module_exit(neoprof_exit);MODULE_LICENSE(GPL v2);MODULE_AUTHOR(PKUZHOU);MODULE_DESCRIPTION(Neoprofiler Linux driver); ioåœ°å€æ˜ å°„ç›¸å…³çŸ¥è¯†éœ€è¦ç†è§£ IOç«¯å£çš„ç¼–å€æ–¹å¼ï¼š åŒ…æ‹¬IOæŒ‡ä»¤çš„ç«¯å£æ˜ å°„æ–¹å¼ã€MMIOçš„ç»Ÿä¸€å†…å­˜æ˜ å°„æ–¹å¼ ä¸€äº›å¸¸è§çš„IOæ“ä½œå‡½æ•° void * ioremap(unsigned long phys_addr, unsigned long size, unsigned long flags); //memset_io\\memcpy_fromio\\readb å‚è€ƒï¼šhttps://blog.csdn.net/do2jiang/article/details/5450839 neomem migration skeletoncommit ID 26cabad18 æ–°å¢ NeoMemæ¨¡å—: migrate.cä¸»è¦æ˜¯æä¾›æ¥å£migrate_misplaced_page_no_vma è°ƒç”¨ä¸€äº›mmä¸­çš„å†…å­˜æ“ä½œå‡½æ•°ï¼Œè¿›è¡Œé¡µé¢éš”ç¦»ã€è¿ç§» neomem.h eomem.cä¸»è¦å°±æ˜¯å¯åŠ¨ neomemæ¨¡å—ï¼ˆè°ƒç”¨coreæ–‡ä»¶ä¸­å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹ï¼‰ late_initcall()åœ¨å†…æ ¸å¯åŠ¨åæœŸé€‚å½“æ—¶é—´æ‰§è¡Œï¼Œç†è§£module_initç­‰initå®çš„é¡ºåºï¼Œåœ¨include/linux/init.hä¸­ linuxè®¾å¤‡é©±åŠ¨åŠ è½½çš„å…ˆåé¡ºåº neomem_core.c å†…å­˜ä¸­çš„å„ç§åˆ†é…å‡½æ•° kthread_runå†…æ ¸çº¿ç¨‹ FPGAç«¯ä¾§æ¨¡å—ç»“æ„é¡¶å±‚æ¨¡å—ï¼š cxltyp3_memexp_ddr4_top-ed_top_wrapper_typ3 ddrå†…å­˜å‚æ•°è°ƒæ•´cxl ipè€ƒè™‘äº†ä¸åŒddrçš„ï¼ŒåŒ…æ‹¬æ˜¯å¦æ”¯æŒDBIã€å†…å­˜é€šé“æ•°é‡ç­‰ã€‚é‡‡ç”¨å®çš„æ–¹å¼åŒºåˆ†ï¼Œè®¾ç½®ä¸åŒçš„æ–¹å¼æ—¶ï¼Œéœ€è¦å¯¹ipå†…é€šè¿‡å®å®šä¹‰æ¥ç¡®å®šç›¸å…³çš„å†…å­˜å‚æ•°ï¼ŒåŒæ—¶ä¹Ÿéœ€è¦åœ¨é¡¶å±‚æ¨¡å—å¯¹ç›¸å…³å‚æ•°è¿›è¡Œä¿®æ”¹ã€‚ .qbluyxirhyrk{zoom:50%;} .afhbswqndgtc{zoom:50%;} .gcccmhmdxspk{zoom:50%;} æˆ–è€…é€šè¿‡æ›´æ”¹ipæ–‡ä»¶ï¼Œé‡æ–°ç”Ÿæˆæ–°çš„IPæ–‡ä»¶å¤¹ .xqviikzffrmr{zoom:50%;} quartusset_global_assignment -name OPTIMIZATION_MODE AGGRESSIVE COMPILE TIME çƒ§å½•æ¨¡å¼AS Jtag ps ä¸‰ç§çƒ§å½•æ¨¡å¼ Neomem todoä»£ç å­˜åœ¨ä¸€äº›å¯ä»¥å®Œå–„çš„åœ°æ–¹ï¼š CXLåœ°å€é‡‡ç”¨ç¡¬ç¼–ç ï¼Œå¯ä»¥å¼•å…¥è®¾å¤‡æ ‘æˆ–è€…å…¶ä»–æ£€æµ‹CXLç‰©ç†åœ°å€çš„å·¥å…·è¿›è¡Œä¼˜åŒ–ï¼Œå‚è€ƒ","tags":[null,null,null,null,null]},{"title":"linuxè„šæœ¬å¤‡å¿˜å½•","path":"/notebooks/compiler_kernel/Linux kernel/linuxè„šæœ¬å¤‡å¿˜å½•.html","content":"Linuxè„šæœ¬å¤‡å¿˜å½•å®‰è£…ç³»ç»Ÿåçš„ç¯å¢ƒå‡†å¤‡æ·»åŠ æ–°ç”¨æˆ· adduser #å°è£…å‘½ä»¤ï¼Œå¤„ç†å®Œæ·»åŠ ç”¨æˆ·çš„å…¨éƒ¨è¿‡ç¨‹ suåˆ°æ–°ç”¨æˆ·æ˜¾ç¤ºusername@hostname~$:useradd #åº•å±‚å‘½ä»¤ï¼Œä»€ä¹ˆéƒ½æ²¡æœ‰åŠ ,suåˆ°æ–°ç”¨æˆ·æ˜¾ç¤º$:# ç”Ÿæˆ 8 ä½å¼ºå¯†ç PASSWORD=$(openssl rand -base64 6 | cut -c1-8)echo Password: $PASSWORD ç”¨æˆ·æ·»åŠ sudoç»„ usermod -aG sudo new_user#åŠ å®Œä»¥åè®°å¾—:newgrp sudo#ä½œç”¨æœ‰3ï¼š#1.åˆ‡æ¢åˆ°æŒ‡å®šçš„ç»„ä¸Šä¸‹æ–‡#2.å³æ—¶ç”Ÿæ•ˆç»„æ›´æ”¹#3.å¯åŠ¨ä¸€ä¸ªå­ shell é…ç½®sshd#æœåŠ¡ç«¯å®‰è£…apt install ssh-server#é…ç½®sudo vim /etc/ssh/sshd_config#é‡å¯æœåŠ¡sudo service restart sshd VimVimé…ç½®æ¨è - ma6174 wget 47.93.11.51:88/install_vim.shbash install_vim.sh zsh#å®‰è£…zshsudo apt install zsh#ä¿®æ”¹é»˜è®¤shellä¸ºzshchsh -s /bin/zsh#å®‰è£…oh-my-zshsh -c $(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)##å¦‚æœä¸æˆåŠŸï¼Œè¯·æ‰§è¡Œä¸‹é¢ä¸¤æ¡å‘½ä»¤ï¼ŒæˆåŠŸäº†å°±ä¸éœ€è¦åšä¸‹é¢ä¸¤æ¡wget 47.93.11.51:88/install_zsh.shbash install_zsh.sh#å®‰è£…zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM:-~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting å†å²è®°å½•æ¨èå‘½ä»¤æ’ä»¶##å‘½ä»¤è‡ªåŠ¨æ¨èï¼Œæ ¹æ®å†å²è®°å½•git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM:-~/.oh-my-zsh/custom/plugins/zsh-autosuggestions å‘½ä»¤è‡ªåŠ¨è¡¥å…¨##å‘½ä»¤è‡ªåŠ¨è¡¥å…¨æ’ä»¶mkdir ~/.oh-my-zsh/plugins/incrwget http://mimosa-pudica.net/src/incr-0.2.zsh -O ~/.oh-my-zsh/plugins/incr/incr.plugin.zsh##ç›®å½•è‡ªåŠ¨è·³è½¬æ’ä»¶sudo apt install autojump .zshrcé…ç½®æ–‡ä»¶é…ç½®#æ’ä»¶æ·»åŠ zsh-syntax-highlightingplugins=(git zsh-syntax-highlighting) #è®¾ç½®ç»ˆç«¯é¢œè‰²ï¼Œæç¤ºç¬¦ï¼ŒåŠä¸Šä¸€æ¡æŒ‡ä»¤è¿”å›ç æç¤ºautoload -U colors colorsPROMPT=%$fg[red]%%n%$reset_color%@%$fg[blue]%%m %$fg[yellow]%%1~ %$reset_color%%# RPROMPT=[%$fg[yellow]%%?%$reset_color%]# Useful support for interacting with Terminal.app or other terminal programs[ -r /etc/zshrc_$TERM_PROGRAM ] . /etc/zshrc_$TERM_PROGRAMsource ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions/zsh-autosuggestions.plugin.zshsource /usr/share/autojump/autojump.shsource ~/.oh-my-zsh/plugins/incr/incr*.zsh ctags#å®‰è£…sudo apt install ctags #å»ºç«‹ç´¢å¼•ctags -I __THROW -I __attribute_pure__ -I __nonnull -I __attribute__ --file-scope=yes --langmap=c:+.h --languages=c,c++ --links=yes --c-kinds=+p --c++-kinds=+p --fields=+iaS --extra=+q -f ~/.vim/systags /usr/include/* /usr/include/x86_64-linux-gnu/sys/* /usr/include/x86_64-linux-gnu/bits/* /usr/include/arpa/* .vimrcæ·»åŠ ç´¢å¼• set tags+=~/systags å®‰è£…glibc-doc ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… sudo apt install glibc-doc å¸¸è§è·¯å¾„hostname :/etc/hostname host: /ect/hosts tomcat#å®‰è£…JDK8sudo apt install default-jre -ysudo apt install openjdk-11-jre-headless -ysudo apt install openjdk-8-jre-headless -y #sudo wget https://downloads.apache.org/tomcat/tomcat-8/v8.5.65/bin/apache-tomcat-8.5.65.tar.gzsudo wget https://mirrors.bfsu.edu.cn/apache/tomcat/tomcat-8/v8.5.73/bin/apache-tomcat-8.5.73.tar.gztar zxf apache-tomcat-8.5.73.tar.gzsudo mv apache-tomcat-8.5.73 /usr/local/tomcat#å»ºç«‹è½¯è¿æ¥sudo ln -s /usr/local/tomcat/bin/* /usr/local/sbin/#å¯åŠ¨startup.sh start #ç«¯å£æ£€æŸ¥netstat -anput | grep 8080#å¯åŠ¨å‘½ä»¤startup.sh start #//å¯åŠ¨shutdown.sh #//å…³é—­catalina.sh stop #//å¯åŠ¨catalina.sh start #//å…³é—­#å…³é—­é˜²ç«å¢™sudo ufw disable #tomcat å‚æ•°é…ç½®vim /usr/local/tomcat/conf/server.xml #.......Connector port=8081 protocol=HTTP/1.1 #å°†ä¹‹å‰8080ç«¯å£æ”¹æˆ8081ç«¯å£connectionTimeout=20000 # redirectPort=8443 /#ç›®å½•ä¿® # Host name=localhost appBase=/opt/www #å°†ç½‘ç«™æ ¹ç›®å½•æ”¹åˆ°/opt/www # unpackWARs=true autoDeploy=true#æ›´æ”¹ç½‘ç«™å®¶ç›®å½•ï¼Œè¿™é‡Œçš„ROOTå¿…é¡»å¤§å†™ï¼Œæ›´æ”¹å®Œæˆåéœ€è¦é‡å¯sudo mkdir /opt/www/ROOT -p mysqlmysql 8.0ä¸‹è½½ wget https://repo.mysql.com//mysql-apt-config_0.8.20-1_all.deb #MySQL è®¾ç½®#å¯†ç sudo mysql -uroot use mysql;update user set authentication_string=PASSWORD(è‡ªå®šä¹‰å¯†ç ) where User=root;update user set plugin=mysql_native_password where User =root;flush privileges;quit; å¯¹äºLinuxå’Œwindowsä¸‹å­—ç¬¦é›†ä¸å…¼å®¹çš„æƒ…å†µï¼Œéœ€è¦æ›¿æ¢ â€¢ æŠŠæ–‡ä»¶ä¸­çš„æ‰€æœ‰çš„utf8mb4_0900_ai_ciæ›¿æ¢ä¸ºutf8_general_ciâ€¢ ä»¥åŠutf8mb4æ›¿æ¢ä¸ºutf8â€¢ å¦‚ä¸Šå›¾æ‰€ç¤ºçš„ä½ç½®ï¼Œä¸Šå›¾åªæ˜¯ä¸€éƒ¨åˆ†ï¼Œæ³¨æ„å…¨éƒ¨æ›¿æ¢ã€‚ æ•°æ®åº“å¯¼å‡º mysqldump -uroot -p c:ShareYunAlbumã€‚sql æ•°æ®åº“å¯¼å…¥ use ShareYunAlbum source ~/ShqreYunAlbum.sql å¸è½½mysql sudo apt purge mysql-* -ysudo rm -rf /etc/mysql/ /var/lib/mysqlsudo apt autoremovesudo apt autorecleansudo apt-get remove mysql-common dpkg -l |grep ^rc|awk print $2 |sudo xargs dpkg -P","tags":[null]},{"title":"llama.cpp","path":"/notebooks/other/å¤§æ¨¡å‹/llama-cpp.html","content":"Llama.cppæºç æµ…æggml æºç ç»“æ„å­¦ä¹ å…¥å£å‡½æ•°ç®€å•ä»¥llama.cliä½œä¸ºæ¨ç†å­¦ä¹ çš„å…¥å£ã€‚å…¶å…¥å£å‡½æ•°mainä½ç½®ä¸ºï¼šllama.cpp/tool/main.cpp/main() å…³é”®æ•°æ®ç»“æ„å†…å­˜ç®¡ç†Arena åˆ†é…å™¨â€œæ‰¹å‘å†…å­˜ï¼Œé›¶å”®æŒ‡é’ˆï¼Œæ•´å•æ¸…åœºâ€ æ‰¹å‘å†…å­˜ï¼š é›¶å”®æŒ‡é’ˆ æ•´åœºæ¸…é™¤ï¼š mmapæ¨¡å‹åŠ è½½æµç¨‹ï¼š æ ¸å¿ƒæ­¥éª¤ï¼š llama_model_loadre æ ¸å¿ƒå¯¹è±¡. ä¹‹ååŠ è½½æ¨¡å‹æ¶æ„arch\\è¶…å‚æ•°hparams\\è¯è¡¨vocab\\å…ƒæ•°æ®ä¿¡æ¯ã€ä»¥åŠå¼ é‡tensors","tags":[null]},{"title":"å¤§æ¨¡å‹å…¥é—¨","path":"/notebooks/other/å¤§æ¨¡å‹/å¤§æ¨¡å‹å…¥é—¨.html","content":"å¤§æ¨¡å‹åŸºç¡€æ¦‚å¿µå…¥é—¨Transformerè‡ªæ³¨æ„åŠ›ï¼ˆSelf-Attentionï¼‰Q\\K\\V Qï¼šç›®å‰å…³ç³»çš„é—®é¢˜ï¼Œå½“å‰token; K:tokençš„æ ‡ç­¾ V:åŒ…å«çš„ä¿¡æ¯ Q*Kå¾—åˆ°è°æ›´é‡è¦ï¼Œä¹‹åå†ä¹˜ä»¥Vå¾—åˆ°è¿™äº›é‡è¦çš„äººè¯´äº†ä»€ä¹ˆä¿¡æ¯ã€‚ é™¤ä»¥æ ¹å·dkä¸softmaxæ˜¯æ•°å­¦ç­–ç•¥ã€‚ å‰é¦ˆç½‘ç»œFFNç®€å•è€Œè¨€å°±æ˜¯å¢åŠ ç»´åº¦-å¢åŠ ä¿¡æ¯-é™ä½ç»´åº¦ã€‚-å¢åŠ éçº¿æ€§å˜åŒ–ã€‚ å±‚æ•°å½±å“é€å±‚æŠ½è±¡ã€‚æµ…å±‚å­¦ä¹ ä½çº§ç‰¹å¾ï¼ˆè¯æ€§ã€å±€éƒ¨è¯­æ³•ï¼‰ï¼Œæ·±å±‚æ•æ‰é«˜çº§è¯­ä¹‰ è¾“å…¥ç©ºé—´â€”Layer 1â€”è¯­æ³•ç©ºé—´â€”Layer 2â€”è¯­ä¹‰ç©ºé—´â€”â€¦â€”æ¨ç†ç©ºé—´ å•å±‚è¡¨ç¤ºï¼š Layer(x)LayerNorm(x+FFN(LayerNorm(x+Attention(x)))) å¤šå±‚å¤åˆï¼š Model(x)LayerN(LayerNâˆ’1(â€¦Layer1(x))) Prefill Decoder Prefillï¼ˆé¢„å¡«å……ï¼‰ï¼šå¤„ç†è¾“å…¥çš„æ‰€æœ‰å·²çŸ¥ tokensï¼Œè®¡ç®—å®ƒä»¬çš„éšè—çŠ¶æ€å¹¶å¡«å…… KV Cacheã€‚ Decoderï¼ˆè§£ç ï¼‰ï¼šåŸºäº KV Cache é€ä¸ªç”Ÿæˆæ–° tokenï¼Œç›´åˆ°ç»“æŸã€‚ 1.ä¸ºä»€ä¹ˆè¦æå‰è®¡ç®—æ‰€æœ‰çš„tokensï¼Ÿ 2.æ€ä¹ˆè®¡ç®—kvçš„ï¼Ÿ 3.ä»€ä¹ˆæ˜¯ token çš„éšè—çŠ¶æ€ 4.QKVæƒé‡çŸ©é˜µæ˜¯å¹²å˜›çš„ï¼Ÿ 5.ä»€ä¹ˆæ˜¯PDåˆ†ç¦» ä¼˜åŒ–ç­–ç•¥è®¡ç®—å›¾ä¼˜åŒ–ä¸ç®—å­èåˆ æŠ•æœºé‡‡æ · FlashAttention","tags":[null]},{"title":"åŠ›æ‰£åˆ·é¢˜ç¬”è®°ä¹±åº","path":"/notebooks/Interview/åŠ›æ‰£åˆ·é¢˜ç¬”è®°(ä¹±åº).html","content":"çŠ¶æ€è§„åˆ’ä¸“é¢˜119æ¨è¾‰ä¸‰è§’2 .dtnbjdcwwtbn{zoom:50%;} å…³é”®ç‚¹ ï¼š ç©ºé—´å¤æ‚åº¦O(row)","tags":[null]}]