[{"title":"GGML源码浅析","path":"/2025/08/01/GGML源码浅析/","content":"GGML 源码浅析1.核心数据结构1.1ggml_contextstruct ggml_context size_t mem_size; void* mem_buffer; //cpu采用由poxsi_align分配的内存对齐内存，对于不同的后端，分配不同的内存 bool mem_buffer_owned;//外部分配还是属于本处，决定内存分配权？ bool no_alloc; bool no_alloc_save; // this is used to save the no_alloc state when using scratch buffers int n_objects; struct ggml_object * objects_begin;//ggml_object维护的是一个链表 struct ggml_object * objects_end; struct ggml_scratch scratch; struct ggml_scratch scratch_save;; struct ggml_object size_t offs; size_t size; struct ggml_object * next; enum ggml_object_type type; char padding[4]; ; ggml_context是最核心的数据结构，所有的张量、计算图都依赖于这个数据结构: mem_size表示ggml_init时分配一块多大的内存，后续的张量都从这块内存中分配空间，避免反复的malloc mem_buffer_owned表示这个mem_buffer是外部传进来的还是自己分配的，决定分配权，避免误释放 。 no_malloc是表示张量分配内存的时候是真的分配内存还是仅仅用于占位 no_alloc_save使用了scratch会强制开启内存，所以需要暂存一下no_malloc scratch是一块临时内存，用于存放中间的临时结果、缓存 scratch_save暂存scatch的状态 n_objects以及两个指针维护了一个对象双向链表，记录所有已创建的对象，可以看到这个ggml_object主要维护了偏移offs和size,容易理解实际数据就是分配在ggml_context的buffer中，而要找到这些数据就通过object链表来进行查找与分配。 ggml_object这个结构体本本身也是分配在ggml_context.mem_buffer上的，之后跟着对应的数据。 ggml-object-ggml_tensor-tensor_data 这一部分的实现具体查看ggml_new_object static struct ggml_object * ggml_new_object(struct ggml_context * ctx, enum ggml_object_type type, size_t size) // always insert objects at the end of the contexts memory pool struct ggml_object * obj_cur = ctx-objects_end; const size_t cur_offs = obj_cur == NULL ? 0 : obj_cur-offs; const size_t cur_size = obj_cur == NULL ? 0 : obj_cur-size; const size_t cur_end = cur_offs + cur_size; // align to GGML_MEM_ALIGN size_t size_needed = GGML_PAD(size, GGML_MEM_ALIGN); char * const mem_buffer = ctx-mem_buffer; struct ggml_object * const obj_new = (struct ggml_object *)(mem_buffer + cur_end); if (cur_end + size_needed + GGML_OBJECT_SIZE ctx-mem_size) GGML_PRINT(%s: not enough space in the contexts memory pool (needed %zu, available %zu) , __func__, cur_end + size_needed, ctx-mem_size); assert(false); return NULL; *obj_new = (struct ggml_object) .offs = cur_end + GGML_OBJECT_SIZE, .size = size_needed, .next = NULL, .type = type, ; GGML_ASSERT_ALIGNED(mem_buffer + obj_new-offs); if (obj_cur != NULL) obj_cur-next = obj_new; else // this is the first object in this context ctx-objects_begin = obj_new; ctx-objects_end = obj_new; //printf(%s: inserted new object at %zu, size = %zu , __func__, cur_end, obj_new-size); return obj_new; 实际使用过程中，可以看到所有的操作都挂靠到ggml_context上 内存分配： struct ggml_init_params params = .mem_size = 64 * 1024 * 1024, .mem_buffer = malloc(mem_size), .no_alloc = false;struct ggml_context * ctx = ggml_init(params); 张量分配： struct ggml_tensor * a = ggml_new_tensor_1d(ctx, GGML_TYPE_F32, 10); ​\t可以查看ggml.c/ggml_new_tensor_impl()具体实现，最终分配的tensor的data,指针指向的数据还是ggml_contxt.mem_buf中的对应偏移量。 计算操作： struct ggml_tensor * c = ggml_add(ctx, a, b); 执行计算图： struct ggml_cgraph graph = ggml_build_forward(c);ggml_graph_compute_with_ctx(ctx, graph, n_threads); 下边小红书博主**TransormerX**绘制的这几张图 清晰 美观的展示了内存分配情况： .ygqtuorlecip{zoom:80%;} .gfyvevcmcqyt{zoom:67%;} .qpimnwgbkgwy{zoom:50%;} 除了图中绘制的tensor是按照这样的内存分布以外，其他类型graph、workbuffer等类型的object都是采用这样的内存排布，即：object结构体-对应类型结构体（tensor\\graph)-相应data 比如图的存储就是object-ggml_cgraph(结构体本身)-节点叶子等指针数组 WORK_BUFFER就是object–work_data （直接被cplan中的指针所指） 1.2ggml_state整个ggml程序运行过程中有一个全局的g_state. static struct ggml_state g_state;#define GGML_MAX_CONTEXTS 64struct ggml_state struct ggml_context_container contexts[GGML_MAX_CONTEXTS]; struct ggml_numa_nodes numa;;struct ggml_context_container bool used; struct ggml_context context;;struct ggml_numa_nodes enum ggml_numa_strategy numa_strategy; struct ggml_numa_node nodes[GGML_NUMA_MAX_NODES]; uint32_t n_nodes; uint32_t total_cpus; // hardware threads on system uint32_t current_node; // node on which main process is execting#if defined(__gnu_linux__) cpu_set_t cpuset; // cpuset from numactl#else uint32_t cpuset; // no NUMA support outside of Linux at this time. Use a portable datatype#endif; ggml_state中包含了一个ggml_context（额外加一个used标识而已）数组。 在第一次调用ggml_init时，会对g_state进行初始化。 //位于ggml.c/ggml_initif (is_first_call) //.....初始化激活函数表 //初始化g_state g_state = (struct ggml_state) /*.contexts =*/ 0 , /*.numa =*/ .n_nodes = 0, .total_cpus = 0, , ; for (int i = 0; i GGML_MAX_CONTEXTS; ++i) g_state.contexts[i].used = false; 于是可以理解到，程序运行时，会在全局静态内存区分配一个g_state,包含了一个g_context数组，每次ggml_init的时候就去g_state中找一个没有使用的g_context,获得其指针后进行每个字段的初始化以及填充，之后就依靠这个ggml_context进行一次一次。 目前个人看代码觉得每次模型执行只需要一个ggml_conterxt，但是给了一个64个ggml_context组成的数组，是因为可能需要支持模型的并行（这个观点参考GPT） 1.3ggml_tensor// n-dimensional tensor struct ggml_tensor enum ggml_type type; //数据类型 GGML_DEPRECATED(enum ggml_backend_type backend, use the buffer type to find the storage location of the tensor); struct ggml_backend_buffer * buffer;//一个表示数据实际存储的内存后端，多态实现，一个重要的结构体 int64_t ne[GGML_MAX_DIMS]; // number of elements//每一维的元素个数 size_t nb[GGML_MAX_DIMS]; // stride in bytes: //每一位走到下一个元素的字节数 // nb[0] = ggml_type_size(type) // nb[1] = nb[0] * (ne[0] / ggml_blck_size(type)) + padding // nb[i] = nb[i-1] * ne[i-1] // compute data enum ggml_op op;//这个tensor是通过什么操作计算得到的 // op params - allocated as int32_t for alignment int32_t op_params[GGML_MAX_OP_PARAMS / sizeof(int32_t)]; //存储当前op的参数op = CONV2D 时，可能存储 kernel size、stride int32_t flags; struct ggml_tensor * grad; //如果当前张量支持反向传播，则存储梯度张量 struct ggml_tensor * src[GGML_MAX_SRC]; //当前张量是某个张量的运算结果，则记录输入张量 // source tensor and offset for views struct ggml_tensor * view_src; size_t view_offs; void * data;//实际张量的数据指针，通常指向ggml_context char name[GGML_MAX_NAME]; void * extra; // extra things e.g. for ggml-cuda.cu // char padding[4]; ; 这里有一个比较重要的概念是view,view不会信分配内存。一个简单的例子：如果一个短向量是一个长向量的子向量，可以理解为短向量是长向量的子向量，也就是长向量的视图，分配短向量时，可以利用长向量已经分配的内存，从而避免了内存的分配。 1.4 ggml_cgraphstruct ggml_cgraph int size; int n_nodes;//节点 int n_leafs;//叶子节点数 struct ggml_tensor ** nodes;//中间节点数 struct ggml_tensor ** grads; struct ggml_tensor ** leafs;//叶子节点 struct ggml_hash_set visited_hash_set;//反向构建中 hash去重 enum ggml_cgraph_eval_order order; ; 2.核心操作2.1模型加载gguf结构与解析gguf定义了模型的权重保存方式，以下为gguf的结构 主要可以分为以下4部分： 1.header 包含模式，tensor数量、kv元数据数、版本等 2.模型元数据（KV表示） 3.每个tensor的信息（offset等，不包含tensor的值） 4.tensor的值 文件ggml.c中，定义了gguf相关的结构体，其中gguf_context对应于一个文件，包含header、kv、tensor_info等 union gguf_value uint8_t uint8; int8_t int8; uint16_t uint16; int16_t int16; uint32_t uint32; int32_t int32; float float32; uint64_t uint64; int64_t int64; double float64; bool bool_; struct gguf_str str; struct enum gguf_type type; uint64_t n; // GGUFv2 void * data; arr;;struct gguf_kv struct gguf_str key; enum gguf_type type; union gguf_value value;;struct gguf_header char magic[4]; uint32_t version; uint64_t n_tensors; // GGUFv2 uint64_t n_kv; // GGUFv2;struct gguf_tensor_info struct gguf_str name; uint32_t n_dims; uint64_t ne[GGML_MAX_DIMS]; enum ggml_type type; uint64_t offset; // offset from start of `data`, must be a multiple of `ALIGNMENT` // for writing API const void * data; size_t size;;struct gguf_context struct gguf_header header; struct gguf_kv * kv; struct gguf_tensor_info * infos; size_t alignment; size_t offset; // offset of `data` from beginning of file size_t size; // size of `data` in bytes //uint8_t * padding; void * data;; ggml.c/gguf_init_from_file实现了从文件加载模型到结构体中 2.2计算图构建以simple-ctx为例说明计算图构建流程 struct ggml_cgraph * build_graph(const simple_model model) struct ggml_cgraph * gf = ggml_new_graph(model.ctx); // result = a*b^T struct ggml_tensor * result = ggml_mul_mat(model.ctx, model.a, model.b); ggml_build_forward_expand(gf, result); return gf;struct ggml_tensor * ggml_mul_mat( struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b) GGML_ASSERT(ggml_can_mul_mat(a, b)); GGML_ASSERT(!ggml_is_transposed(a)); bool is_node = false; if (a-grad || b-grad) is_node = true; const int64_t ne[4] = a-ne[1], b-ne[1], b-ne[2], b-ne[3] ; struct ggml_tensor * result = ggml_new_tensor(ctx, GGML_TYPE_F32, 4, ne); result-op = GGML_OP_MUL_MAT; result-grad = is_node ? ggml_dup_tensor(ctx, result) : NULL; result-src[0] = a; result-src[1] = b; return result; ggml_new_graph会在ggml-contxt中相关的内存区域分配ggml_cgraph的内存，进行初始化； 而后进行实际的算子构建，这个过程每一步得到的输出张量会记录对应的输入、以及操作类型，参照上边的ggml_tensor的数据结构 最后核心的函数是ggml_build_forward_expand，这个过程根据输出的tensor，反向添加graph中的计算节点。 具体构建过程见：ggml.c/ggml_visit_parents简言之就是DFS+hash去重，填充cgraph中的相关指针 2.3计算核心函数 enum ggml_status ggml_graph_compute_with_ctx(struct ggml_context * ctx, struct ggml_cgraph * cgraph, int n_threads) struct ggml_cplan cplan = ggml_graph_plan(cgraph, n_threads, NULL); struct ggml_object * obj = ggml_new_object(ctx, GGML_OBJECT_TYPE_WORK_BUFFER, cplan.work_size); cplan.work_data = (uint8_t *)ctx-mem_buffer + obj-offs; return ggml_graph_compute(cgraph, cplan); 主要步骤为， 1.构建执行计划ggml_graph_plan,生成执行顺序和任务计划、所有算子中的预计分配内存大小、线程数量。线程分配数量由ggml_get_n_tasks中的一个switch case决定。其中有一段work_size += CACHE_LINE_SIZE * n_threads;的代码是避免多个线程访问同一个缓存和，造成伪共享。一些可以被多线程执行的算子计算预计内存分配的时候还会乘以线程数，保证不会导致额外的内存同步开销。 2.ggml_new_object生成任务缓冲区,ggml_context中 。 3.执行计算图ggml_graph_compute ggml_graph_compute 执行ggml_graph_compute时，首先初始化或者设置ggml_threadpool中的相关参数，包括cplan等 只有调用ggml_graph_compute_thread进行多线程处理，启用omp进行多线程处理，否则单线程 其中遍历cgraph中的每个算子节点，通过ggml_compute_forward转发到不同的算子进行计算，每个算子内部区分不同的精读，转发到不同的精度处理函数，最后不同的精度计算算子函数 通过ith th考虑线程分配，内存存取 将线程划分计算的权利交给了算子自身来执行。 例如以f16_add为例,通过ith划分举证的行和列，每个线程计算不同的小矩阵，实现并行化。 static void ggml_compute_forward_add_f16_f16( const struct ggml_compute_params * params, struct ggml_tensor * dst) const struct ggml_tensor * src0 = dst-src[0]; const struct ggml_tensor * src1 = dst-src[1]; GGML_ASSERT(ggml_are_same_shape(src0, src1) ggml_are_same_shape(src0, dst)); const int ith = params-ith; const int nth = params-nth; const int nr = ggml_nrows(src0); GGML_TENSOR_BINARY_OP_LOCALS GGML_ASSERT(src0-type == GGML_TYPE_F16); GGML_ASSERT(src1-type == GGML_TYPE_F16); GGML_ASSERT(dst-type == GGML_TYPE_F16); GGML_ASSERT( nb0 == sizeof(ggml_fp16_t)); GGML_ASSERT(nb00 == sizeof(ggml_fp16_t)); // rows per thread const int dr = (nr + nth - 1)/nth; // row range for this thread const int ir0 = dr*ith; const int ir1 = MIN(ir0 + dr, nr); if (nb10 == sizeof(ggml_fp16_t)) for (int ir = ir0; ir ir1; ++ir) // src0, src1 and dst are same shape = same indices const int i3 = ir/(ne2*ne1); const int i2 = (ir - i3*ne2*ne1)/ne1; const int i1 = (ir - i3*ne2*ne1 - i2*ne1); ggml_fp16_t * dst_ptr = (ggml_fp16_t *) ((char *) dst-data + i3*nb3 + i2*nb2 + i1*nb1); ggml_fp16_t * src0_ptr = (ggml_fp16_t *) ((char *) src0-data + i3*nb03 + i2*nb02 + i1*nb01); ggml_fp16_t * src1_ptr = (ggml_fp16_t *) ((char *) src1-data + i3*nb13 + i2*nb12 + i1*nb11); for (int i = 0; i ne0; i++) dst_ptr[i] = GGML_FP32_TO_FP16(GGML_FP16_TO_FP32(src0_ptr[i]) + GGML_FP16_TO_FP32(src1_ptr[i])); else // src1 is not contiguous GGML_ABORT(fatal error); todo ggml backend","tags":["LLM/ggml"],"categories":["源码解析/大模型"]},{"title":"几种程序接口重定向、插桩方式比较","path":"/2025/07/29/几种程序接口重定向、插桩方式比较/","content":"最近在实验中需要分析程序中的堆变量内存分配情况，一开始自己的实现是采用llvm IR Pass修改的方式，后来在OSDI的论文中发现相关的方法采用的是LD_PRELOAD的方式实现，一开始认为这种方法会更加简单，于是进行了实现，结果发现各有特点。 1. LLVM IR 方式2. LD_PRELOAD方式代码 LD_PRELOAD的全进程级别：LD_PRELOAD是基于全进程级别的动态链接符号重定向。 启动加载时加载指定的.so文件，然后后续所有的调用都会使用so文件中提供的实现，这包括引用程序代码、第三方库、libc 比如：重定向了一个malloc，记录程序中的malloc地址然后使用LD_PRELOAD的方式进行重定向。 #include stdio.h#include stdlib.hint main() void* p = malloc(64); // printf(p: %p , p); free(p); return 0; 理论以上代码值调用一个malloc,但是拦截重定向以后发现有3个malloc,不注释代码中的printf函数，还会多出一个malloc。 这样的全进程级别特性可以采集到lib c本身的特性，但是也可能会对程序分析不必要的麻烦，比如我本身只想分析应用程序级别的事务，实现程序代码中的过滤可以通过调用栈过滤等方式实现。","tags":["LD_PRELOAD","LLVM","PIN"]},{"title":"论文中常见内存性能分析workloads","path":"/2025/07/27/论文中常见内存性能分析workloads/","content":"一、分类说明整理所读到论文中经常使用的内存分析工作负载。 按照特点可以分为延迟敏感型、带宽密集型；按照作用可以分为AI、HPC、Database等 博客用于内存性能评估的workload中整理了常见的workloads,但是主要还是重在基本介绍，没有对其访存特征等镜像介绍。本文借鉴这篇博客，自己分析、运行相关workloads。 二、LLM inference1.llama.cpp轻量化的大模型推理框架、适用于嵌入型系统、边缘节点上进行大模型推理。 访存特征： 模型权重加载阶段：采用大块连续内存、或者可选mmap()映射模型参数。具有较好的空间局部性、较差的时间局部性(一次加载一次使用) 推理阶段：主要是KV-Cache需要大量内存访问，读写频繁、更新频繁、各个层中存在一些张量操作也需要访存。高读密集型 内存需求： ​\t同其他大模型推理需求相似，内存需求量主要来自模型权重与KV-cache。模型权重内存使用量与精读有关、KV-Cache与依赖层数有关。一个qwen-7b在llama.cpp的内存占用量约为14~16B 其他： ​\tllama.cpp的内存管理采用统一预分配内存池，使用offset二次分配与访问，最后集中释放的方式进行内存管理。其ggml内存中有对内存的一次性malloc（ggml_init）ggml_new_tensor、ggml_new_tensor_1d进行内存内存二次分配、ggml_free进行内存释放。Arena 分配器（“批发内存，零售指针，整单清场”）","tags":["内存性能分析workloads"],"categories":["内存性能分析workloads"]},{"title":"Qt源码阅读与设计模式","path":"/2025/07/18/Qt源码阅读与设计模式/","content":"todo","tags":["Qt","设计模式"],"categories":["Qt"]},{"title":"CPP杂记","path":"/notebooks/cpp/CPP杂记.html","content":"全局静态变量、函数内静态变量、attribute((destructor))析构顺序构造析构顺序的不确定性 以及静态函数获取的单例。 C++ 标准规定：同一个编译单元（同一个 cpp 文件）内，静态全局对象的析构顺序与构造顺序相反。 但不同编译单元（不同 cpp 文件so）之间的析构顺序是未定义的。 局部 static（即函数内 static）对象的析构顺序与其定义顺序有关，但也只在同一编译单元内有保证。 若一个变量仅在单个文件中可见，则建议将这个变量声明为静态全局变量，static修饰的静态全局变量仅在当前文件中可见。 如果一个全局变量只被单个函数使用,将其改为该函数的静态局部变量可以进一步限制变量的作用域,提高代码的内聚性,降低耦合度。静态局部变量具有全局寿命但局部作用域的特点, 静态全局变量是存储在**静态数据区的,**而不是栈区,因此静态全局变量的大小不会导致栈溢出。栈溢出通常是由于函数调用层次过深或局部变量过大导致的。 类的内存占用 1.32位系统中虚函数指针为4字节，64位为8字节 2.只需要考虑虚函数指针，虚函数表不计入某个类的资源 3.char占一字节，但是需要考虑内存调用 4.如果有虚继承，则多一个虚基类指针。 5.空类占一个字节（用于标识） 指针好题 int arr[5]{1,2,3,4,5};在这个数组的定义中，通常的理解arr是数组的地址即数组首元素的地址，进一步理解arr是一个int型的指针常量，常量+1地址偏移sizeof(int)，所以arr+1是首元素下一个元素的地址；考虑到这一层就不难理解**arr*的含义，arr是对arr取地址，结果也是个地址，只是这个地址的类型是指向有5个int类型数据的数组的指针常量，这个常量+1地址偏移5sizeof(int)。 各级指针算各级的： 主要就是理解 和 * 的“升级降级”； 链接：https://www.nowcoder.com/exam/test/89156461/submission?examPageSource=Intelligentpid=62380309testCallback=https%3A%2F%2Fwww.nowcoder.com%2Fexam%2Fintelligent%3FquestionJobId%3D10%26subTabName%3Dintelligent_page%26tagId%3D21000testclass%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91 Copy and Swap传统做法operator= class MyString private: char* data; // 动态分配的字符串public: // 赋值运算符重载 MyString operator=(const MyString other) // 检查自赋值 if (this == other) return *this; // 释放当前对象的资源 delete[] data; // 复制数据 data = new char[std::strlen(other.data) + 1]; std::strcpy(data, other.data); // 返回当前对象的引用 return *this; ; Copy and Swap MyString operator=(const MyString other) // 检查自赋值 if (this == other) return *this; MyString tmpother; std::swap(data,other.data); return *this; 优势： 异常安全：传统方法new抛出异常时，对象出于无效状态。data已经被删除，但是分配失败 强异常安全性: 如果一个操作因为异常而失败，程序的状态会回滚到操作之前的样子，就像这个操作从来没执行过一样 代码复用：复用拷贝构造函数 自动资源管理：自动释放tmp资源 C++11 写法 MyString operator=(MyString other) //值传递 //传入左值：拷贝构造 //传入右值：移动构造 std::swap(data,other.data); return *this; 移动构造还是拷贝构造？ 左值：叫得出名字 右值：叫不出名字（临时变量，std::move） 左值用拷贝构造，右值用移动构造（偷）","tags":[null]},{"title":"控台项目与iSet项目已使用Qt技能点整理","path":"/notebooks/cpp/技能点整理.html","content":"Qt与QML知识总结Qt中的设计模式中间滑动的slider 2. doubleSpinBox3. iSet新建项目的两种模式ListWidget、选中状态设置为图标模式4.QTreeWidget 框架、表头、样式表、代理 Qt QTreeWidget树形控件用法详解_qtreewidget用法_睿科知识云的博客-CSDN博客 2. Qt大模块1. Qt DP指针2. 视图模型机制3. 视图框架4. QStyle 高度自定义实现5. 元对象与信号槽机制6.构建系统7.QInvokeMethod8.国际化3. Qt细节1. 基础控件2. Undo操作3. svg操作4. Qt不在对象树的工具汇总5.Qt中有有用的宏：Q_LIKELY 6.paint在install中绘制 4. Qt锦上添花1. 动画知识2. 拖拽3. 插件机制4.模块化构建5. Qt中的设计模式1. 单例模式2. 责任链模式3. 接口模式4. 适配器模式5.观察者模式， 线程观察、时间压缩 6.全局信号单例转发类 MAINOPERATIONVIEW_EXPORT bool MainOperationView_Init(IISetWidget ** ppWidget, QWidget * parent) if (ppWidget == nullptr || parent == nullptr) return false; *ppWidget = new CMainOperationView(parent); return true; 6. C++知识c++11新特性，所有知识点都在这了！ - 知乎 (zhihu.com) this_thread ++ lambda的坑 for(int id = enCoef9_Rr ; id = enCoef9_Bb ;id++) connect(m_spinBoxs[id],QOverloaddouble::of(QDoubleSpinBox::valueChanged),this,[](double value) OnCoefMatrixSlot(id,value); ); id 恒等于 0 多继承与QOBject private 虚继承 class CBaseprivate:\tvirtual void virtualPrivateFuntion() std::coutbase virtualPrivateFuntion;\t；class CSub :public CBase\tprivate:\tvirtual void virtualPrivateFuntion() override std::coutsub virtualPrivateFuntion;\tint main()\tCBase* pObject = new CSub();\tpObject-virtualPrivateFuntion();//结果：sub virtualPrivateFuntion，//结论：子类继承父类的private virtual可以重写 可变参数、变参模板 函数包装器 std::shared_ptrreset、make_shared 右值引用C++反射元编程Metaprogram is a program about a program. 7.杂项QStatusBar插件机制解耦快捷键ISet7.0 接口设计 MVC8.轮子1.单例2.工作线程封装3.stl 迭代器模式和适配器模式报错整理： QMenu 没有添加Action时，不能直接visible或这exec； setGeometry: Unable to set geometry 的一种解决办法是重写sizehint，而不是使用setFixedSize； 工具使用AddressSanitizer（不适用与MinGW）[AddressSanitizer 定位嵌入式cc++内存错误 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/436177229#:~:text=AddressSanitizer （又名 ASan）是 C%2FC%2B%2B 的内存错误检测器。 AddressSanitizer 由 google,的一部分，而从 4.8 版开始逐渐成为 GCC 的一部分。 这也意味着如果交叉编译器版本低于 4.8 ，是无法使用的。) Qt 拾遗 008 在 Qt 中使用 Address Sanitizer - 简书 (jianshu.com) 在Qt中使用gcc 4.8.0的地址消毒剂(Address Sanitizer) MTuner软件【精选】基于MTuner软件进行qt的mingw编译程序的内存泄漏检测_mtuner怎么使用_yantuguiguziPGJ的博客-CSDN博客","tags":[null]},{"title":"CXL-place-llvm-PGO杂记","path":"/notebooks/lab/CXL-place-llvm-PGO杂记.html","content":"CXL-place-llvm-PGO杂记 记录完成llvmPGO 中的一些知识杂记 1.llvm中的malloc重定向拦截案例：2.复制构造、移动构造、原地构造3.内存分配器的实现https://blog.lfalive.top/2022/02/15/JeMalloc/ http://hydra.azilian.net/Papers/jemalloc.pdf","tags":[null]},{"title":"nk01(tx-network)","path":"/notebooks/AI_interview/nk01(tx-network).html","content":"1.5层网络分别是什么，讲讲每层什么协议，有什么东西2.MTU包含哪些层的数据，大小一般多大怎么计算3.MTU和MSS区别4.TCP怎么保证可靠的6.建连和断连是怎么样7.为什么挥手四次要比握手多一次8.挥手并不是一定得四次，能在更少次数内实现，请分析可能怎么做的9.既然能挥手次数更少，但是为什么现在主流还是四次10.我假设是一个客户端，我在和服务端通信，我怎么知道发送窗口数据量是多大呢11.现在已经有了一个滑动窗口了，这个滑动窗口大小变化的时候是怎么变化的12.我丢包了，那这个窗口大小是不是就有问题了，有什么处理方案13.你作为一个一端的程序，是怎么知道是网络拥塞还是是链路丢包的14.TCP的拥塞控制是怎么做的15.假设要让你设计一个完整的判断网络拥塞还是链路丢包的协议，你会怎么设计16.现在假设你打开腾讯视频，突然某些（不是所有）视频你看不了了，你会怎么分析+排查+定位+解决这个问题，从app端上的问题-》网络的问题-》服务端的问题各个角度尽量全面的分析17.wireshark你了解吗，怎么在手机上抓包呢18.算了你假设你能在手机上抓包，你怎么从二进制数据排查定位分析这个场景的问题原因呢19.抓包的底层原理是怎么样的，这个包是怎么从操作系统的内核态数据取到的20.HTTP1-3对比，讲讲多路复用在内核是怎么实现的21.QUIC保证udp可靠传输和tcp自身可靠传输的对比22.HTTP和HTTPS区别23.你讲讲HTTPS的完整的方案24.你这种方案的RTT是多少25.有1RTT的HTTPS方案，你了解吗26.你对网络安全了解多少，像DDOS攻击，中间人攻击这些了解吗，有没有一些解决27.k个一组翻转链表 作者：静静地看你们表演链接：https://www.nowcoder.com/feed/main/detail/ebd659f61ec743d89c402d24311ca250来源：牛客网","tags":[null,null]},{"path":"/about/index.html","content":"🧑‍💻 About me Hello, welcome to my blog. I’m Zane Jiang. I graduated with a bachelor’s degree in Computer Science from Nanjing Normal University(NNU), and I am currently pursuing a master’s degree at the College of Computer Science, Chongqing University(CQU). I have worked as a C++ software development engineer for one year in a company specializing in LED control systems. My current areas of interest include OS,LLVM, CXL, Qt, and more. This blog is used to document some of my reflections on life, work, and study notes. 📫 Contact Email: 2129056867@qq.com GitHub"},{"title":"Hexo","path":"/notebooks/other/hexo.html","content":"Hexo部署过程中遇到的一些问题图片与Typora兼容网上给了很多方法，尝试没有效果，自己尝试的方案： 卸载插件hexo-asset-image: yarn remove hexo-asset-image,GitHub有修改的对应插件，但是使用无效果 typora配置 Typora新插入图片路径显示为： Hexo部署时正常显示 Hexo不生效问题Hexo部署到github上不生效，网上解决方案说需要除Main或者Master分支以外额外构建一个分支，然后网站推送到这个分支上，实际使用不管用。 首先，只需要维护一个主分支，不需要其他分支； 其次，hexo -d执行以后，main分支中即使已经更新了代码，但是github page更新也需要一段时间，部署频繁会产生排队 仓库主页github-pages上可以观察到生成静态页面的进度。","tags":[null]},{"title":"ASPLOS`25 Systematic CXL Memory Characterization and Performance Analysis at Scale","path":"/notebooks/paper/ASPLOS-25-Systematic-CXL-Memory-Characterization-and-Performance-Analysis-at-Scale.html","content":"Systematic CXL Memory Characterization and Performance Analysis at Scale Jinshu Liu Virginia Tech https://github.com/MoatLab/Melody 1.IntroductionCurrently, there is a significant gap in research that explores detailed CXL characteristics and their impact on memory-intensive workloads at scale, in depth, and across the full spectrum of sub-μs latencies. In particular, how do CXL devices differ in detailed performance characteristics beyond average latency and bandwidth metrics? How (much) does CXL’s long (and longer) latency affect CPU efficiency and workload performance? What are the underlying causes and how do we analyze it? Exsiting works focus on coarse-grained analysis and overlook several critical aspects: (i) CXL performance stability (i.e., tail latencies); (ii) CPU tolerance to prolonged CXL latencies across various workloads, and the architectural implications of CXL; and (iii) the lack of systematic approach to dissect workload performance and CPU inefficiency under CXL. So: introduce Melody, a comprehensive framework for detailed CXL performance characterization. The first analysis of CXL characteristics beyond average latency and bandwidth across 4 real CXL devices. An extensive evaluation of CXL’s performance implications across diverse workloads. A systematic approach for workload performance analysis under CXL. contributions(in my view): ​\t1.MELODY,a framwork to measure CXL perfomence. ​\t2.An in-depth study of CXL tail latencies (like caption). ​\t3.Root-cause analysis approach 2.BackgroundHow CPU backend and CXL MC process Load and Store request? .ttdxpdtpxdfl{zoom:200%;} Request types: The CPU issues two types of load requests: Demand and Prefetch. Demand loads are memory reads that CPU requests from (CXL) MC only when it is needed for computation. Prefetch reads are predictive reads directed by prefetchers, e.g., “L1PF” and “L2PF” in Figure 2a. Stores are first queued in the “store buffer.” Each store request triggers a Read-for-ownership (RFO) for cache coherence from CXLDRAM, followed by a Write upon cache eviction. MC ： Memory requests to the CXL MC are encapsulated(compress) in a specific packet format, known as Flits , for transmission over CXLPCIe. Upon arrival, the CXL controller (“CXL Ctrl”) parses the request and places it in the request queue. The request scheduler then selects the next request to process based on the scheduling policy and other factors such as thermal management for low latency, high bandwidth, and reliability. Requests are then passed to the command scheduler, which issues appropriate low-level DDR commands to the DRAM chips. 3.CXL Device Characterization3.1 Testbed Concern: work load: cloud workloads (in-memory caching and databases such as Redis [13] and VoltDB [21], CloudSuite [1], and Phoronix [12]), graph processing (GAPBS [22], PBBS [19]), data analytics (Spark [30]), MLAI (GPT-2 [5], MLPerf [14], Llama [9]), SPEC CPU 2017 [18], and PARSEC [24]. 3.2 CXL latency stability and its relationship with bandwidth Terms distinction: Loaded latencies: memory access latency under high utilization Idle latency: occurs when the system experiences minimal load 这一部分实现了一个MIO，通过多次指针追踪记录一次rdtsc时间戳来计算average latency，并采用MLC来验证MIO。测试了一些tail latency 与bandwidth之间的关系，结果均可以想到。 一个测量内存压力的方法：将指针追踪访问线程和32个AVX访存线程一起bind到一个numa nod(co-locate) CXL latency vs. bandwidth under various readwrite ratios. Local DRAM achieves the highest bandwidth under a read-only workload, whereas NUMA and all CXL devices (except CXL-C) achieve minimal bandwidth in read-only scenarios. This is because NUMA and CXL links are bidirectional, allowing them to sustain higher bandwidth under mixed readwrite workloads CXL devices demonstrate significant variability Impact of CPU prefetchers on (tail) latency. Prefetching does not fully mitigate CXL-induced tail latencies. Reasoning. 本节中测出的结果发现尾延迟等性能差距很大，这样的结论其实作用不大。但是性能差异大可以作为其他性能研究的挑战和动机 1.CXL协议传输层与连接层的实现本身引入了性能开销 2.MC 控制器实现本身 4 Workload Characterization 讨论了一些工作负载的延迟敏感性等，此前论文已经有过 5 Spa for CXL Slowdown Analysis5.2 Challenges and Limitations of State-of-the-ArtChallenge:1.Identifying the underlying CPU eventsmetrics that can correlate to the slowdowns is challenging. It is even more challenging to establish a precise correlation between workload performance and architecture-level performance metrics, Why not TMA? TMA does not provide a differential analysis to interpret pipeline differences resulting from varying backend memory (i.e., CXL vs. local DRAM). TMA is unable to precisely correlate architecture level metrics with workload slowdowns. 5.3 Spa: A Bottom-Up Approach DRAM (Demand Load) Slowdown:These misses denote demand read misses, excluding RFO and prefetch requests. Store Slowdown :Incoming store requests queued in the store buffer are dequeued upon completion. Some writes issue RFO requests before execution. If the store buffer fills up, these RFOs would hinder load efficiency, causing CPU stalls. Cache Slowdown:On SKX, most cache slowdown occurs in L2 due to a significant rise in stall cycles for L1 load misses with CXL. Conversely, on SPREMR, LLC experiences the bulk of slowdown, with a notable increase in stall cycles for L2 load misses with CXL. key finding: This reduces L2 prefetcher’s coverage of both demand reads and L1 prefetch. L1 prefetches would either miss entirely in L2 or at best, they would hit on a pending L2 prefetch in L2. Consequently, CXL also negatively impacts L1 prefetcher’s timeliness.Loads that would have otherwise hit in the cache if L1 prefetches were timely, now are delayed. Consequently, overall prefetch efficiency suffers and stalls on caches increase. 由于CXL的长延迟，L2预取的信息时效性降低，当L1需要相应数据的时候，L2还没有预取回来，导致L1认为miss，于是访问L2,再次发出请求。原本可以命中的Load请求变得不命中。 intel没有计数器直接观测L1Pf-L2-hit与miss的情况，可以通过一些其他的计数器间接的观测情况。 发现：L2PF-L3-miss减少，L1PF-L3-miss增多，L2PFL3-hit不变，因此推导出：L2预取器低效预取，L1预取增多。 5.5 5.6 Workload Slowdown Diversity Period-based Slowdown AnalysisAn approach to convert time-based sampling data into a period-based slowdown analysis. 5.7 Spa Use CasesPerformance tuning. For example, to mitigate the slowdown bursts observed in 605.mcf (Figure 16b), we first identify memory accesses during bursty periods (e.g., exceeding 10%) using binary instrumentation via Intel Pin. Next, we pinpoint the source code responsible for high slowdowns using addr2line. Our analysis reveals that two performance-critical objects, each 2GB in size, are contributing to the slowdown. 作者提到的两个case，一个是用来做性能优化，一个是作为性能指标来进行分层，这两个点其实都是和后一篇论文有联系，做铺垫。 不足与机会： 作者在验证cache slow down的主要原因的 方法是： To validate this, we disable all the hardware prefetchers (L1 and L2) and measure workload slowdowns. With prefetchers off, we found virtually no stall cycles on cache。这样的方法并不深入，为什么降低？这些值得深挖，但是需要一些硬件探索。 关于预取，可以增加预取器的深度(也就是再多预取几个周期)直接解决这个问题。 5.7中讲到了一个关于SPA的使用案例，通过剖析SPA中的slowdown来分析slowdown，然后把slowdown严重的变量放置到CXL，这样的方法我觉得十分适用。","tags":[null]},{"title":"perf使用","path":"/notebooks/other/perf使用.html","content":"Perf使用 杂记1.文档1.man+perf -h遇到新工具当然最好的方式是读文档，但是网络上找半天也没有找到很好的perf手册，最后发现在GPT的指引下，最好的手册害得是linux man手册。 上手最快最全面的方式：help+man 首先perf -h查看各条子命令基本功能。 在使用子命令时 man perf-record、man perf-script查看各条子命令的详细功能。 踩坑案例： 折腾半天perf record记录的L3 miss，perf script查看对应的结果，发现里面有一些地址，和程序malloc时的地址进行匹配发现都没有访问程序malloc的位置，最后发现其中的地址是ip而不是访问的内存地址。几番查找资料无果，最后发现perf record中使用-d参数才会显示addr 2.event查看各个事件的详细描述，在intel 官方的事件库中查找对应的事件功能 https://perfmon-events.intel.com/index.html?pltfrm=skylake_server.html 3.文章与优化案例https://www.brendangregg.com/ https://weedge.github.io/perf-book-cn/zh/chapters/3-CPU-Microarchitecture/3-8_Modern_CPU_design_cn.html 2.踩坑杂记perf事件冲突","tags":[null]},{"title":"CYY-RV64.zip","path":"/notebooks/paper/CYY-RV64.zip.html","content":"学习一下CYY师兄的工作，part1 https://www.rv64.zip/ BackgroundMotivation1.理想的RISC-V板子应当包含一组标准的指令拓展RVA23U64,但是目前的生态下，不同硬件支持的拓展与标准并不一致； 2.编译器和CPU没有针对新拓展进行优化的话，盲目打开新拓展反而会导致程序性能下降 Existing solution1.target_clones attributes 改代码，维护成本高 间接调用开销： When using target_clones or target_version, the compiler will use GNU IFUNC to dispatch the function call to the correct version at runtime. This introduces an overhead of an indirect function call, and also refuses some optimizations such as inlining. When compiling without -fno-plt or with -fno-pic, things will be worse since it requires 2 level call to the function (the first level is PLT call). 前置知识： PLT（Procedure Linkage Table) PLT 是动态链接（共享库）中用于实现 延迟绑定（Lazy Binding） 的核心结构，解决程序调用共享库函数时的跳转问题。 首次调用函数时： 程序跳转到 PLT 表中的对应条目（如 printf@plt）。 PLT 条目包含一条跳转指令，默认指向 动态链接器（_dl_runtime_resolve）。 动态链接器解析函数真实地址，并回填到 GOT（Global Offset Table）。 后续调用时： PLT 直接通过 GOT 跳转到真实函数地址（无需再次解析）。 -fno-plt 选项可绕过 PLT，直接通过 GOT 调用 IFUCN（Indirect Function） 运行时动态选择函数的具体实现,通过函数指针跳转，比直接调用多一次寻址，地址运行时确定，无法内联 定义时通过 __ attribute__((ifunc(resolver)))标记函数，提供一个解析器函数。 static void* my_func_resolver() if (__builtin_cpu_supports(avx2)) return my_func_avx2; else return my_func_default;void my_func() __attribute__((ifunc(my_func_resolver))); 最佳案例：GLib通过IFUNC为memcpy提供了多个实现。 Solution1.Decoupled function clone table​\t相当于将target_clones attributes从函数层提升到了文件层，不需要修改源代码。patch 2.Automatic function clone table generation​\t根据perf结果选择最佳的result 3.针对直接调用提了一些编译器端和CPU端的支持 期待CYY师兄的正式论文,后续继续学习 Other1.英语表达读起来好舒服 2.类似的方案在box64之类的二进制翻译场景下也大有用处。","tags":[null]},{"title":"OCP China 2024 CXL 论坛学习笔记","path":"/notebooks/paper/OCP-China-2024-CXL-论坛学习笔记.html","content":"OCP China 2024 CXL论坛 学习笔记会议链接 阿里云 数据中心高性能Scale Up 互联系统趋势 孔阳 阿里云超高速互联负责人 胡文普 CXL部分 Scale Up 云的角度 关注两个计算 ： 通用计算、GPU计算 通用计算上： 考虑弹性分析：存储上-云盘技术 网络-CIPU网络虚拟化 内存上-CXL GPU上：大模型单次任务，数据并行、流水线并行、tensor并行、专家并行，都具有较高的带宽要求 CXL 机柜内的资源弹性实现需要满足高性能接口、资源共享、极致弹性、软件生态兼容性等要求。CXL特性符合这些要求。CXL将一致性访问从CPU内部拓展到CPU和内存之间，实现多服务器之间的互联。 CXL的演进 GIM ： P2P ： DSP与type3互联，type3可以分配给DSP或者host HBR-PBR:不止树状、星状、网络状 E3.s 热插拔，便于可拓展 JBOM 大容量 PEMEM ：支持2.0，满足redis实时性持久化等要求 基于 内存与CPU实现资源解耦 CXL在小数据上传输性能大大提高； intel: CXL on Intel Xeon@ Platform 赵森林 CXL overview CXL Specification Summary","tags":[null]},{"title":"龙蜥CXL讲解-高显扬","path":"/notebooks/paper/龙蜥CXL讲解-高显扬.html","content":"CXL技术介绍对视频链接的PPT搬运，方便快速阅读 高显杨 浪潮 综述 协议协议演进 1.1内存拓展 2.0内存赤化 3.0特性 CXL子协议 CXL设备 CXL Fabric 参考VPN，下边两张为单switch CXL RAS特性 内存热插拔？如何避免宕机 CXL初始化 RCRB CXL 1.1跑CXL2实现协议兼容 CXL方案 池化管理：FM中的bind和UnBind 业界方案 补充","tags":[null]},{"title":"llama.cpp","path":"/notebooks/other/大模型/llama-cpp.html","content":"Llama.cpp源码浅析ggml 源码结构学习入口函数简单以llama.cli作为推理学习的入口。其入口函数main位置为：llama.cpp/tool/main.cpp/main() 关键数据结构内存管理Arena 分配器“批发内存，零售指针，整单清场” 批发内存： 零售指针 整场清除： mmap模型加载流程： 核心步骤： llama_model_loadre 核心对象. 之后加载模型架构arch\\超参数hparams\\词表vocab\\元数据信息、以及张量tensors","tags":[null]},{"title":"OSDI'25 Tiered Memory Management Beyond Hotness","path":"/notebooks/paper/OSDI-25-Tiered-Memory-Management-Beyond-Hotness.html","content":"Tiered Memory Management Beyond Hotness Jinshu Liu Hamid Hadian Hanchen Xu Huaicheng Li Virginia Tech https://github.com/MoatLab/SoarAlto/ Virginia 这个MoatLab对CXL内存的研究很深入，之前的Pond(ASPLOS `23)、Melody（ASPLOS`25）都出自这个实验室 1.IntroductionHot data is not always performance-critical and can reside in the slow-tier without degrading performance . Latency mitigation techniques, such as memory-level parallelism (MLP), obscure the true cost of memory accesses 1.先前的工作通过启发式或者内存访问成本间接的反应MLP的影响，但是仍然缺少准确的MLP建模和指标。 2.现有的内存分层方法具有难以轻量化和不准确的特点。尤其是一开始先放置本地内存的方法本身就是次优的，并且激进的迁移策略会导致过分的迁移。 所以作者就定义了一个MLP影响的指标，AOL，并且用来辅助放置决策和迁移决策。 Propose Amortized Offcore Latency (AOL), a novel performance metric that accurately quantifies the performance impact of memory accesses by integrating memory latency and MLP. 放置决策策略SOAR基于AOL进行排序，然后以此决定放置。ALTO依靠AOL来进行页面提升的过滤，可以与TPP等策略进行结合。 2.Background and MotivationMLP反映等待内存控制器实现的内存请求数量。 high-MLP access patterns： array traversals。 low MLP：pointer-chasing with depedent requests 把两个类型的访存一起跑，然后不同的分层策略依照不同的策略跑了测性能，发现把数组访问的放到快速层，反而会使性能降低。 3.Memory Performance PredictionRelating Slow-tier Performance to CPU Stalls离线分析 Performance degradation on the slow-tier is predominantly caused by increased CPU stalls due to LLC misses, which we refer to as LLC-Stalls 强调区分LLC-miss和LLC-Stall 慢速层单次miss造成的延迟更长，假设相同的miss,慢速层也会有更长的LLS-Stall. 论文中讲到基于LLC-Stall来预测减速的误差低于4%，开源以后可以预测一下基于LLC-Miss的（考虑预取器的影响）。 LLC-Stalls for Performance Prediction在线预测 发现快速层发生CPUStall的在慢速层也会发生。 所以用P SLLCc来预测慢速层的减速。 AOL for Accurate Prediction进一步研究发现，P在低MLP的场景下准确，但是在高MLP的场景下并不准确、主要是忽略了MLP的影响，高MLP会减少长延迟的影响。 随着延迟的增加，MLP的延迟掩盖受益会降低。 因此定义了AOL： 指标 事件 含义 𝑠𝐿𝐿𝐶 CYCLE ACTIVITY.STALLS L3 MISS L3 Miss时导致的Stall c CPU_CLK_UNHALTED.THREAD 非Halt下的时钟周期数 A1 OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DATA_RD L2 Miss 后、请求完成前，这些内存读取请求在 SQ 中等待的周期数换言之，每个时钟周期检查是否存在至少一个load请求，有就加1 A2 OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD L2 miss 后，每个周期有多少个未完成的 Demand Load 请求在SQ中等待，即：请求堆积的深度压力。 A3 OFFCORE REQUESTS.DEMAND DATA RD L2 miss 后，被发往 uncore 的 load 请求的次数。 延迟计算运用到了排队论中的Little`s法则:平均在系统中的项数 L = 到达率 λ × 平均响应时间 W 结合事件： L 某个时间段内，在 uncore 正在等待完成的请求数（单位：个），即 “每周期 outstanding 的请求数” λ 请求到达速率（单位：请求周期）≈ 总请求数 总周期数 W 每个请求在系统中停留的时间（单位：周期）→ 平均延迟 W = L / λ = 平均 outstanding 请求数 / 到达速率 根据排队理论，计算得1。 MLP是平均每个周期内多少个inflight内存请求，衡量内存访问的并行度。 A2代表总的堆积请求数，总的堆积请求数（A2）除以总的堆积周期数（A1),得到每个周期的平均inflight请求数。 1、2代入的AOL。 延迟除以并行请求，得到了一个并行请求下单个请求的延迟影响。 然后作者定义了减速模型：S P x K. k f(AOL)的函数是用SP与AOL进行分析，反向呈现出特定的渐进双曲线，反推出了其数学模型。 关于a和b，与硬件相关而与工作负载无关的常数，两个特定的场景（指针追踪、数组访问）能够推出（估计待定系数法） 分析： AOL增加时（MLP减小或者Latency增大），K趋近到上界1，S接近P,预测由LLC.stallc决定。相反（MLP增大或者Latency减少），K趋近下界0，S减小 有了预测模型以后，基于时间序列预测了 4.Soar: Rank-based Static Object Allocation现有的初次放置的分层方案目的是最大化利用快速层内存。 作者希望寻找一种方法最初就能精准放置内存，降低内存迁移开销。 读到这句话的时候这难受。。 挑战： While AOL-based prediction is effective at the workload level, it falls short for individual objects due to the semantic gap between architectural events and object-level memory accesses. 尽管AOL预测在workload级别能够表现得很好，但是却无法在单个变量上表现很好。 key insight： ​\tdistribute CPU stalls across objects proportionally to their relative access frequencies based on the observed MLP and latencies, thereby approximating each object’s performance impact to application performance accurately. Object-Level Performance Profiling​\tPeriodically collects and processes three types of metrics: object metadata via object tracking memory accesses via PEBS-based LLC-miss sampling temporal performance via AOL-based prediction ①-②Object TrackingFlow 通过LD_PRELOAD的方式拦截修改，记录五元组对象流 ③-④用PEBS记录LLC misses、访问时间戳和vaddr ⑤-⑥基于AOL预测性能 ⑦ 合并三个对象流，基于时间戳来判断地址，有了访问时间戳，可以计算访问次数以及访问比例。 ⑧将访存比例与AOL减速预测结合，计算减速得分 具体计算算法： 极端场景下并行少，MLP1，减速打分等于时间段减速P*访存比例R 高MLP时，缩小评分 低MLP时，放大评分 作者随后解释了怎样设计的factor，以及计算单位字节得分等。 Object Allocation依然是打分之后进行排序，topk 放置到快速层 影响排名不一定与请求顺序相同，如果打分低的先到了，后续打分高的请求到了会使得打分低的请求降级。 问题：是依据调用栈来进行分组对变量进行标识的，这样在一个函数内部进行内存分配时，大家调用栈都相同，这样并无法区分。 具体要看代码实现是否区分时空调用？ 特别指出可以与一些异构内存感知的内存分配器同时使用（memkind、Unified Memory Framework) Use Cases and Limitations1.HPC、在线服务这种长时间访问的应用，静态分配不再最优 2.假设对象是均匀的，对象内部的访问每一页频率都差不多。 5.Alto: AOL-based Adaptive Page Migrations现在方案的不足： 1.某些迁移没有。只是表面热 2.迁移开销很大，策略到单次迁移需要12us,访问到迁移中的页导致CPU stall 3.CXL与local的延迟和带宽都在缩小，迁移开销的影响就显得很大 4.冷页不是真的冷。 虽然用 AOL（Amortized Offcore Latency）来设计基于性能感知的页迁移（page-level migration）策略是很有前景的，但目前仍面临一些独特的挑战，特别是在如何用现有粗粒度硬件性能计数器（performance counters）准确估算单个内存页的性能影响方面。 方法很简单，就是用AOL辅助平时的方法决策一下： 而后讲了与TPP、Nomad、NBT等方法的集成。 6.Evaluation 关注1：CXL模拟方式：SKX lowering the uncore frequency and disabling cores on one NUMA node 关注2：workloads : GAPBS、ML、caching、SPEC2017 执行过程中的排序 ALTO效果。 不足与机会：1.从MLP的角度分析，和预取有关系吗？对于预取的影响（如果这个东西能量化，也能分析出很多东西） 2.并没有考虑区分读写比例的影响？ 3.本文中第4节提到的通过访存比例来分配内存slowdown的做法是否合理？ 是因为其指标是基于perf stat的，如果全部用perf record的方法是否会更加精确？这一点作者没有详细描述。 hard 4.全部放在运行时进行变量分析会不会发生采样不准确的问题，在NeoMem中也有？但是如何解决？可不可以结合NeoMem完全捕获数据流？ 基于采样，长生命周期的可能采集到，短生命周期取样。 机器的拓展性，针对SPX，其他的SPR、EMR的对应事件的拓展性替代如何，是否都只是PEBS？ 乱序校正的影响大不大？ 例如三段式的，第一次进行热点代码识别，第二次将热点代码全部卸载到CXL，然后利用Neomem捕获trace，从而准确感知，最后根据决策实现数据放置？ hard 5.结合内存分配器进行小变量页内集中优化，大变量的访问是否集中？不集中的话可以用perf采集地址，然后绘制访存直方图。","tags":[null]},{"title":"大模型入门","path":"/notebooks/other/大模型/大模型入门.html","content":"大模型基础概念入门Transformer自注意力（Self-Attention）Q\\K\\V Q：目前关系的问题，当前token; K:token的标签 V:包含的信息 Q*K得到谁更重要，之后再乘以V得到这些重要的人说了什么信息。 除以根号dk与softmax是数学策略。 前馈网络FFN简单而言就是增加维度-增加信息-降低维度。-增加非线性变化。 层数影响逐层抽象。浅层学习低级特征（词性、局部语法），深层捕捉高级语义 输入空间—Layer 1—语法空间—Layer 2—语义空间—…—推理空间 单层表示： Layer(x)LayerNorm(x+FFN(LayerNorm(x+Attention(x)))) 多层复合： Model(x)LayerN(LayerN−1(…Layer1(x))) Prefill Decoder Prefill（预填充）：处理输入的所有已知 tokens，计算它们的隐藏状态并填充 KV Cache。 Decoder（解码）：基于 KV Cache 逐个生成新 token，直到结束。 1.为什么要提前计算所有的tokens？ 2.怎么计算kv的？ 3.什么是 token 的隐藏状态 4.QKV权重矩阵是干嘛的？ 5.什么是PD分离 优化策略计算图优化与算子融合 投机采样 FlashAttention","tags":[null]},{"title":"LLVM","path":"/notebooks/compiler&kernel/LLVM/LLVM.html","content":"入门llvm笔记 1.新旧新增pass流程 2CRTP（奇异递归模板模式）(以下内容基于AI生成后修改) 通常通过继承的方式实现单例模式也是这样，只是不知道叫这个名字 CRTP（Curiously Recurring Template Pattern，奇异递归模板模式）是C++中的一种高级模板编程技术，通过让一个类继承自以自身为模板参数的基类模板，实现静态多态或代码复用。 template typename Derivedclass Base /* 基类使用Derived类型 */ ;class MyClass : public BaseMyClass /* 派生类将自身作为模板参数传递给基类 */ ; 核心作用1. 静态多态（编译时多态） 动态多态（虚函数）的问题：运行时虚表查找导致性能开销。 CRTP的解决方案：基类在编译时通过模板参数直接调用派生类的方法。 template typename Derivedclass Animal public: void speak() static_castDerived*(this)-speakImpl(); // 编译时确定调用 ;class Cat : public AnimalCat public: void speakImpl() std::cout Meow ; ;class Dog : public AnimalDog public: void speakImpl() std::cout Woof ; ;// 使用AnimalCat cat;cat.speak(); // 输出 Meow（无虚函数开销） 2. 代码复用 基类可提供通用逻辑，派生类通过特化实现差异部分。 template typename Derivedclass Counter protected: static int count;public: Counter() ++count; static int getCount() return count; ;template typename Derivedint CounterDerived::count = 0;// 统计对象实例数的类class Widget : public CounterWidget ;class Gadget : public CounterGadget ;// 使用Widget w1, w2;Gadget g1;std::cout Widget::getCount(); // 输出 2std::cout Gadget::getCount(); // 输出 1 CRTP vs 虚函数 特性 CRTP 虚函数 多态时机 编译时 运行时 性能 无额外开销（直接调用） 虚表查找开销 灵活性 类型固定（模板参数需明确） 支持运行时类型动态替换 适用场景 高性能库、框架基础设施 需要运行时动态行为的情况 CRTP的典型应用场景 编译时多态：如数学库中的向量矩阵运算（Eigen库）。 对象计数：统计不同派生类的实例数量。 Mixin模式：为类动态添加功能（如LLVM的PassInfoMixin）。 链式调用：返回派生类引用以实现链式语法（return static_castDerived(*this);）。 3 LLVM与CPP实现DenseMap与stdMapdyn_cast与RTTI isadef-use user-value为什么llvm中User会继承value 4 支配树基本概念支配树 wiki 严格支配（Strict Domination）：如果 A 支配 B 且 A ≠ B，则称 A 严格支配 B。 立即支配者（Immediate Dominator, idom）：对于某个基本块 B，其被严格支配的所有基本块中，离 B 最近的那个称为 B 的立即支配者。 LLVM中的使用场景 死代码消除 (Dead Code Elimination) 死代码消除有多种方法多种粒度，这里block为粒度可以使用支配树方法 如果一个基本块不在入口块的支配树上，那说明它在某些路径上根本无法到达，因此可能是不可达代码。 if (!DT-dominates(entry, B)) B-eraseFromParent(); // 删除不可达的基本块 循环识别 (Loop Identification) LICM（Loop-Invariant Code Motion）是一种经典的循环优化策略。要安全地将一条指令从循环体中移出（外提到前置块中），必须保证其在所有循环入口都被执行。 判断某条指令的基本开是够被循环入口块支配，如果支配，则说明每次都会执行这条指令，可以外提 静态单赋值节点Φ 节点插入 关键类与关键接口 DominatorTree：核心支配树实现，llvm/IR/Dominators.h DominatorTreeWrapperPass：将支配树封装为分析Pass DominatorTreeAnalysis：支配树分析 DominatorTree DT = getAnalysisDominatorTreeWrapperPass().getDomTree(); 作用： invoke callCallBaseInvokeInst 处理器硬件计数pt LBR PEBS","tags":[null]},{"title":"Kernel-compile","path":"/notebooks/compiler&kernel/Linux kernel/Kernel-compile.html","content":"内核编译#查看当前内核版本uname -a#源码获取sudo apt-get install linux-sourcecd /usr/srctar xvf linux-source-*.tar.bz2cd linux-source-*#补丁应用patch -p1 /path/to/patch.diff#`-p1`选项可能需要根据补丁文件的格式进行调整。make menuconfig #或者oldconfig,本质是配置/usr/src/configmake -j$(nproc)#根据 .config 配置文件编译内核、内核模块和其他必要的文件，生成内核镜像（vmlinuz）和其他相关的文件#编译过程中可能出现每包头文件或者其他错误，可能是版本原因，针对报错解决即可#内核安装#安装过程可能会出现头文件报错或者缺库、或安装完成后缺库，只需要apt安装对应的库就好，make过程中会自动hook#安装内核模块(在运行时可以加载或卸载的模块)#从编译输出的目录（如 lib/modules/kernel_version/）,并执行 depmod 来生成模块依赖关系sudo make modules_install#内核镜像（如 vmlinuz）、配置文件（如 config）、符号表文件（如 System.map）和 initrd 镜像安装到 /boot 目录sudo make install#更新启动引导程序sudo update-grup 关于配置选项相关操作，参考：:star::star:Linux 内核动手编译实用指南 KGDB配置编译选项 参考资料KGDB原理分析及远程挂载调试ARM64内核 内核启动参数 kgdboc=ttyS0,115200 kgdbwait kgdbtcp=192.168.1.2:1234 kgdboc=ttyS0,115200：设置串口调试（可选） kgdbwait：启动时等待调试器连接 kgdbtcp=192.168.1.2:1234：被调试主机的IP和端口 永久修改：/etc/default/grub下GRUB_CMDLINE_LINUX变量 proxmox-boot-toolproxmox-boot-tool，一个脚本，设置启动内核、增删内核等 Proxmox VE（Proxmox Virtual Environment）是一个开源的虚拟化管理平台，专为企业级环境设计，能够管理虚拟机（VM）、容器、存储和集群。 其中 proxmox-boot-tool脚本在内核管理切换过程中比较有用，这里做备份，便于不整体下载Proxmox VE而单独使用此工具，仅供个人学习使用 使用前提是需要先下载Promox VE 先换源/etc/apt/sources.list.d/pve-no-subscription.list deb http://mirrors.ustc.edu.cn/proxmox/debian/pve bookworm pve-no-subscriptiondeb http://mirrors.tuna.tsinghua.edu.cn/proxmox/debian/pve bookworm pve-no-subscription 记得把etcaptsources.list.d下原有的源注释掉 kernel add等 在 boot下边找到对应版本号 之后可通过apt search \\install 搜索下载对应的pve版本内核 proxmox-boot-tool下载链接,先下载proxmox-kernel-helper 参考链接： https://kernelnewbies.org/KernelBuild","tags":[null]},{"title":"Neoperf_study","path":"/notebooks/compiler&kernel/Linux kernel/Neoperf-study.html","content":"NeoPerf study 本文主要为学习论文《NeoMem: HardwareSoftware Co-Design for CXL-Native Memory Tiering》的工作，分为三个部分，用户态、内核以及FPGA部分，内核开源仓库地址为： PKUZHOUlinux 代码基于linux内核代码6.0开始修改。 由于初步探索linux内核代码，所以没有按照自顶向下的视角分析代码，而是基于git提交记录，借助AI与互联网搜索，平铺遇到的相关知识。版本不断更新…… a naive neoprof drivercommit ID 9bd35383 本次主要在driver目录下提交了一个驱动neoperf: 主要是实现了一些对外设的IO操作 Linux内核配置文件KconfigKconfig文件用于定义内核配置菜单，这些菜单可以在编译内核时启用或禁用特定的功能。 #Kconfig文件config NEOPROF#定义了一个名为`NEOPROF`的内核配置选项，将在内核配置菜单中创建选项\tbool Enable Neoprofiler #bool类型，是否启用 default n #默认不启用 在内核编译过程中可以在Drivers下查找到 Kconfig有其独特的语法，也是可以一层一层包裹下去：menu、source、endmenu等组成了编译选项配置过程中的树状菜单 Kconfig设置对应的编译变量后，makefile指导构建编译的过程中会利用这些变量，从而实现选择性的编译 neoperf.h主要新增了四个接口，对neoprof设备（此处指Type2-CXL设备）进行访问： /* * The following functions are used to access the neoprof device*/u64 get_nr_hotpages(void);//获取当前系统中的热页数量u64* get_hotpages(void);//获取热页u64 get_hotness_threshold(void);//获取热度阈值void set_hotness_threshold(u64 threshold);//设置热度阈值 neoperf.c驱动开发hello worldneoperf.c 以下部分参考驱动开发知识：https://www.cnblogs.com/downey-blog/p/10500828.html module_init(neoprof_init);module_exit(neoprof_exit);MODULE_LICENSE(GPL v2);MODULE_AUTHOR(PKUZHOU);MODULE_DESCRIPTION(Neoprofiler Linux driver); io地址映射相关知识需要理解 IO端口的编址方式： 包括IO指令的端口映射方式、MMIO的统一内存映射方式 一些常见的IO操作函数 void * ioremap(unsigned long phys_addr, unsigned long size, unsigned long flags); //memset_io\\memcpy_fromio\\readb 参考：https://blog.csdn.net/do2jiang/article/details/5450839 neomem migration skeletoncommit ID 26cabad18 新增 NeoMem模块: migrate.c主要是提供接口migrate_misplaced_page_no_vma 调用一些mm中的内存操作函数，进行页面隔离、迁移 neomem.h eomem.c主要就是启动 neomem模块（调用core文件中启动守护进程） late_initcall()在内核启动后期适当时间执行，理解module_init等init宏的顺序，在include/linux/init.h中 linux设备驱动加载的先后顺序 neomem_core.c 内存中的各种分配函数 kthread_run内核线程 FPGA端侧模块结构顶层模块： cxltyp3_memexp_ddr4_top-ed_top_wrapper_typ3 ddr内存参数调整cxl ip考虑了不同ddr的，包括是否支持DBI、内存通道数量等。采用宏的方式区分，设置不同的方式时，需要对ip内通过宏定义来确定相关的内存参数，同时也需要在顶层模块对相关参数进行修改。 .rprrpcsdliws{zoom:50%;} .ooymwtkzceep{zoom:50%;} .mzvwlfgqlynm{zoom:50%;} 或者通过更改ip文件，重新生成新的IP文件夹 .jwqgsldvedmq{zoom:50%;} quartusset_global_assignment -name OPTIMIZATION_MODE AGGRESSIVE COMPILE TIME 烧录模式AS Jtag ps 三种烧录模式 Neomem todo代码存在一些可以完善的地方： CXL地址采用硬编码，可以引入设备树或者其他检测CXL物理地址的工具进行优化，参考","tags":[null,null,null,null,null]},{"title":"linux脚本备忘录","path":"/notebooks/compiler&kernel/Linux kernel/linux脚本备忘录.html","content":"Linux脚本备忘录安装系统后的环境准备添加新用户 adduser #封装命令，处理完添加用户的全部过程 su到新用户显示username@hostname~$:useradd #底层命令，什么都没有加,su到新用户显示$:# 生成 8 位强密码PASSWORD=$(openssl rand -base64 6 | cut -c1-8)echo Password: $PASSWORD 用户添加sudo组 usermod -aG sudo new_user#加完以后记得:newgrp sudo#作用有3：#1.切换到指定的组上下文#2.即时生效组更改#3.启动一个子 shell 配置sshd#服务端安装apt install ssh-server#配置sudo vim /etc/ssh/sshd_config#重启服务sudo service restart sshd VimVim配置推荐 - ma6174 wget 47.93.11.51:88/install_vim.shbash install_vim.sh zsh#安装zshsudo apt install zsh#修改默认shell为zshchsh -s /bin/zsh#安装oh-my-zshsh -c $(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)##如果不成功，请执行下面两条命令，成功了就不需要做下面两条wget 47.93.11.51:88/install_zsh.shbash install_zsh.sh#安装zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM:-~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting 历史记录推荐命令插件##命令自动推荐，根据历史记录git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM:-~/.oh-my-zsh/custom/plugins/zsh-autosuggestions 命令自动补全##命令自动补全插件mkdir ~/.oh-my-zsh/plugins/incrwget http://mimosa-pudica.net/src/incr-0.2.zsh -O ~/.oh-my-zsh/plugins/incr/incr.plugin.zsh##目录自动跳转插件sudo apt install autojump .zshrc配置文件配置#插件添加zsh-syntax-highlightingplugins=(git zsh-syntax-highlighting) #设置终端颜色，提示符，及上一条指令返回码提示autoload -U colors colorsPROMPT=%$fg[red]%%n%$reset_color%@%$fg[blue]%%m %$fg[yellow]%%1~ %$reset_color%%# RPROMPT=[%$fg[yellow]%%?%$reset_color%]# Useful support for interacting with Terminal.app or other terminal programs[ -r /etc/zshrc_$TERM_PROGRAM ] . /etc/zshrc_$TERM_PROGRAMsource ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions/zsh-autosuggestions.plugin.zshsource /usr/share/autojump/autojump.shsource ~/.oh-my-zsh/plugins/incr/incr*.zsh ctags#安装sudo apt install ctags #建立索引ctags -I __THROW -I __attribute_pure__ -I __nonnull -I __attribute__ --file-scope=yes --langmap=c:+.h --languages=c,c++ --links=yes --c-kinds=+p --c++-kinds=+p --fields=+iaS --extra=+q -f ~/.vim/systags /usr/include/* /usr/include/x86_64-linux-gnu/sys/* /usr/include/x86_64-linux-gnu/bits/* /usr/include/arpa/* .vimrc添加索引 set tags+=~/systags 安装glibc-doc 使用以下命令安装 sudo apt install glibc-doc 常见路径hostname :/etc/hostname host: /ect/hosts tomcat#安装JDK8sudo apt install default-jre -ysudo apt install openjdk-11-jre-headless -ysudo apt install openjdk-8-jre-headless -y #sudo wget https://downloads.apache.org/tomcat/tomcat-8/v8.5.65/bin/apache-tomcat-8.5.65.tar.gzsudo wget https://mirrors.bfsu.edu.cn/apache/tomcat/tomcat-8/v8.5.73/bin/apache-tomcat-8.5.73.tar.gztar zxf apache-tomcat-8.5.73.tar.gzsudo mv apache-tomcat-8.5.73 /usr/local/tomcat#建立软连接sudo ln -s /usr/local/tomcat/bin/* /usr/local/sbin/#启动startup.sh start #端口检查netstat -anput | grep 8080#启动命令startup.sh start #//启动shutdown.sh #//关闭catalina.sh stop #//启动catalina.sh start #//关闭#关闭防火墙sudo ufw disable #tomcat 参数配置vim /usr/local/tomcat/conf/server.xml #.......Connector port=8081 protocol=HTTP/1.1 #将之前8080端口改成8081端口connectionTimeout=20000 # redirectPort=8443 /#目录修 # Host name=localhost appBase=/opt/www #将网站根目录改到/opt/www # unpackWARs=true autoDeploy=true#更改网站家目录，这里的ROOT必须大写，更改完成后需要重启sudo mkdir /opt/www/ROOT -p mysqlmysql 8.0下载 wget https://repo.mysql.com//mysql-apt-config_0.8.20-1_all.deb #MySQL 设置#密码sudo mysql -uroot use mysql;update user set authentication_string=PASSWORD(自定义密码) where User=root;update user set plugin=mysql_native_password where User =root;flush privileges;quit; 对于Linux和windows下字符集不兼容的情况，需要替换 • 把文件中的所有的utf8mb4_0900_ai_ci替换为utf8_general_ci• 以及utf8mb4替换为utf8• 如上图所示的位置，上图只是一部分，注意全部替换。 数据库导出 mysqldump -uroot -p c:ShareYunAlbum。sql 数据库导入 use ShareYunAlbum source ~/ShqreYunAlbum.sql 卸载mysql sudo apt purge mysql-* -ysudo rm -rf /etc/mysql/ /var/lib/mysqlsudo apt autoremovesudo apt autorecleansudo apt-get remove mysql-common dpkg -l |grep ^rc|awk print $2 |sudo xargs dpkg -P","tags":[null]}]